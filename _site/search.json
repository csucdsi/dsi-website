[
  {
    "objectID": "accessibility.html",
    "href": "accessibility.html",
    "title": "Accessibility at Wildcat Data Hub",
    "section": "",
    "text": "The Wildcat Data Hub is committed to providing data and research support that is accessible to all. We encourage all faculty, staff, students, and industry clients to participate in our consultations and project services.\nIf you anticipate needing any type of accommodation or have questions about physical access, please contact the Accessibility Resource Center (ARC) at 530-898-5959 in advance of your visit."
  },
  {
    "objectID": "sidebar.html",
    "href": "sidebar.html",
    "title": "Data Science at Chico State",
    "section": "",
    "text": "HIGHLIGHTS\n\n\n\n\n 2025-10-14  Data Science Seminar - Internship Series \n\n\n 2025-05-09  What Does Your Congressperson Really Think? \n\n\n 2025-04-17  Data Science Seminar – Dr. Chris Barker \n\n\n 2025-03-28  Data Science Seminar – Dr. Jing Guo \n\n\n 2025-03-14  Data Science Seminar – Your [Data] Powers Can Change the World! \n\n\n 2025-01-31  Introduction to Causality – Ricardo Aguilar \n\n\n 2024-12-06  Workshop Reproducible Research using R \n\n\n 2024-12-03  Masters in Data Science and Analytics - Fall 25 enrollment open \n\n\n 2024-12-01  We’re Hiring! \n\n\n 2024-03-15  DataFest 2024 @Chico April 12-14"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About the DSI",
    "section": "",
    "text": "The Data Science Initiative (DSI) at Chico State is a collective of interested faculty, students and staff working to develop the Data Science capabilities of our campus and community. By levering expertise across a wealth of disciplines including Statistics, Computer Science, Business, Biology, Nutrition, Mathematics and Political Science, Chico State is well poised to become an educational and workforce training leader in the North State."
  },
  {
    "objectID": "about.html#our-mission-is-to",
    "href": "about.html#our-mission-is-to",
    "title": "About the DSI",
    "section": "Our mission is to",
    "text": "Our mission is to\n\nFoster a supportive, inclusive and diverse community for data science researchers, practitioners, learners and enthusiasts.\nProvide high-quality data science education to learners from all backgrounds and domains.\nDevelop and support interdisciplinary teaching and research opportunities.\nEmphasize the use of data in an accountable and transparent manner for the benefit of all persons.\nFurther the advancement of algorithms and scientific methods to make decisions and extract insights from data."
  },
  {
    "objectID": "about.html#we-work-to-achieve-this-mission-by",
    "href": "about.html#we-work-to-achieve-this-mission-by",
    "title": "About the DSI",
    "section": "We work to achieve this mission by",
    "text": "We work to achieve this mission by\n\nBuilding relationships with community partners to build data-enabled solutions and provide high impact real-world learning experiences for students.\nProviding training on data collection, handling, visualization, statistical analysis and machine learning modeling, and reproducible research.\nOffer curriculum for multiple audiences including traditional in person and online courses, short term workshops and specialized trainings."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome,",
    "section": "",
    "text": "The Data Science Initiative at Chico State is a resource of information and support for our campus and community.\nBy providing data science education, research, and collaboration across disciplines we equip students with the skills needed to analyze and interpret complex data, while also providing faculty and community members with data-driven solutions through partnerships and consulting services.\nThis work fosters interdisciplinary learning, research opportunities, data analysis competitions, and real-world applications in fields like business, health, and regenerative agriculture. We are committed to helping to address the growing demand for data expertise in today’s job market.\n\n\n\n\n\n2024 NorCal DataFest participants, organizers, judges and President Steve Perez after a fun weekend of data wrangling, snacking and socializing."
  },
  {
    "objectID": "index.html#bridging-innovation-and-opportunity",
    "href": "index.html#bridging-innovation-and-opportunity",
    "title": "Welcome,",
    "section": "Bridging Innovation and Opportunity",
    "text": "Bridging Innovation and Opportunity\n\n\n\n\n Wildcat Data Hub \n\n\nThe Wildcat Data Hub (WDH) empowers the campus and local community with expert data science and statistical consulting, helping researchers and organizations achieve excellence in science and business. The WDH offers a range of services, including data collection, cleaning, visualization, and analysis, as well as personalized short and long term project assistance for students, faculty, and staff.\n\n\n\n\n\n NorCal ASA DataFest \n\n\nA 48-hour data analysis competition where undergraduate students from various majors work in teams on large, real-world data. The data is revealed at the event’s start on Friday evening, and teams present their findings to a panel of judges on Sunday afternoon. No prior programming experience is required!\n\n\n\n\n\n Community Coding \n\n\nCoding is a social activity! Whether you’re working on a data analysis project, exploring R or Python, or need a collaborative space to focus, this is the place for you. Bring your questions, challenges, and curiosity. Faculty and WDH staff are available to guide you through data science topics like data collection and analysis. Join a supportive environment where students, staff, and faculty can code, learn, and work together!\n\n\n\n\n\n Student Projects \n\n\nCheck out the variety of innovative projects students have created as part of the Data Science Certificate Capstone, or the Masters in Data Science and Analytics. These projects highlight the power of creativity and technical expertise. Whether it’s app development, research, or sustainability initiatives, these projects drive progress and provide real-world impact."
  },
  {
    "objectID": "news.html",
    "href": "news.html",
    "title": "News and Events",
    "section": "",
    "text": "Data Science Seminar - Internship Series\n\n\n\n\n\n\nSeminar\n\n\nData Science\n\n\nInternships\n\n\n\n\n\n\n\n\n\nOct 14, 2025\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nWhat Does Your Congressperson Really Think?\n\n\n\n\n\n\nSeminar\n\n\nData Science\n\n\nPolitical Modeling\n\n\n\n\n\n\n\n\n\nMay 9, 2025\n\n\nKhushi Choudhary\n\n\n\n\n\n\n\n\n\n\n\n\nData Science Seminar – Dr. Chris Barker\n\n\n\n\n\n\nSeminar\n\n\nClinical Trials\n\n\n\n\n\n\n\n\n\nApr 17, 2025\n\n\nKhushi Choudhary\n\n\n\n\n\n\n\n\n\n\n\n\nData Science Seminar – Dr. Jing Guo\n\n\n\n\n\n\nSeminar\n\n\nData Science\n\n\nGraph Theory\n\n\n\n\n\n\n\n\n\nMar 28, 2025\n\n\nKhushi Choudhary\n\n\n\n\n\n\n\n\n\n\n\n\nData Science Seminar – Your [Data] Powers Can Change the World!\n\n\n\n\n\n\nSeminar\n\n\nSocial Impact\n\n\nData Science\n\n\n\n\n\n\n\n\n\nMar 14, 2025\n\n\nKhushi Choudhary\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Causality – Ricardo Aguilar\n\n\n\n\n\n\nSeminar\n\n\nData Science\n\n\nCausal Inference\n\n\n\n\n\n\n\n\n\nJan 31, 2025\n\n\nKhushi Choudhary\n\n\n\n\n\n\n\n\n\n\n\n\nWorkshop Reproducible Research using R\n\n\n\n\n\n\nWorkshop\n\n\n\n\n\n\n\n\n\nDec 6, 2024\n\n\nDr. D\n\n\n\n\n\n\n\n\n\n\n\n\nMasters in Data Science and Analytics - Fall 25 enrollment open\n\n\n\n\n\n\nlearning\n\n\nMSDSA\n\n\n\n\n\n\n\n\n\nDec 3, 2024\n\n\nMSDSA Graduate Coordinator\n\n\n\n\n\n\n\n\n\n\n\n\nWe’re Hiring!\n\n\n\n\n\n\ninternship\n\n\nconsulting\n\n\nDataHub\n\n\n\n\n\n\n\n\n\nDec 1, 2024\n\n\nWildcat Data Hub\n\n\n\n\n\n\n\n\n\n\n\n\nDataFest 2024 @Chico April 12-14\n\n\n\n\n\n\nDataFest\n\n\n\n\n\n\n\n\n\nMar 15, 2024\n\n\nDr. D\n\n\n\n\n\n\n\n\n\n\n\n\nState of Data Science at Chico State - Fall 23\n\n\n\n\n\n\nclasses\n\n\ncertificate\n\n\nmasters\n\n\nlearning\n\n\n\n\n\n\n\n\n\nNov 15, 2023\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nAnnouncing Introduction to Python MATH 131 in Spring 2024\n\n\n\n\n\n\nclasses\n\n\npython\n\n\ndata\n\n\nlearning\n\n\n\n\n\n\n\n\n\nNov 13, 2023\n\n\nEdward A. Roualdes\n\n\n\n\n\n\n\n\n\n\n\n\nHealth Equity Datathon\n\n\n\n\n\n\nevent\n\n\n\n\n\n\n\n\n\nMar 9, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nDataFest 2023 April 14-16- Registration now open!\n\n\n\n\n\n\nevent\n\n\n\n\n\n\n\n\n\nMar 3, 2023\n\n\nDr. D\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Tech Justice: The Just Data Lab\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNov 27, 2022\n\n\nMath 485 Student\n\n\n\n\n\n\n\n\n\n\n\n\nResearch Statistician vacancies at the Bureau of Labor Statistics\n\n\n\n\n\n\nstatistics\n\n\nmathematics\n\n\nresearch\n\n\n\n\n\n\n\n\n\nNov 27, 2022\n\n\nDr. D\n\n\n\n\n\n\n\n\n\n\n\n\nFooling Facial Recognition\n\n\n\n\n\n\nmachine-learning\n\n\n\n\n\n\n\n\n\nOct 27, 2022\n\n\nBrandon Trahams\n\n\n\n\n\n\n\n\n\n\n\n\nSeptember Student post: Introduction to SQL\n\n\n\n\n\n\ntutorial\n\n\n\n\n\n\n\n\n\nSep 1, 2022\n\n\nJoseph Shifman\n\n\n\n\n\n\n\n\n\n\n\n\nAugust Student post: Underlying geometry of data\n\n\n\n\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nAug 1, 2022\n\n\nSkip Moses\n\n\n\n\n\n\n\n\n\n\n\n\nFall 22 Guest post series\n\n\n\n\n\n\nlearning\n\n\n\n\n\n\n\n\n\nJul 17, 2022\n\n\nDr. D\n\n\n\n\n\n\n\n\n\n\n\n\nChico State Data Fest 2022 Recap\n\n\n\n\n\n\nDataFest\n\n\n\n\n\n\n\n\n\nApr 4, 2022\n\n\nEmma Mitchell\n\n\n\n\n\n\n\n\n\n\n\n\nNew grant program supports Hispanic students in Data Science enabled USDA career paths.\n\n\n\n\n\n\ncollaboration\n\n\n\n\n\n\n\n\n\nMar 1, 2022\n\n\nEmma Mitchell\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Data to Fight Food Insecurity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2021\n\n\nDr. D.\n\n\n\n\n\n\n\n\n\n\n\n\nRs tapply() in Julia\n\n\n\n\n\n\nlearning\n\n\n\n\n\n\n\n\n\nSep 20, 2021\n\n\nEdward A. Roualdes\n\n\n\n\n\n\n\n\n\n\n\n\nNew Class!\n\n\n\n\n\n\nclasses\n\n\nlearning\n\n\n\n\n\n\n\n\n\nMay 12, 2021\n\n\nDr. D\n\n\n\n\n\n\n\n\n\n\n\n\nFall 21 internship opportunity\n\n\n\n\n\n\n\n\n\n\n\nMay 11, 2021\n\n\nDSI Coordinator\n\n\n\n\n\n\n\n\n\n\n\n\nVirtual Workshop Series for Harnessing the Power of Data to Advance Immune-mediated and Infectious Disease Research\n\n\n\n\n\n\nevent\n\n\nseminar\n\n\n\n\n\n\n\n\n\nApr 9, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nPaid summer research opportunity- Basic needs and food insecurity among college students\n\n\n\n\n\n\npaid-opportunity\n\n\n\n\n\n\n\n\n\nApr 7, 2021\n\n\nDSI Coordinator\n\n\n\n\n\n\n\n\n\n\n\n\nSofware Carpentry Workshop for Website Building\n\n\n\n\n\n\nworkshop\n\n\n\n\n\n\n\n\n\nFeb 10, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nSofware Carpentry Workshop for Website Building\n\n\n\n\n\n\nworkshop\n\n\n\n\n\n\n\n\n\nFeb 10, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nSpring internship opportunity\n\n\n\n\n\n\ninternship\n\n\n\n\n\n\n\n\n\nDec 11, 2020\n\n\nDSI Coordinator\n\n\n\n\n\n\n\n\n\n\n\n\nExtended hours for Community coding! Spring 20\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 22, 2020\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nData Science and Analytics Research Fellowship\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDec 3, 2019\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nASA DataFest 2020 @ Chico State - April 17-19\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNov 7, 2019\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nWe’re Hiring!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2019\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nAt DataFest 2019, I Learned…\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApr 9, 2019\n\n\nEdward A. Roualdes\n\n\n\n\n\n\n\n\n\n\n\n\nDSI Seminar 4/23 & 4/25: Growing a Scientific Mindset to Develop Analytics Teams\n\n\n\n\n\n\nworkshop\n\n\npredictive_analytics\n\n\n\n\n\n\n\n\n\nApr 9, 2019\n\n\nDSI\n\n\n\n\n\n\n\n\n\n\n\n\nNorcon - Hacker Conference April 13th\n\n\n\n\n\n\nevent\n\n\nconference\n\n\n\n\n\n\n\n\n\nApr 8, 2019\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nDSI Seminar 3/29: An Introduction to SAP Predictive Analytics Workshop\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMar 29, 2019\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nDSI Seminar 3/28: InfoVis: Communicating Data Visually\n\n\n\n\n\n\nviz\n\n\n\n\n\n\n\n\n\nMar 28, 2019\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nDSI Seminar 3/5: Strategies to manage Big Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMar 3, 2019\n\n\nEdward Roualdes\n\n\n\n\n\n\n\n\n\n\n\n\nWomen in Data Science technical conference! Mon Mar 4th, Sylvesters 100\n\n\n\n\n\n\nevent\n\n\n\n\n\n\n\n\n\nFeb 23, 2019\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nASA DataFest 2019 @ Chico State - April 5-7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 17, 2019\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nDSI seminar 2/19: Managing data from multiple tables using SQL\n\n\n\n\n\n\nlearning\n\n\nseminar\n\n\nworkshop\n\n\nevent\n\n\n\n\n\n\n\n\n\nFeb 13, 2019\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nDSI seminar 2/14: Spatial is Special!\n\n\n\n\n\n\nseminar\n\n\nworkshop\n\n\n\n\n\n\n\n\n\nFeb 2, 2019\n\n\n\n\n\n\n\n\n\n\n\n\nJanuary Updates\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 22, 2019\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nCommunity Coding - Now for credit!\n\n\n\n\n\n\nDSI\n\n\nevent\n\n\nlearning\n\n\nseminar\n\n\nworkshop\n\n\n\n\n\n\n\n\n\nJan 21, 2019\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nData Science info session\n\n\n\n\n\n\ncertificate\n\n\nclasses\n\n\nDSI\n\n\nevent\n\n\n\n\n\n\n\n\n\nOct 29, 2018\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nCloud Computing at Chevron\n\n\n\n\n\n\n\n\nThe Department of Computer Science Speaker Series\n\n\n\n\n\nOct 25, 2018\n\n\n\n\n\n\n\n\n\n\n\n\nBiomedical Optical Imaging and Machine Learning for Cancer and Disease Detection\n\n\n\n\n\n\nseminar\n\n\n\nThe Department of Biological Sciences Omicron Seminar Series\n\n\n\n\n\nOct 25, 2018\n\n\n\n\n\n\n\n\n\n\n\n\nFall hours set for DSI Workshops & Community Coding\n\n\n\n\n\n\n\n\n\n\n\nOct 8, 2018\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nSeminar: LabKey Server\n\n\n\n\n\n\nevent\n\n\n\nSecure collaboration for research labs\n\n\n\n\n\nOct 1, 2018\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nSoftware Carpentry- Post workshop report\n\n\n\n\n\n\nevent\n\n\nworkshop\n\n\n\n\n\n\n\n\n\nAug 19, 2018\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nMeasuring Variation in the Empirical Storm Season Over Time\n\n\n\n\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nJul 18, 2018\n\n\nEdward Roualdes\n\n\n\n\n\n\n\n\n\n\n\n\nAugust Workshop - Reproducible Scientific Research with R\n\n\n\n\n\n\nworkshop\n\n\n\nA Software Carpentry Workshop\n\n\n\n\n\nJul 14, 2018\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nCurrent job and research project openings at Chico State\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJul 11, 2018\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nData Fest Prep\n\n\n\n\n\n\nlearning\n\n\n\nPractice makes perfect!\n\n\n\n\n\nApr 23, 2018\n\n\n\n\n\n\n\n\n\n\n\n\nWorkshop: An Introduction to SAP Predictive Analytics\n\n\n\n\n\n\nworkshop\n\n\n\n\n\n\n\n\n\nApr 23, 2018\n\n\n\n\n\n\n\n\n\n\n\n\nWorkshop: Data Visualization with ggplot2\n\n\n\n\n\n\n\n\n\n\n\nApr 18, 2018\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nWorkshop: Using Python for Exploratory Data Analysis\n\n\n\n\n\n\nlearning\n\n\nworkshop\n\n\npython\n\n\n\nPart 2 of 2\n\n\n\n\n\nApr 5, 2018\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nWorkshop: A Brief Introduction to Tableau Public\n\n\n\n\n\n\nworkshop\n\n\ntableau\n\n\n\n\n\n\n\n\n\nApr 4, 2018\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nWorkshop: Getting Started with Python & Jupyter Notebooks\n\n\n\n\n\n\nlearning\n\n\npython\n\n\nworkshop\n\n\n\nPart 1 of 2\n\n\n\n\n\nApr 1, 2018\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nDataFest Registration now open!\n\n\n\n\n\n\nevent\n\n\nlogistics\n\n\n\n\n\n\n\n\n\nMar 26, 2018\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nData Science Certificate Info Session\n\n\n\n\n\n\ncertificate\n\n\nlearning\n\n\nclasses\n\n\n\n\n\n\n\n\n\nMar 23, 2018\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nSeminar: Introduction to Bayesian Modeling\n\n\n\n\n\n\n\n\n\n\n\nMar 15, 2018\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nSeminar: Teaching Bioinformatics\n\n\n\n\n\n\n\n\n\n\n\nMar 6, 2018\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nSave the Date! April 27-29 ASA DataFest 2018 @ CSUC\n\n\n\n\n\n\n\n\n\n\n\nFeb 21, 2018\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nNew Undergraduate Certificate in Data Science - Fall 18\n\n\n\n\n\n\n\n\n\n\n\nFeb 20, 2018\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nStan and C++ readings\n\n\n\n\n\n\n\n\n\n\n\nFeb 18, 2018\n\n\nEdward Roualdes\n\n\n\n\n\n\n\n\n\n\n\n\nSpring hours set for DSI Workshops & Community Coding\n\n\n\n\n\n\n\n\n\n\n\nJan 29, 2018\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nIntro to R (MATH 130)- New section added for spring\n\n\n\n\n\n\n\n\n\n\n\nDec 5, 2017\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nMeet and analyze data\n\n\n\n\n\n\n\n\n\n\n\nOct 24, 2017\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nFun Opportunities for Statistics Students\n\n\n\n\n\n\n\n\n\n\n\nOct 12, 2017\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to R Short Course\n\n\nstuff\n\n\n\n\n\n\n\n\nAug 14, 2017\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nCall for speakers and makers\n\n\n\n\n\nAre you working on an interesting project that you want to share?\n\n\n\n\n\nAug 1, 2017\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nNew Site\n\n\n\n\n\n\nlogistics\n\n\n\n\n\n\n\n\n\nAug 1, 2017\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nDSI Workshop - Fitting introductory statistical models in R\n\n\n\n\n\nSpring 17 DSI Workshop Series on R\n\n\n\n\n\nApr 28, 2017\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nDSI Workshop - Data Visualization with ggplot2\n\n\n\n\n\nSpring 17 DSI Workshop Series on R\n\n\n\n\n\nApr 21, 2017\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nDSI Workshop - Exploring your data\n\n\n\n\n\nSpring 17 DSI Workshop Series on R\n\n\n\n\n\nApr 14, 2017\n\n\nRobin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nDSI Workshop - Preparing Data for Analysis using R\n\n\n\n\n\nSpring 17 DSI Workshop Series on R\n\n\n\n\n\nApr 7, 2017\n\n\nRick Hubbard\n\n\n\n\n\n\n\n\n\n\n\n\nInstalling R with Homebrew on Mac OS X\n\n\n\n\n\n\ninstall\n\n\n\n\n\n\n\n\n\nMar 24, 2017\n\n\nJustin Bankes\n\n\n\n\n\n\n\n\n\n\n\n\nDSI Kick Off Meeting (& quick intro to R)\n\n\n\n\n\n\nDSI\n\n\nworkshop\n\n\n\n\n\n\n\n\n\nMar 24, 2017\n\n\nRobin Donatello, Rick Hubbard, Essia Hamouda\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/2024-09-20_Saul-Mooradian/index.html#sauls-2024-ds-capstone-project",
    "href": "projects/2024-09-20_Saul-Mooradian/index.html#sauls-2024-ds-capstone-project",
    "title": "Building an R package",
    "section": "Saul’s 2024 DS Capstone project",
    "text": "Saul’s 2024 DS Capstone project\nMy capstone project centered around streamlining common data analysis processes for Chico State’s Center for Healthy Communities - a non-profit organization promoting food security, nutrition education, and much more. These processes included re-coding variables, creating tables, and generating dynamic inline code, allowing for faster data processing and report building.\nTo do this, I developed an R package (chcRne) designed for the Research and Evaluation team at CHC. R packages provide a mechanism to get all your functions in a single, easily accessible location accompanied by documentation and examples."
  },
  {
    "objectID": "projects/2024-09-20_Saul-Mooradian/index.html#a-couple-of-examples",
    "href": "projects/2024-09-20_Saul-Mooradian/index.html#a-couple-of-examples",
    "title": "Building an R package",
    "section": "A couple of examples",
    "text": "A couple of examples\nCurrently there are 10 functions with documentation in the (chcRne) package. Here are the installation instructions along with an introduction to a couple chcRne functions.\n\nInstall chcRneto_binarycount_and_percent\n\n\n\n# Run the following two lines of code to install chcRne\ninstall.packages(\"devtools\") \ndevtools::install_github(\"Smoorad99/chcRnePackage\", dependencies = TRUE)\n\n\n\nto_binary() converts all “String”/“NA” or “Yes/”No” responses in the selected columns to binary (1/0) where the strings are replaced by 1s and the NAs are replaced by 0s.\n\ndf_converted &lt;- to_binary(data = bns2_pkg_data, \n                          these.cols = c(q14_1, q14_4), \n                          prefix = FALSE, yesno = TRUE)\n\n# View the converted dataframe side-by-side to check if the function worked\nold &lt;- bns2_pkg_data |&gt; dplyr::select(q14_1, q14_4)\nnew &lt;- df_converted |&gt; dplyr::select(q14_1, q14_4)\ncbind(old, new) |&gt; head(10)\n\n\n\ncount_and_percent() returns a string that includes the total count and percent of respondents that selected a category specified in the function. If you include one category, the function will return the count and percent of respondents that selected that category relative to all non-NA responses."
  },
  {
    "objectID": "projects/2024-09-20_Saul-Mooradian/index.html#lessons-learned",
    "href": "projects/2024-09-20_Saul-Mooradian/index.html#lessons-learned",
    "title": "Building an R package",
    "section": "Lessons learned",
    "text": "Lessons learned\nHere are a couple of lessons/things I wish I had put more thought into during the early stages of this project.\n\nFunction names are PAINFUL to change after a version of your package has been released and is being used by others. I would recommend spending some extra time when naming your functions and asking others for their opinion before a first release. If your second opinion grimaces when seeing the name of your function, you should probably change it. For example, nperc_tbl_MATA is not a good name for a function 😬\nIf you are including functions that already exist within your organization or that you use. Think about how you can improve these functions sooner rather than later. If you are like me, you many not have had the developer knowledge to do this immediately, but this may help you limit the breaking changes you make down the road."
  },
  {
    "objectID": "projects/2024-09-20_Saul-Mooradian/index.html#resources-for-package-creation",
    "href": "projects/2024-09-20_Saul-Mooradian/index.html#resources-for-package-creation",
    "title": "Building an R package",
    "section": "Resources for package creation",
    "text": "Resources for package creation\nIt is easy to be intimidated by scary phrases like “package development”, but R makes building packages relatively simple, with the option to add complexity. You can learn about and create a basic package in less than two hours. Also, Hadley Wickham and Jennifer Bryan have a wonderful book called R Packages that offers a more detailed introduction to package building - a book I relied heavily on during this project.\nThank you Robin Donatello, the Chico State Statistics Department, and the CHC team! This project would not have been possible without your guidance/mentoring over the last few years."
  },
  {
    "objectID": "Faculty_Expectations.html",
    "href": "Faculty_Expectations.html",
    "title": "Wildcat Data Hub Faculty Affiliate Expectations Guide",
    "section": "",
    "text": "This guide details the minimum expectations for participation to maintain status as a Faculty Affiliate of the Wildcat Data Hub (WDH/ “The Hub”), part of the Data Science Initiative (DSI) at California State University, Chico."
  },
  {
    "objectID": "Faculty_Expectations.html#goals-and-role-of-the-hub",
    "href": "Faculty_Expectations.html#goals-and-role-of-the-hub",
    "title": "Wildcat Data Hub Faculty Affiliate Expectations Guide",
    "section": "1.1 Goals and Role of The Hub",
    "text": "1.1 Goals and Role of The Hub\nThe WDH is dedicated to providing high-quality support for research projects while creating paid, hands-on learning opportunities for students, through a mix of pro-bono and fee-based services.\nWe fulfill this role by offering:\n\nFree drop-in consultation and coding support\nShort- and long-term project assistance provided by qualified students and experienced faculty on a fee-based system"
  },
  {
    "objectID": "Faculty_Expectations.html#core-services",
    "href": "Faculty_Expectations.html#core-services",
    "title": "Wildcat Data Hub Faculty Affiliate Expectations Guide",
    "section": "1.2 Core Services",
    "text": "1.2 Core Services\nThe WDH offers comprehensive support across the research lifecycle, including:\n\nSupport for programming languages (R, Python, SQL, and more)\nData cleaning and transformation\nData collection tools and techniques\nData visualization and reports\nReproducible research techniques\nData analysis using statistical modeling and machine learning\nDeveloping measurable outcomes for research and grant proposals"
  },
  {
    "objectID": "Faculty_Expectations.html#mandatory-annual-engagement",
    "href": "Faculty_Expectations.html#mandatory-annual-engagement",
    "title": "Wildcat Data Hub Faculty Affiliate Expectations Guide",
    "section": "2.1 Mandatory Annual Engagement",
    "text": "2.1 Mandatory Annual Engagement\n\n\n\n\n\n\nAnnual Contribution Required\n\n\n\nAffiliates must contribute to at least one (1) WDH service activity or project per calendar year to maintain their active status and qualify for renewal. Failure to meet this expectation may result in the non-renewal or removal of affiliate status at the end of the year.\n\n\nExamples of qualifying activities include:\n\nContributing to a WDH project: Providing specialized data analysis, programming, or research support to an official WDH project.\nHosting weekly Community Coding hours: Offering time for drop-in programming support to students, staff, and faculty through our Community Coding program. Note: This is an ongoing commitment; one session will not suffice.\nRecruit a client to the Wildcat Data Hub: Securing a client, whether at the university or in the community, for The Hub’s business.\nGrant Proposals: Writing, applying to, and receiving grants for The Hub to use to provide funding to training, equipment, students, or affiliates."
  },
  {
    "objectID": "Faculty_Expectations.html#communication-standards",
    "href": "Faculty_Expectations.html#communication-standards",
    "title": "Wildcat Data Hub Faculty Affiliate Expectations Guide",
    "section": "2.2 Communication Standards",
    "text": "2.2 Communication Standards\nWhen you become an affiliate, you may be sent projects for consideration based on your skillset and domain knowledge. While you are not required to accept and work on a project, the following is expected:\n\n\n\n\n\n\nResponse Required Within 2 Business Days!\n\n\n\n\nAcknowledgement of receipt and an initial assessment of the feasibility of the project and your availability to work on it is expected within two business days.\n\n\n\nTimely response is mandatory, even if you ultimately decline the request, to ensure that incoming client requests are handled promptly. Chronic failure to meet this communication standard will constitute an inadequate contribution to service and may result in non-renewal of your affiliation."
  },
  {
    "objectID": "Faculty_Expectations.html#mandatory-affiliation-disclosure",
    "href": "Faculty_Expectations.html#mandatory-affiliation-disclosure",
    "title": "Wildcat Data Hub Faculty Affiliate Expectations Guide",
    "section": "3.1 Mandatory Affiliation Disclosure",
    "text": "3.1 Mandatory Affiliation Disclosure\n\n\n\n\n\n\nAffiliates must proactively acknowledge the Wildcat Data Hub in all professional output and communication when the work in question utilized WDH resources, services, or personnel.\n\n\n\nAffiliates are expected to list the WDH as one of their affiliations in:\n\nCVs\nTalks\nPapers\nGrant proposals\n\nIf scholarly work is conducted using the WDH (e.g., using WDH resources or staff time), the WDH must be listed as an institutional affiliation, and any WDH staff contributors must be listed on the resulting research or scholarly output."
  },
  {
    "objectID": "Faculty_Expectations.html#authorship-and-integrity-standards",
    "href": "Faculty_Expectations.html#authorship-and-integrity-standards",
    "title": "Wildcat Data Hub Faculty Affiliate Expectations Guide",
    "section": "3.2 Authorship and Integrity Standards",
    "text": "3.2 Authorship and Integrity Standards\nAffiliates must adhere to institutional standards for research integrity.\n\nAuthorship on publication resulting from WDH collaboration should be limited to only those individuals who have contributed in a meaningful and substantive way to its intellectual content.\nPassive affiliate status alone does not guarantee authorship on WDH-produced or -supported works."
  },
  {
    "objectID": "posts/2019-12-03-fellowship-announcement.html",
    "href": "posts/2019-12-03-fellowship-announcement.html",
    "title": "Data Science and Analytics Research Fellowship",
    "section": "",
    "text": "Apply at https://www.zintellect.com/Opportunity/Details/NIH-NIAID-2020-0002\n\n\nAs a Research Participant in the NIAID Data Analytics and Research Branch (DARB), the participant will receive training and hands-on-experience in applying and managing data and portfolio analysis strategies and learning about NIH and bibliometric databases and tool development to manage programs in infectious, immunological, and allergic diseases. Appointments will be for one year, with a second-year option. The program is within NIAID DARB and the participant will have opportunity to interact and build relationships with NIAID extramural and intramural Divisions and NIAID leadership. NIAID actively encourages fellows to partake in a variety of developmental assignments during their fellowship to broaden their perspectives on NIAID and NIH’s missions, strengthen managerial and technical competencies, develop a broad understanding of NIAID’s data needs from a variety of views, and further develop leadership abilities. In addition to a stipend, Research Participants will be provided with a travel and training allowance and a health insurance allowance.\nNIAID is a $5.5 billion research organization whose mission is to conduct and support basic and applied research to better understand, treat, and ultimately prevent infectious, immunologic, and allergic diseases. The scope and complexity of NIAID operations have expanded dramatically in recent years to respond to emerging and immediate health challenges, and to meet the urgent mandates of the Executive and Legislative Branches. The planning, development, and evaluation of these independent research areas are done as part of a total integrated process, cutting across all mission areas and budgets to collaboratively identify and weigh program priorities, emerging requirements and opportunities and research constraints to meet NIAID expanding mission objectives.\nDARB provides robust data and portfolio analytical capabilities for data-driven decision making; performs short-and long-term portfolio analyses informed by analytical and data science research methodologies; The fellow will have the opportunity to learn about NIH grant and bibliometric data, evaluate robustness tools developed at DARB and learn how to carry out in-depth data analysis that informs NIAID leadership. The fellow will also have the opportunity to learn about developing tools and applications for data mining, curation, manipulation, verification, cleansing, analysis, and visualization; provides training on data and portfolio analysis tools and methodologies; consult with program and other staff to produce portfolio analyses; provide interpretations of data and portfolio analysis results; disseminate findings, tools, data, etc. as appropriate. The fellow will have the opportunity to build relationship with NIAID Office of Data Science and Emerging Technologies and interact with counterparts and leadership in the Office of Extramural Research (OER) and the Office of Portfolio Analysis (OPA), and the NIH Institutes.\nAppointments are typically made for one year and are renewable for a total of two years. Stipend rates are established and non-negotiable. Stipends are reported to the U.S. Internal Revenue Service as fellowship awards however, no federal income taxes will be withheld. Stipends are paid monthly.\n1st year stipend rate: $67,600, $74,880, or $85,020 annually (commensurate with education and experience) 2nd year stipend rate: $70,304, $77,785, or $88,421 annually (commensurate with education and experience)\n100% of health insurance premiums are covered for individuals or families, as appropriate.\nAn annual travel ($3,500) and training ($2,500) allowance is established for each participant for a total of $6,000 annually. Travel and training funds are interchangeable as necessary.\nQualifications The qualified candidate must have received a bachelor’s, master’s or doctoral degree in one of the relevant fields. Degree must have been received within five years of the appointment start date. Current students who are close to completing their degrees may apply but must have completed their degrees by the start of the fellowship.\nPreferred skills:\n\nExperience in biological research, science management, data science, bioinformatics, or other biocomputational fields\nExperience in R, Python or other data science tools\nExcellent critical thinking and analytical skills, including exceptional attention to detail\nExperience with statistical methods\nExcellent oral and written communication skills\nStrong interpersonal skills and an ability to collaborate with staff at all levels\n\nThis opportunity is available to U.S. citizens only.\nFor a full description of this opportunity and to submit your application, visit https://www.zintellect.com/Opportunity/Details/NIH-NIAID-2020-0002.\nIf you have questions, send an email to NIHprograms@orau.org. Please include the reference code for this opportunity (NIH-NIAID-2020-0002) in your email."
  },
  {
    "objectID": "posts/2019-12-03-fellowship-announcement.html#application-deadline-december-17-2019-300pm-et",
    "href": "posts/2019-12-03-fellowship-announcement.html#application-deadline-december-17-2019-300pm-et",
    "title": "Data Science and Analytics Research Fellowship",
    "section": "",
    "text": "Apply at https://www.zintellect.com/Opportunity/Details/NIH-NIAID-2020-0002\n\n\nAs a Research Participant in the NIAID Data Analytics and Research Branch (DARB), the participant will receive training and hands-on-experience in applying and managing data and portfolio analysis strategies and learning about NIH and bibliometric databases and tool development to manage programs in infectious, immunological, and allergic diseases. Appointments will be for one year, with a second-year option. The program is within NIAID DARB and the participant will have opportunity to interact and build relationships with NIAID extramural and intramural Divisions and NIAID leadership. NIAID actively encourages fellows to partake in a variety of developmental assignments during their fellowship to broaden their perspectives on NIAID and NIH’s missions, strengthen managerial and technical competencies, develop a broad understanding of NIAID’s data needs from a variety of views, and further develop leadership abilities. In addition to a stipend, Research Participants will be provided with a travel and training allowance and a health insurance allowance.\nNIAID is a $5.5 billion research organization whose mission is to conduct and support basic and applied research to better understand, treat, and ultimately prevent infectious, immunologic, and allergic diseases. The scope and complexity of NIAID operations have expanded dramatically in recent years to respond to emerging and immediate health challenges, and to meet the urgent mandates of the Executive and Legislative Branches. The planning, development, and evaluation of these independent research areas are done as part of a total integrated process, cutting across all mission areas and budgets to collaboratively identify and weigh program priorities, emerging requirements and opportunities and research constraints to meet NIAID expanding mission objectives.\nDARB provides robust data and portfolio analytical capabilities for data-driven decision making; performs short-and long-term portfolio analyses informed by analytical and data science research methodologies; The fellow will have the opportunity to learn about NIH grant and bibliometric data, evaluate robustness tools developed at DARB and learn how to carry out in-depth data analysis that informs NIAID leadership. The fellow will also have the opportunity to learn about developing tools and applications for data mining, curation, manipulation, verification, cleansing, analysis, and visualization; provides training on data and portfolio analysis tools and methodologies; consult with program and other staff to produce portfolio analyses; provide interpretations of data and portfolio analysis results; disseminate findings, tools, data, etc. as appropriate. The fellow will have the opportunity to build relationship with NIAID Office of Data Science and Emerging Technologies and interact with counterparts and leadership in the Office of Extramural Research (OER) and the Office of Portfolio Analysis (OPA), and the NIH Institutes.\nAppointments are typically made for one year and are renewable for a total of two years. Stipend rates are established and non-negotiable. Stipends are reported to the U.S. Internal Revenue Service as fellowship awards however, no federal income taxes will be withheld. Stipends are paid monthly.\n1st year stipend rate: $67,600, $74,880, or $85,020 annually (commensurate with education and experience) 2nd year stipend rate: $70,304, $77,785, or $88,421 annually (commensurate with education and experience)\n100% of health insurance premiums are covered for individuals or families, as appropriate.\nAn annual travel ($3,500) and training ($2,500) allowance is established for each participant for a total of $6,000 annually. Travel and training funds are interchangeable as necessary.\nQualifications The qualified candidate must have received a bachelor’s, master’s or doctoral degree in one of the relevant fields. Degree must have been received within five years of the appointment start date. Current students who are close to completing their degrees may apply but must have completed their degrees by the start of the fellowship.\nPreferred skills:\n\nExperience in biological research, science management, data science, bioinformatics, or other biocomputational fields\nExperience in R, Python or other data science tools\nExcellent critical thinking and analytical skills, including exceptional attention to detail\nExperience with statistical methods\nExcellent oral and written communication skills\nStrong interpersonal skills and an ability to collaborate with staff at all levels\n\nThis opportunity is available to U.S. citizens only.\nFor a full description of this opportunity and to submit your application, visit https://www.zintellect.com/Opportunity/Details/NIH-NIAID-2020-0002.\nIf you have questions, send an email to NIHprograms@orau.org. Please include the reference code for this opportunity (NIH-NIAID-2020-0002) in your email."
  },
  {
    "objectID": "posts/2022-04-04-chico-state-data-fest-2022-recap/index.html",
    "href": "posts/2022-04-04-chico-state-data-fest-2022-recap/index.html",
    "title": "Chico State Data Fest 2022 Recap",
    "section": "",
    "text": "On April 1-3rd, Chico State University hosted the ASA DataFest 2022. DataFest is an event hosted by the Chico State Data Initiative (DSI), organized by Doctor Robin Donatello. Students were presented with undisclosed data on Friday and then worked through the weekend to gain the best insights into the confidential, real-world data sets. After long nights and early mornings, teams presented their findings to the experienced panel of judges for a chance at prizes and certificates. The event is part of the university’s efforts to provide training, expand collaboration and encourage new research in the field of Data Science and Data Analytics.\nKick-off began at 5:30 p.m. on Friday, April 1st, when teams from both Sacramento State and Chico State arrived to unravel their first data sets. 29 students made up the six different teams, with majors from all across the board. This year we had representation from Engineering (6.8%), Statistics (17%), Mathematics (13.7%), Computer Science (51.7%), Natural Sciences (Biology) (3.4%), Social Sciences (3.4%) and Business Information Systems (3.4%). The contestants’ experience in programming varied greatly, with some who were very well-versed and others who were just beginners.\nBy Sunday, the teams began wrapping up their findings and preparing for presentations, which were limited to five minutes each. Our panel of judges included: Stewart He, Data Scientist at Lawrence Livermore National Lab; Monica So, Assistant Professor at Chico State University; Kevin Buffardi, Faculty; and Christine Leistner, Faculty.\nEach team displayed great teamwork and demonstrated how working together can help you in the long run. With that said, the hardwork and dedication each team showed us reflected very heavily on this year’s winners. The winning teams of this year’s DataFest were:\n\nBest Analysis: K-Wildcat\nBest Discovery: K-Wildcat\nBest Visualization: Team Money\nJudge’s Choice: Lambda\n\nAcknowledgements\nIn addition to all the data exploration that took place throughout the weekend, we would like to give a special thank you to our sponsors: Chico State Data Science Initiative, American Statistical Association, ChicostArt, Center for Entrepreneurship at Chico State University, CSU Chico College of Business, Payless Building Supply, Math Club, and Stoble Coffee Roasters. Without the help of these amazing businesses and organizations, none of this would be possible.\nLastly, we would like to take this opportunity to acknowledge everyone who took the time to help build DataFest from the ground up. Support for the Data Science Initiative at Chico State by departments, organizations, and businesses like these are what make events for students possible.\nFollowing this year’s DataFest, the DSI is already looking to plan next year’s DataFest and looks forward to exposing more students to real world data issues. If you would like to be directly involved in next year’s festivities, please contact Robin Donatello at rdonatello@csuchico.edu."
  },
  {
    "objectID": "posts/2021-02-10-swc-website-march.en.html",
    "href": "posts/2021-02-10-swc-website-march.en.html",
    "title": "Sofware Carpentry Workshop for Website Building",
    "section": "",
    "text": "This event has been postponed due to unforseen and unavoidable circumstances. We will be rescheduling this event for Summer. We are considering expanding the workshop an additional 2 days to include more lessons on R programming. Registered participants want a refund please email datascience@csuchico.edu. We apologize for the inconvenience.\n\nEver wish you had a way to showcase your work inside and out of the classroom? A place to share materials with students, or to blog about current research and developments in your field?\nOn March 6th & 13th, 2021 the CSU Math Council is sponsoring a virtual professional development workshop for Mathematics & Statistics faculty across the CSU to learn how to build a professional website using Data Science tools such as GitHub and R Markdown.\nWe will be using curated lesson materials from The Carpentries, a fiscally sponsored project of Community Initiatives. They teach skills that are immediately useful for researchers, using lessons and datasets that allow researchers to quickly apply what they’ve learned to their own work. However, this will not be a standard Software Carpentry workshop, we have purposefully chosen selected parts of Carpentry lessons to provide the necessary building blocks for a successful website. The curriculum will include:\n\nUsing the Unix Shell\nVersion control with git\nVery basic introduction to R (no real working with data)\nCreating reproducible documents using Markdown.\nUsing all those tools to create a website\n\nThe target audience is learners who have little to no prior computational experience, and the instructors put a priority on creating a friendly environment to empower faculty to learn new tools to showcase their accomplishments.\nSpace is limited and it will likely fill quickly. Here is a link to the workshop webpage https://csucdsi.github.io/2021-03-06-csumath/ for more information and to sign up.\nQuestions? Send an email to datascience@csuchico.edu\nWe hope to see you in March!"
  },
  {
    "objectID": "posts/2021-05-12-dasg.html",
    "href": "posts/2021-05-12-dasg.html",
    "title": "New Class!",
    "section": "",
    "text": "Data is not neutral, nor are the algorithms that control how the data that governs our lives are used. Interpretations and recommendations made using data are subjective. This course introduces students how to start harnessing the power of data to intelligently cope with the requirements of citizenship, employment, and family to be prepared for a healthy, happy and productive life. In this class students will practice collecting and wrangling data into a usable form, visualizing large data sets to discover patterns, representing data in a meaningful way, exploring varying interpretations of the data and results, and discussing potentials for misuse and abuse. This course promotes critical reflection on the ethical, social, cultural, and political dimensions of data as well as providing direct hands on experience with both spreadsheets, and the Data Science language, R.\n\nOpen to current CSU, Chico students only.\nNo programming or data experience necessary!\nCarries GE Credit."
  },
  {
    "objectID": "posts/2018-03-26-datafest.html",
    "href": "posts/2018-03-26-datafest.html",
    "title": "DataFest Registration now open!",
    "section": "",
    "text": "logo"
  },
  {
    "objectID": "posts/2018-03-26-datafest.html#view-the-event-website-for-more-information.",
    "href": "posts/2018-03-26-datafest.html#view-the-event-website-for-more-information.",
    "title": "DataFest Registration now open!",
    "section": "View the Event Website for more information.",
    "text": "View the Event Website for more information."
  },
  {
    "objectID": "posts/2018-04-10-intro_tableau_public_announce.html",
    "href": "posts/2018-04-10-intro_tableau_public_announce.html",
    "title": "Workshop: A Brief Introduction to Tableau Public",
    "section": "",
    "text": "April is Data Fest Prep month! Hone your skills in preparation for this exciting data hackathon event!"
  },
  {
    "objectID": "posts/2018-04-10-intro_tableau_public_announce.html#description",
    "href": "posts/2018-04-10-intro_tableau_public_announce.html#description",
    "title": "Workshop: A Brief Introduction to Tableau Public",
    "section": "Description",
    "text": "Description\nThis is a hands-on mini-workshop, so bring your laptop if you want to “play” … The why, what, and how of getting into Tableau is presented, including an overview of the Tableau product line. After this quick intro, participants will step through the process of downloading and installing the Tableau Public app on their machine, download some sample data, and will build a couple of dashboards. Suggestions for next steps will be provided so participants can explore Tableau further."
  },
  {
    "objectID": "posts/2018-04-10-intro_tableau_public_announce.html#rsvp-here-for-this-and-other-upcoming-dsi-workshops.",
    "href": "posts/2018-04-10-intro_tableau_public_announce.html#rsvp-here-for-this-and-other-upcoming-dsi-workshops.",
    "title": "Workshop: A Brief Introduction to Tableau Public",
    "section": "RSVP here for this and other upcoming DSI workshops.",
    "text": "RSVP here for this and other upcoming DSI workshops."
  },
  {
    "objectID": "posts/2018-10-01-dsi-workshops-community-coding.html",
    "href": "posts/2018-10-01-dsi-workshops-community-coding.html",
    "title": "Fall hours set for DSI Workshops & Community Coding",
    "section": "",
    "text": "The Data Science Initative workshops and Community Coding sessions are in full swing for Fall! We secured the same time and place as last semester.\n\nTuesday & Thursday 2-3:50 Meriam Library (MLIB) 442 (4th floor, directly left out of elevators).\n\nWorkshops & Seminars\n\nWe will be reviewing suggestions from Spring and planning talks and workshops at all levels.\nDo you have a request for a specialized workshop topic, or want to share your research or project? Contact us to start the discussion.\n\nCommunity Coding Sessions\n\nOn days when no talks or workshops are scheduled the room will be open for Community Coding.\nThis open work session provides a helpful and friendly working environment where you can code, ask questions or discuss ideas related to R, Python, Data Science, or more generally data visualization and analysis.\nWe invite you to bring your Data Science and coding questions, data, and projects. Just need a place to work on stats/CS homework? You’re invited too!\nOn most days Edward Roualdes (STAT) or Robin Donatello (STAT) will be present. Other members of the DSI may drop in on occasion.\n\n\n\n\nlogo"
  },
  {
    "objectID": "posts/2018-01-29-dsi-workshops-community-coding.html",
    "href": "posts/2018-01-29-dsi-workshops-community-coding.html",
    "title": "Spring hours set for DSI Workshops & Community Coding",
    "section": "",
    "text": "The Data Science Initative at Chico State and the Chico R Users Group are hosting bi-weekly work sessions and tutorial sessions for the entire campus and Chico community.\n\nSpring 18: Tuesday & Thursday 2-3:50 Meriam Library (MLIB) 442 (4th floor, directly left out of elevators).\n\nWorkshops\n\nWe will be planning a few introductory workshops on topics such as R, Python, Git\nAnd a few advanced workshops on creating academic webpages with R Markdown, and an introduction to Bayesian Methods for statistical analysis.\nDo you have a request for a specialized workshop topic? Contact us to start the discussion.\n\nCommunity Coding Sessions\n\nOn days when no talks or workshops are scheduled the room will be open for Community Coding.\nThis open work session provides a helpful and friendly working environment where you can code, ask questions or discuss ideas related to R, Python, Data Science, or more generally data visualization and analysis.\nWe invite you to bring your Data Science and coding questions, data, and projects. Just need a place to work on stats/CS homework? You’re invited too!\nOn most days Robin Donatello (STAT) or Edward Roualdes (STAT) will be present. Other members of the DSI may drop in on occasion.\n\n\n\n\nlogo"
  },
  {
    "objectID": "posts/2024-12-06-swc_workshop-2024/index.en.html",
    "href": "posts/2024-12-06-swc_workshop-2024/index.en.html",
    "title": "Workshop Reproducible Research using R",
    "section": "",
    "text": "The CSU Carpentry Collective is offering a low-cost, three half-day Software Carpentry workshop on programming in R for anyone affiliated with the CSU system on January 13-15, 2025.\nThe Carpentries is a fiscally sponsored project of Community Initiatives. They teach skills that are immediately useful for researchers, using lessons and datasets that allow researchers to quickly apply what they have learned to their own work.\nThe curriculum will cover topics such as data manipulation, creating publication-quality graphics, and project management using RStudio. Participants who complete all three days will receive a certificate of completion and understand the fundamentals of R.\nThe target audience is anyone from learners who have little to no prior computational experience to those with experience and just want a bit of a refresher, and the instructors put a priority on creating a friendly environment to empower researchers and enable data-driven discovery. Even those with some experience will benefit, as the goal is to teach not only how to do analyses, but how to manage the process to make it as automated and reproducible as possible.\nHere is a link to the workshop webpage https://project-da-fanh.github.io/2025-01-13-CSU-online/ for more information and a link to sign up. Seats are $25 for faculty/staff and $10 for students and space is limited.\nQuestions? Contact fanh.analytics@gmail.com\nWe hope to see you at the workshop!\nThis workshop is supported by the Chico State Data Science Initiative, CSUSB DAWG, and Project DA-FANH [grant no. 2021-77040-34880] from the USDA National Institute of Food and Agriculture. Project DA-FANH aims to foster an active, inclusive, and diverse community of learners and instructors that promote and model the importance of software and data in the Food, Agriculture, Natural Resources and Human Sciences."
  },
  {
    "objectID": "posts/2025-01-31-Math500-Seminar-Ricardo-Aguilar/index.html",
    "href": "posts/2025-01-31-Math500-Seminar-Ricardo-Aguilar/index.html",
    "title": "Introduction to Causality – Ricardo Aguilar",
    "section": "",
    "text": "Presented by Ricardo Aguilar\nJoin us for an engaging seminar exploring the foundations of causal inference — a powerful framework for identifying what truly causes what in data.\nThis talk will introduce key concepts in causal reasoning, blending classical statistical thinking with modern machine learning approaches.\n\n\n\n\nUnderstanding Directed Acyclic Graphs (DAGs) as tools for representing cause-and-effect\n\nThe role of counterfactuals and potential outcomes in causal analysis\n\nKey assumptions: exchangeability, positivity, and consistency\n\nApproaches to causal structure discovery (test-based & score-based methods)\n\nA conceptual walkthrough of Inverse Probability Treatment Weighting (IPTW) and its practical challenges\n\n\n\n\n\n📅 Date: January 31, 2025\n📍 Location: Holt Hall 291\n🗣️ Speaker: Ricardo Aguilar\n\nWhether you’re working in data science, public health, economics, or social science, this seminar will help sharpen how you approach causal questions in your field.\nAll majors welcome — no prior causal inference experience required!"
  },
  {
    "objectID": "posts/2025-01-31-Math500-Seminar-Ricardo-Aguilar/index.html#upcoming-seminar-introduction-to-causality",
    "href": "posts/2025-01-31-Math500-Seminar-Ricardo-Aguilar/index.html#upcoming-seminar-introduction-to-causality",
    "title": "Introduction to Causality – Ricardo Aguilar",
    "section": "",
    "text": "Presented by Ricardo Aguilar\nJoin us for an engaging seminar exploring the foundations of causal inference — a powerful framework for identifying what truly causes what in data.\nThis talk will introduce key concepts in causal reasoning, blending classical statistical thinking with modern machine learning approaches.\n\n\n\n\nUnderstanding Directed Acyclic Graphs (DAGs) as tools for representing cause-and-effect\n\nThe role of counterfactuals and potential outcomes in causal analysis\n\nKey assumptions: exchangeability, positivity, and consistency\n\nApproaches to causal structure discovery (test-based & score-based methods)\n\nA conceptual walkthrough of Inverse Probability Treatment Weighting (IPTW) and its practical challenges\n\n\n\n\n\n📅 Date: January 31, 2025\n📍 Location: Holt Hall 291\n🗣️ Speaker: Ricardo Aguilar\n\nWhether you’re working in data science, public health, economics, or social science, this seminar will help sharpen how you approach causal questions in your field.\nAll majors welcome — no prior causal inference experience required!"
  },
  {
    "objectID": "posts/2019-03-25-dsi-seminar-kevin-buffardi.html",
    "href": "posts/2019-03-25-dsi-seminar-kevin-buffardi.html",
    "title": "DSI Seminar 3/28: InfoVis: Communicating Data Visually",
    "section": "",
    "text": "Presenter: Kevin Buffardi, Associate Professor of Computer Science\nDate: Thursday March 28th, 2019\nTime: 2-2:50 pm\nLocation: Tehama 116\nRSVP: http://goo.gl/forms/BnjV0y5zoz09tUU83\n\n\n\nInformation is plentiful, but making sense of it is not always so easy. Graphical representation of data can help us discover new insights and communicate hidden meaning in complex data. In this talk, Dr. Kevin Buffardi (computer science) will introduce principles and challenges in visualizing information for better human understanding. Examples of good and bad practices will illustrate how to (and how NOT to) communicate effectively through Information Visualization. No prior experience in statistics or computer science is necessary – all audiences welcome!"
  },
  {
    "objectID": "posts/2019-03-25-dsi-seminar-kevin-buffardi.html#description",
    "href": "posts/2019-03-25-dsi-seminar-kevin-buffardi.html#description",
    "title": "DSI Seminar 3/28: InfoVis: Communicating Data Visually",
    "section": "",
    "text": "Information is plentiful, but making sense of it is not always so easy. Graphical representation of data can help us discover new insights and communicate hidden meaning in complex data. In this talk, Dr. Kevin Buffardi (computer science) will introduce principles and challenges in visualizing information for better human understanding. Examples of good and bad practices will illustrate how to (and how NOT to) communicate effectively through Information Visualization. No prior experience in statistics or computer science is necessary – all audiences welcome!"
  },
  {
    "objectID": "posts/2020-12-11-spring-internship-opportunity.en.html",
    "href": "posts/2020-12-11-spring-internship-opportunity.en.html",
    "title": "Spring internship opportunity",
    "section": "",
    "text": "The Data Science Initiative is partnering with the Center for Healthy Communities to offer a virtual internship experience this Spring. This flexible, 3 unit internship is focused on the management, analysis and reporting of data through a variety of projects relating to basic needs and our community’s health.\nThis is a great opportunity for students who need to complete the Capstone for the Data Science Certificate or students who need additional units to round out their schedules.\nDeadline to submit the on-line application is December 31th.\nFor additional details, please view the Virtual Internship Job Description.\nPlease email datascience@csuchico.edu with any questions."
  },
  {
    "objectID": "posts/2018-02-21-asa-datafest-2018.html",
    "href": "posts/2018-02-21-asa-datafest-2018.html",
    "title": "Save the Date! April 27-29 ASA DataFest 2018 @ CSUC",
    "section": "",
    "text": "logo\n\n\nThis year the CSU Chico Data Science Initiative will be hosting an ASA DataFest. This will be the first year Chico State has participated.\nASA DataFest is a data hackathon for undergraduate students, sponsored by the American Statistical Association and founded at UCLA, in 2011. A data analysis problem is presented in the form of a dataset and an associated challenge. Teams of students get a dataset on Friday afternoon and work on the problem until Sunday afternoon where they present their findings. After two days of intense data wrangling, analysis, and presentation design, each team is allowed a few minutes and no more than two slides to impress a panel of judges. Prizes are given for Best in Show, Best Visualization, and Best Use of External Data.\nUndergraduates from all majors are welcome. Some of the most diverse teams have been the most successful.\nA key feature of ASA DataFest is that it brings together the data science community. Undergraduate students do the work, but they are assisted by roving consultants who are graduate students, faculty, and industry professionals.\nLearn more about this national event at the event website\n\n\nRegister Here Now!\n\n\n\n\nlogo"
  },
  {
    "objectID": "posts/2018-07-18-storm-events.html",
    "href": "posts/2018-07-18-storm-events.html",
    "title": "Measuring Variation in the Empirical Storm Season Over Time",
    "section": "",
    "text": "This blog post attempts an analysis of the annual variability of dates on which storms formed during the years 1950 to 2016. Throughout, the word storm will refer to named tropical or subtropical cyclones in the Atlantic Ocean. The inspiration of this analysis came from a CSU, Chico campus seminar.\nDuring the Fall semester of 2017, CSU, Chico’s Dr. Ann Bykerk-Kauffman gave one of three talks at the Department of Geological and Environmental Sciences seminar titled 2017 Hurricane Talk. Part of Dr. Bykerk-Kauffman’s presentation included data from the National Oceanic and Atmospheric Administration’s National Hurricane Center’s (NHC) Data Archive: https://www.nhc.noaa.gov/data/#hurdat [Landsea:2013]. After her talk, Dr. David M. Hassenzahl, Dean of the College of Natural Sciences, asked a great question, which I’ll try to paraphrase: Is the variation of the empirical storm season changing over time?\nOne possible way to interpret the phrase variation of the empirical storm season goes like this. The official storm season is June 01 to November 30. The official storms season proves useful as a contrast to an empirical storm season. The word empirical refers to the actual dates for which the named storms in any given year form. Just because we define a storm season, does not mean all the storms form within the official storm season. Some years contain some storms outside the official storm season, and some years contain all storms within the official storm season – as we’ll see later, no year in our data set has all storms outside of the official storm season. Since there is not a direct correspondence between the official storm season and the empirical storm season, it’s useful to separate these two phrases. Last, the word variation describes the average distance (measured in days) from the middle of the empirical storm season.\nThere are of course other ways to measure the variation of the empirical storm season. This blog post attempts to quantify the annual variation of the empirical storm season in three different ways. The first attempt follows the logic in the last paragraph. The second attempt defines a percentage of storms that form outside of the official storm season, relative to the total number of storms in each year. The last attempt hypothesizes a probability distribution that produces storms throughout the year, and then asks if this distribution of storms changes over time.\nThe rest of this post proceeds as follows. Section 3 discusses some related research and briefly compares this analysis to previous efforts. Section 4 walks through the data preparation necessary for our analyses. Section 5 contains the bulk of the analysis, for which multiple measurements of variation of the storm season are considered as a time series. Here, we focus on Atlantic storms from the years 1950 to 2016. However, no qualitative, and only minor quantitative, differences are found by analyzing Pacific Ocean storms simiarly. The post is concluded in Section 6, and Sections 7 and 8 offer my appreciation to those who directly and indirectly made this analysis possible."
  },
  {
    "objectID": "posts/2018-07-18-storm-events.html#has-the-variation-in-the-empirical-storm-season-changed-over-time",
    "href": "posts/2018-07-18-storm-events.html#has-the-variation-in-the-empirical-storm-season-changed-over-time",
    "title": "Measuring Variation in the Empirical Storm Season Over Time",
    "section": "Has the variation in the empirical storm season changed over time?",
    "text": "Has the variation in the empirical storm season changed over time?\nIn an effort to answer Dean Hassenzahl’s question, we attempt to measure the variation of the empirical storm season year over year. To measure such variation, we will use the median absolute deviation (MAD) statistic. The MAD statistic is an estimator of the population standard deviation σ, which is based on the median instead of the mean making it more robust to potential outliers.\nTo measure the variation of the emprical storm season over time, first consider a year \\(Y\\). In year \\(Y\\), there will be a handful of storms that occur at different times. Recall, we converted dates to numbers as per the discussion above in Section Data Preparation. Define the median storm date as the date corresponding to the median of the numbers that represent the storms’ dates.\ndf['median'] = df.groupby('year')['num_dates'].transform(lambda x: x.median())\ndf['median_date'] = mdates.num2date(df['median'])\nThe plot below depicts this visually for the year 2005. The histogram of storms in 2005 appears in blue, as do the vertical ticks representing each storm. The median storm date appears as the taller, red tick. \nidx_2005 = df['year'] == 2005\nfig, ax = plt.subplots(1, 1, figsize=(8, 5))\nax.cla()\nbp.histogram(df['num_dates'].loc[idx_2005], bins=365//30)\nbp.rug(df['num_dates'].loc[idx_2005].values, markersize=20)\nbp.rug(df['median'].loc[idx_2005].values[:1], markersize=50, color='tab:red')\nplt.xlabel('Month', fontsize=20)\nplt.ylabel('Density', fontsize=20)      \nplt.title('Density of Storms in 2005', fontsize=20)\nax.set_xlim([datetime.datetime(2005, 1, 1), \n             datetime.datetime(2005, 12, 1)])  \nax.xaxis.set_major_locator(mdates.AutoDateLocator())                                 \nax.xaxis.set_major_formatter(mdates.DateFormatter('%m')) \nplt.tight_layout()\n\nBy this definition, across all the years, the median storm dates generaly fall in August or September. The following table depicts the counts of the median storm date within each numbered month, over all the years for which we have data.\ndf.drop_duplicates('year', inplace=False)['median_date'].dt.month.value_counts().sort_index()\n7      1\n8     23\n9     42\n10     1\nName: median_date, dtype: int64\nThe median storm date strictly measures an average storm date within year \\(Y\\). Variation on the other hand measures average distance from the median storm date. We measure distance from the median storm date in days. Since some storms form before the median storm date and some storms after, we take the absolute value of the distance of each storm from the median storm date. Our MAD estimator is the median of the absolute values of these distances. The last step scales our MAD estimator by \\(\\frac{1}{\\Phi^{-1}(0.75)} \\approx 1.4826\\), in a fairly standard assumption of normal data. In the end, we have MAD estimates of the variation of the empirical storm season for each year in our data set.\nTo help visualize this calculation, consider the plot above. For each storm (blue ticks), count the days between each storm and the median storm date (red tick), disregarding any potential negative signs. From these counts, calculate the median and then scale it by \\(1.4826\\). This calcuation is done for each year, and we refer to the collection of yearly statistics as the MAD estimates.\ndf['mad'] = df.apply(lambda x: np.abs((x['num_dates'] - x['median'])), axis=1)\nsdf = (df[['year', 'mad']].groupby('year', as_index=False)\n            .aggregate(lambda x: 1.4826*np.median(x)))\nA plot of the MAD estimates across time appears below. A non-zero slope would indicate a change in the variation of the empirical storm season across time. Hence, to answer Dean Hassenzahl’s question, we seek to quantify statistically the slope of these data.\nA standard first attempt would fit simple linear regression to these data. However, fitting linear regression to these data strictly ignores any possible correlation in storm seasons across time. In this scenario, each year is treated as independent. Recall, both Kossin and Kim treated their data as independent across time.\nTreating each year as independent can be suspicious and can lead to over confident conclusions. We are more interested in the semilocal linear trend model mentioned previously. As a comparison, we fit linear regression and the semilocal linear trend model.\nThe plot below depicts the MAD estimates of the storm season by year in blue, with the estimate from linear regression overlayed in red. The subtle negative slope indicates that, if anything, the variation of the emprical storm season is decreasing in time. The negative sign of this slope agrees qualitatively with Kim, but disagrees with Kossin and Karloski. Though we remind the reader that we are measureing the variation of the empirical storm season differently than Kossin and Karloski. Nevertheless, here we are most interested in the uncertainty of this slope estimate.\nreg = sm.OLS(sdf['mad'], sm.tools.add_constant(sdf['year'])).fit()\n\nfig, ax = plt.subplots(1, 1, figsize=(8, 5))\nax.cla()\nbp.curve(sdf['year'], sdf['mad'], alpha=0.5)\nbp.line(sdf['year'], reg.fittedvalues, color='tab:red')\nplt.xlabel('Year', fontsize=20)\nplt.ylabel('MAD', fontsize=20)\nplt.title('MAD of Storm Season by Year', fontsize=20)\nplt.tight_layout()\n\nThe plot above looks reasonable and the slope point estimate is reasonable given the uncertainty seen in that point estimate. We should not focus on the p-value, rather we should focus on the standard error in the estimated coefficient year.\nreg.summary()\n     &lt;td&gt;mad&lt;/td&gt;       &lt;th&gt;  R-squared:         &lt;/th&gt; &lt;td&gt;   0.000&lt;/td&gt;             &lt;td&gt;OLS&lt;/td&gt;       &lt;th&gt;  Adj. R-squared:    &lt;/th&gt; &lt;td&gt;  -0.015&lt;/td&gt;       &lt;td&gt;Least Squares&lt;/td&gt;  &lt;th&gt;  F-statistic:       &lt;/th&gt; &lt;td&gt;0.009973&lt;/td&gt;       &lt;td&gt;Wed, 04 Jul 2018&lt;/td&gt; &lt;th&gt;  Prob (F-statistic):&lt;/th&gt;  &lt;td&gt; 0.921&lt;/td&gt;            &lt;td&gt;17:13:23&lt;/td&gt;     &lt;th&gt;  Log-Likelihood:    &lt;/th&gt; &lt;td&gt; -251.32&lt;/td&gt;&lt;td&gt;    67&lt;/td&gt;      &lt;th&gt;  AIC:               &lt;/th&gt; &lt;td&gt;   506.6&lt;/td&gt;    &lt;td&gt;    65&lt;/td&gt;      &lt;th&gt;  BIC:               &lt;/th&gt; &lt;td&gt;   511.1&lt;/td&gt;        &lt;td&gt;     1&lt;/td&gt;      &lt;th&gt;                     &lt;/th&gt;     &lt;td&gt; &lt;/td&gt;   &lt;td&gt;nonrobust&lt;/td&gt;    &lt;th&gt;                     &lt;/th&gt;     &lt;td&gt; &lt;/td&gt;   \n\nOLS Regression Results\n\n\n\nDep. Variable:\n\n\n\n\n\nModel:\n\n\n\n\n\nMethod:\n\n\n\n\n\nDate:\n\n\n\n\n\nTime:\n\n\n\n\n\nNo. Observations:\n\n\n\n\n\nDf Residuals:\n\n\n\n\n\nDf Model:\n\n\n\n\n\nCovariance Type:\n\n\n\n\n\n\n\n\n\ncoef\n\n\nstd err\n\n\nt\n\n\nP&gt;|t|\n\n\n[0.025]\n\n\n\n\nconst\n\n\n47.9342\n\n\n131.006\n\n\n0.366\n\n\n0.716\n\n\n-213.703\n\n\n309.571\n\n\n\n\nyear\n\n\n-0.0066\n\n\n0.066\n\n\n-0.100\n\n\n0.921\n\n\n-0.139\n\n\n0.125\n\n\n\n &lt;td&gt; 1.829&lt;/td&gt; &lt;th&gt;  Durbin-Watson:     &lt;/th&gt; &lt;td&gt;   2.333&lt;/td&gt;    &lt;td&gt; 0.322&lt;/td&gt; &lt;th&gt;  Prob(JB):          &lt;/th&gt; &lt;td&gt;   0.410&lt;/td&gt;&lt;td&gt; 2.527&lt;/td&gt; &lt;th&gt;  Cond. No.          &lt;/th&gt; &lt;td&gt;2.03e+05&lt;/td&gt;\n\n\nOmnibus:\n\n\n\n\n\nProb(Omnibus):\n\n\n0.401\n\n\nJarque-Bera (JB):\n\n\n1.784\n\n\n\n\nSkew:\n\n\n\n\n\nKurtosis:\n\n\n\n\nThe above regression output provides us a number of important summary statistics. The slope is estimated to be \\(-0.007\\) with a standard error one order of magnitude larger. This indicates low confidence in the slope estimate.\nThe Durbin-Watson statistic is greater than 2, possibly indicating negative autocorrelation in these data, but there’s likely to be high uncertainty in this statistic as well.\nTo build upon this simple regression model, we will allow possible autocorrelation in the data. We next introduce the semilocal linear trend model.\n\nState Space Model\nA more sophisticated model for these data, such that we do not strictly rule out a correlation of the storm seasons across time, is the following Bayesian structural time series model. The semilocal linear trend model describes the time series of interest \\(y_{t}\\) as\n\\[\n\\begin{aligned}\ny\\_t & = \\mu\\_t + \\epsilon\\_t \\newline\n\\mu\\_{t+1} & = \\mu\\_t + \\nu\\_t + \\gamma\\_t \\newline\n\\nu\\_{t+1} & = \\eta + \\phi(\\nu\\_t - \\eta) + \\zeta\\_t \\newline\n\\epsilon\\_t & \\sim \\mathbb{N}(0, \\sigma\\_y^2) \\newline\n\\gamma\\_t & \\sim \\mathbb{N}(0, \\sigma\\_{\\mu}^2) \\newline\n\\zeta\\_t & \\sim \\mathbb{N}(0, \\sigma\\_{\\nu}^2)\n\\end{aligned}\n\\]\nwhere \\(\\epsilon_t, \\gamma_t\\), and \\(\\zeta_t\\) are independent. The notation \\(\\mathbb{N}(0, \\sigma^2)\\) stands for a normal random variable with mean \\(0\\) and variance \\(\\sigma^2\\).\nThe variable \\(\\eta\\), the long run slope in the time series, is of most interest. Specifically, we allow deviations from the slope, \\(\\nu\\_{t}\\), so long as the deviations \\(\\nu_{t}\\) tend to revert back to the long run slope. For more details on this model, consult Time Series Analysis by State Space Methods and the R package bsts’s help page on their semilocal linear trend model or their blog post about the semilocal linear trend model.\nHere, the time series of interest \\(y_t\\) is the yearly MAD estimates of variation of the empirical storm season. Since this model will better handle possible correlations across time in the MAD estimates of variation, we will have an appropriate estimate of the variation in the long run slope.\nIn Stan, we write this model as follows. The priors are discussed in the next subsection.\nlocal_linear = requests.get('https://raw.githubusercontent.com/roualdes/stormevents/master/semilocal_linear.stan').text\nprint(local_linear)\ndata {\n  int &lt;lower=1&gt; T;\n  vector[T] x;\n  vector[T] y;\n}\ntransformed data {\n  real sd_y = sd(y);\n  real sd_x = sd(x);\n}\nparameters {\n  real&lt;lower=0&gt; sigma_y;\n  vector[T] gamma;\n  real&lt;lower=0&gt; sigma_gamma;\n  vector[T] zeta;\n  real&lt;lower=0&gt; sigma_zeta;\n  real eta;\n  real&lt;lower=-1, upper=1&gt; phi;\n}\ntransformed parameters {\n  vector[T] mu;\n  vector[T] nu;\n\n  mu[1] = y[1] + sigma_gamma * gamma[1];\n  nu[1] = zeta[1];\n  for (t in 2:T) {\n    mu[t] = mu[t-1] + nu[t-1] + sigma_gamma * gamma[t];\n    nu[t] = eta + phi * (nu[t-1] - eta) + sigma_zeta * zeta[t];\n  }\n}\nmodel {\n  // likelihood\n  y ~ normal(mu, sigma_y);\n\n  // priors\n  sigma_y ~ exponential(1 / sd_y);\n  gamma ~ normal(0, 1);\n  sigma_gamma ~ gamma(2, 1 / sd_y);\n  zeta ~ normal(0, 1);\n  sigma_zeta ~ gamma(2, 1 / sd_y);\n  eta ~ student_t(3, 0, sd_y / sd_x);\n  phi ~ normal(0, 0.5);\n}\ngenerated quantities {\n  vector[T] y_pred;\n  for (t in 1:T)\n    y_pred[t] = normal_rng(mu[t], sigma_y);\n}\nIn order to fit this model to the yearly variation in the storm season, we need to compile the above Stan program.\nstmod = pystan.StanModel(model_code=local_linear)\nINFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_c5a67a1a28bbc98cedc1cecc2429214e NOW.\n\nModel Priors\nThe semilocal linear trend model above is fit as a Bayesian model, hence there are priors are on all parameters. An effort has been made such that all priors are weakly informative. We tried to follow a combination of the guidelines established by the Stan community and the default priors for rstanarm [Stan-Development-Team:2016].\nSpecifically, the parameters \\(\\sigma\\_y, \\sigma\\_{\\gamma}, \\sigma\\_{\\zeta}, \\eta\\), and \\(\\phi\\) have priors. Let \\(y = (y_1, \\ldots, y_T)'\\) denote the observations of interest and \\(x\\) be the x-axis values along which the observations \\(y\\) are observed.\n\\[\n\\begin{align}\n\\sigma\\_y & \\sim \\text{Exponential}(1 / \\text{sd}(y) ) \\newline\n\\sigma\\_{\\gamma} & \\sim \\Gamma(2, 1 / \\text{sd}(y) ) \\newline\n\\sigma\\_{\\zeta} & \\sim \\Gamma(2, 1 / \\text{sd}(y) ) \\newline\n\\eta & \\sim \\mathbb{t}\\_3(0, \\text{sd}(y) / \\text{sd}(x) ) \\newline\n\\phi & \\sim \\mathbb{N}(0, 0.5)\n\\end{align}\n\\]\nThe prior on \\(\\sigma_y\\) attempts to match the scale of the standard deviation of the observations \\(y\\) by scaling an \\(\\text{Exponential(1)}\\) distribution appropriately. The scale parameters of \\(\\gamma\\) and \\(\\zeta\\) are given boundary avoiding priors and are scaled the same as \\(\\sigma_y\\). The prior on \\(\\eta\\) is treated as a regression coefficient in a multiple regression model and thus has a t-distribution on it with degrees of freedom that allow for as wide a distribution as possible with a finite variance. Since \\(\\eta\\) is a slope parameter it is given the ratio of standard deviations of \\(y\\) and \\(x\\) to match the scale of a simple linear regression slope of \\(y\\) on \\(x\\). The prior on \\(\\phi\\) attempts to weakly inform \\(\\phi\\) towards 0 with a standard deviation of 0.5. This leaves room for the data to insist upon a posterior distribution on \\(\\phi\\) to be near the extremes \\(-1\\) or \\(1\\).\nThe above model is fit with Stan, and random samples from the joint posterior distribution over the model parameters are extracted. We next evaluate the fit of the model and discuss the interpretation of the model in the context of the data.\nsdata = {                                                                            \n    'T': sdf.shape[0], \n    'x': np.arange(sdf.shape[0]),\n    'y': sdf['mad'].values.ravel()\n}\nstfit = stmod.sampling(data=sdata,\n                      control={'adapt_delta': .99})                                                                                                                                    \nposterior = stfit.extract()  \n/Users/ez/py3/lib/python3.6/site-packages/pystan/misc.py:399: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  elif np.issubdtype(np.asarray(v).dtype, float):\nStan models, like many other sophisticated, statistical models, are susceptible to fitting problems. The interested reader may refer to Section 34 of the Stan reference manual for further details. For now, the checks below help assure us that this model applied to these data offer little to be concerned about.\nstan_utility.check_treedepth(stfit)\nstan_utility.check_energy(stfit)\nstan_utility.check_div(stfit)\nstan_utility.check_rhat(stfit)\nstan_utility.check_n_eff(stfit)\n0 of 4000 iterations saturated the maximum tree depth of 10 (0.0%)\nE-BFMI indicated no pathological behavior\n0.0 of 4000 iterations ended with a divergence (0.0%)\nRhat looks reasonable for all parameters\nn_eff / iter looks reasonable for all parameters\nThe plot below superimposes our fitted model over the MAD estimates of the yearly variation of the empirical storm season.\nfig, ax = plt.subplots(1, 1, figsize=(8, 5))\nax.cla()                                                                         \nbp.curve(sdf['year'], sdf['mad'], alpha=0.5)                                                   \nbp.curve(sdf['year'], posterior['y_pred'].mean(0), color='tab:red')                  \nplt.ylabel('MAD', fontsize=20)                                                              \nplt.xlabel('Year', fontsize=20)\nplt.title('MAD of Storm Season by Year', fontsize=20)\nplt.tight_layout()\n\nThe variable \\(\\eta\\) defines the long run slope of the variation of the MAD estimates. The point estimate of this model is similar to the point estimate from simple linear regression. Here, however, we have an accurate estimate of the variation of the long run slope.\nThe median of the posterior distrbution of the long run slope, \\(\\eta\\), from the semilocal linear trend model is \\(.03\\). Below, \\(80\\)% and \\(95\\)% credible intervals provide estimates of error of \\(\\eta\\). The density below, with \\(2.5, 10, 50, 90\\), and \\(97.5\\) percentiles drawn as short, blue ticks, depicts the posterior distribution of \\(\\eta\\).\nWe find evidence of a slight postive slope in MAD estimates across time. The semilocal linear trend model shows that there is more noise in the estimate of slope than does simple linear regression. With such high uncertainty, there is little evidence that the variation in the empirical storm season is getting significantly longer.\neta_percentiles = np.percentile(posterior['eta'], [2.5, 10, 50, 90, 97.5])\nprint(\"Linear regression slope estimate: {}\".format(reg.params[1]))\nprint(eta_percentiles)\n\nfig, ax = plt.subplots(1, 1, figsize=(8, 5))\nax.cla()  \nbp.density(posterior['eta'])\nbp.rug(eta_percentiles)\nplt.ylabel('Density', fontsize=20)\nplt.title('Posterior Distribution of $\\eta$', fontsize=20)\nplt.xlabel('$\\eta$', fontsize=20)\nplt.tight_layout()\nLinear regression slope estimate: -0.006597090749461623\n[-0.58850735 -0.33643296  0.0261598   0.35216475  0.58740378]\n\nIn short, we have some evidence that the variation of the empirical storm season is not changing in time.\nNonetheless, there are other ways to address the idea of Dr. Hassenzahl’s question. Next, we investigate whether or not the proportion of storms occuring outside of the official storm season is changing in time."
  },
  {
    "objectID": "posts/2018-07-18-storm-events.html#is-the-annual-percentage-of-storms-outside-official-storm-season-changing",
    "href": "posts/2018-07-18-storm-events.html#is-the-annual-percentage-of-storms-outside-official-storm-season-changing",
    "title": "Measuring Variation in the Empirical Storm Season Over Time",
    "section": "Is the Annual percentage of storms outside official storm season changing?",
    "text": "Is the Annual percentage of storms outside official storm season changing?\nThe official storm season is between June 01 and November 30. In some years, all the storms form within the official storm season. In other years, there are a few storms that form outside the official storm season. Next, we consider the yearly percentage of storms that form outside of the official storm season. This percentage is calculated for each year as follows. Divide the number of storms that form outside the official storm season in a given year by the number of named storms that formed in that year and then multiply by 100. If this yearly percentage were to trend up or down over time, we might believe that the variation of the empirical storm season were changing.\nFirst, we calculate the percentage of storms forming outside of the official storm season for each year.\ndef outside_SS(df):\n    y = df['year'].values[0]\n    early = np.sum(df['date'] &lt; datetime.datetime(y, 6, 1))\n    late = np.sum(df['date'] &gt; datetime.datetime(y, 10, 30))\n    return 100 * (early + late) / df['year'].shape[0]\n\nsdf['prop'] = df.groupby('year', as_index=False).apply(outside_SS)\nPlotting these percentages over time shows that there are plenty of years where 0 storms formed outside of the official storm season. In no years were all the storms outside of the official storm season.\nreg = sm.OLS(sdf['prop'], sm.tools.add_constant(sdf['year'])).fit()\n\nfig, ax = plt.subplots(1, 1, figsize=(8, 5))\nax.cla()\nbp.curve(sdf['year'], sdf['prop'])\nbp.line(sdf['year'], reg.fittedvalues, color='tab:red')\nplt.xlabel('Year', fontsize=20)\nplt.ylabel('Percentage', fontsize=20)\nplt.title('Percentage of Storms Outside of Official Storm Season by Year', fontsize=20)\nplt.tight_layout()\n\nWe analyze these percentages using the same semilocal linear trend model as above. If the slope parameter \\(\\eta\\) is significantly non-zero, we’ll have found some evidence in a changing proportion of storms occuring outside of the official storm season.\nsdata = {                                                                            \n    'T': sdf.shape[0], \n    'x': np.arange(sdf.shape[0]),\n    'y': sdf['prop']\n}\nstfit = stmod.sampling(data=sdata,\n                      control={'adapt_delta': .99}) \nposterior = stfit.extract() \n/Users/ez/py3/lib/python3.6/site-packages/pystan/misc.py:399: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  elif np.issubdtype(np.asarray(v).dtype, float):\nstan_utility.check_treedepth(stfit)\nstan_utility.check_energy(stfit)\nstan_utility.check_div(stfit)\nstan_utility.check_rhat(stfit)\nstan_utility.check_n_eff(stfit)\n0 of 4000 iterations saturated the maximum tree depth of 10 (0.0%)\nE-BFMI indicated no pathological behavior\n0.0 of 4000 iterations ended with a divergence (0.0%)\nRhat looks reasonable for all parameters\nn_eff / iter looks reasonable for all parameters\nThe plot below displays the semilocal linear trend estimates of the percentages of storms that formed outside of the official storm season. The model estimates are drawn in red and are superimposed over the light blue observations. It appears to have a gentle positive slope.\nfig, ax = plt.subplots(1, 1, figsize=(8, 5))\nax.cla()                                                                         \nbp.curve(sdf['year'], sdf['prop'], alpha=0.5)                                                   \nbp.curve(sdf['year'], posterior['y_pred'].mean(0), color='tab:red')                  \nplt.ylabel('Percentage', fontsize=20)                                                              \nplt.xlabel('Year', fontsize=20)\nplt.title('Percentage of Storms Outside of Official Storm Season by Year', fontsize=20)\nplt.tight_layout()\n\nThe posterior distribution of \\(\\eta\\) appears below, alongside multiple percentiles. While the median of \\(\\eta\\) is positive, even the \\(80\\)% credible interval includes 0. While I certainly don’t want to make a binary conclusion here, it appears that there is much noise in the estimate of the long term slope parameter \\(\\eta\\).\neta_percentiles = np.percentile(posterior['eta'], [2.5, 10, 50, 90, 97.5])\nprint(\"Linear regression slope estimate: {}\".format(reg.params[1]))\nprint(eta_percentiles)\n\nfig, ax = plt.subplots(1, 1, figsize=(8, 5))\nax.cla()  \nbp.density(posterior['eta'])\nbp.rug(eta_percentiles)\nplt.ylabel('Density', fontsize=20)\nplt.xlabel('$\\eta$', fontsize=20)\nplt.title('Posterior Distribution of $\\eta$', fontsize=20)\nplt.tight_layout()\nLinear regression slope estimate: -0.0038128475204844752\n[-0.4140813  -0.22224445  0.02994714  0.28013784  0.44618868]\n\nIt doesn’t appear that the percentage of storms occuring outside of the official storm season is changing over time.\nLast, we analyze the stationarity of the empirical storm season."
  },
  {
    "objectID": "posts/2018-07-18-storm-events.html#is-the-distribution-of-the-empirical-storm-season-stationary",
    "href": "posts/2018-07-18-storm-events.html#is-the-distribution-of-the-empirical-storm-season-stationary",
    "title": "Measuring Variation in the Empirical Storm Season Over Time",
    "section": "Is the Distribution of the Empirical Storm Season Stationary?",
    "text": "Is the Distribution of the Empirical Storm Season Stationary?\nConsider the average density histogram above, where the empirical storm season was averaged over all the years for which we have data. Let’s refer to this histogram as the average storm season. If the empirical storm season was not changing over time, then this average storm season would represent the stationary distribution from which each year’s storm season was randomly drawn. If such a stationary storm season producing distribution exists, then no year’s storm season in our data set should be too different from the average storm season.\nTo evaluate the stationarity of the storm season, we compute such a histogram for each year’s empirical storm season separately. For instance, consider the histogram of the storms from 2005. Now imagine we overlayed the average storm season histogram with the histogram from the 2005 storm season. We calculate the maximal, absolute difference between these two histograms. This idea is most easily visualized with histograms, but in fact we do all the calculations with the empirical cumulative distribution functions of the empirical storm seasons. Intuitively, these ideas are similar. In fact, this is just the Kolmogorov-Smirnov (KS) statistic, for each year’s storm season relative to the average storm season.\nWe walk through each step of the calculations involved. First, we calculate the average storm season.\nhist, bins = np.histogram(df['cnum_dates'], \n                          bins=df['cnum_dates'].nunique(), density=True)\ncdf = np.cumsum(hist)\necdf = cdf/cdf[-1]\nNext, we’ll replicate this calculation for each year in our data set.\nks = []\nfor year in np.nditer(df['date'].dt.year.unique()):\n    h, _ = np.histogram(df['cnum_dates'][df['date'].dt.year == year], \n                        bins=df['cnum_dates'].nunique(), density=True)\n    bcdf = np.cumsum(h)\n    ks.append(np.max(np.abs(ecdf - bcdf/bcdf[-1])))\nsdf['KS'] = np.array(ks)*100\nThe plot below displays the year over year KS statistics. There appears to be a negative slope over time. We remind the reader that the yearly KS statistics appear in absolute value. Hence, a (possible) negative slope is not as indicative as the word negative connotes. Here, any slope, positive or negative, will simply suggest a non-stationary storm season.\nreg = sm.OLS(sdf['KS'], sm.tools.add_constant(sdf['year'])).fit()\n\nfig, ax = plt.subplots(1, 1, figsize=(8, 5))\nax.cla()\nbp.curve(sdf['year'], sdf['KS'], alpha=0.5)\nbp.line(sdf['year'], reg.fittedvalues, color='tab:red')\nplt.xlabel('Year', fontsize=20)\nplt.ylabel('KS', fontsize=20)\nplt.title('KS Statistics by Year', fontsize=20)\nplt.tight_layout()\n\nsdata = {                                                                            \n    'T': sdf.shape[0], \n    'x': np.arange(sdf.shape[0]),\n    'y': sdf['KS']\n}\nstfit = stmod.sampling(data=sdata, \n                       control={'adapt_delta': .99,\n                                'max_treedepth': 15}) \nposterior = stfit.extract()\n/Users/ez/py3/lib/python3.6/site-packages/pystan/misc.py:399: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  elif np.issubdtype(np.asarray(v).dtype, float):\nstan_utility.check_treedepth(stfit, max_depth=15)\nstan_utility.check_energy(stfit)\nstan_utility.check_div(stfit)\nstan_utility.check_rhat(stfit)\nstan_utility.check_n_eff(stfit)\n0 of 4000 iterations saturated the maximum tree depth of 15 (0.0%)\nE-BFMI indicated no pathological behavior\n2.0 of 4000 iterations ended with a divergence (0.05%)\n  Try running with larger adapt_delta to remove the divergences\nRhat looks reasonable for all parameters\nn_eff / iter looks reasonable for all parameters\nThe semilocal linear trend model smoothes out the yearly KS statistics. Similar to linear regression, there appears to be a negative slope.\nfig, ax = plt.subplots(1, 1, figsize=(8, 5))\nax.cla()                                                                         \nbp.curve(sdf['year'], sdf['KS'], alpha=0.5)                                                   \nbp.curve(sdf['year'], posterior['y_pred'].mean(0), color='tab:red')  \nplt.ylabel('KS', fontsize=20)                                                              \nplt.xlabel('Year', fontsize=20)\nplt.title('KS Statistics by Year', fontsize=20)\nplt.tight_layout()\n\nThe posterior distribution of \\(\\eta\\) is noisy, despite the negative median value.\neta_percentiles = np.percentile(posterior['eta'], [2.5, 10, 50, 90, 97.5])\nprint(\"Linear regression slope estimate: {}\".format(reg.params[1]))\nprint(eta_percentiles)\n\nfig, ax = plt.subplots(1, 1, figsize=(8, 5))\nax.cla()  \nbp.density(posterior['eta'])\nbp.rug(eta_percentiles)\nplt.ylabel('Density', fontsize=20)\nplt.title('Posterior Distribution of $\\eta$', fontsize=20)\nplt.xlabel('$\\eta$', fontsize=20)\nplt.tight_layout()\nLinear regression slope estimate: -0.004147888339256261\n[-0.83684908 -0.50679053 -0.0118629   0.46288992  0.80493632]\n\nWe find little evidence that the empirical storm season is non-stationary, since the posterior distribution of \\(\\eta\\) is so noisy about \\(0\\)."
  },
  {
    "objectID": "posts/2021-09-20-tapply.html",
    "href": "posts/2021-09-20-tapply.html",
    "title": "Rs tapply() in Julia",
    "section": "",
    "text": "Lately, I, Edward, have been programming in Julia a lot. Two times in the last week, I’ve needed a function like R’s tapply(), but in Julia. With a little bit of searching around the interwebs, I hacked together a reasonable equivalent to R’s tapply() written in Julia. This blog post will explain the function tapply() and briefly introduce the two examples where I used tapply(). Last, I’ll provide my Julia code which replicates R’s tapply() function."
  },
  {
    "objectID": "posts/2021-09-20-tapply.html#example-1",
    "href": "posts/2021-09-20-tapply.html#example-1",
    "title": "Rs tapply() in Julia",
    "section": "Example 1",
    "text": "Example 1\nIn fact, the first time this came up for me was for a sub-problem that involved the practice problem above. I wanted to sum elements of a vector as grouped by another vector. My sub-problem involved groups as defined by integers instead of letters, but that’s no issue for tapply().\nh &lt;- c(1, 1, 2, 2, 3, 3, 3, 4, 5, 5)\ntapply(x, h, sum)\n\n##  1  2  3  4  5 \n##  3  7 18  8 19\nSince this example is no different than above, I’ll provide some more details of the broader problem I was working on. While working on a non-DSL version of Stan, I was attempting to take a derivative of something like a random effects linear model with respect to the random intercept. As it turns out, such a derivative needs the sum of the intercepts as grouped by their unique ID."
  },
  {
    "objectID": "posts/2021-09-20-tapply.html#tabulate-values",
    "href": "posts/2021-09-20-tapply.html#tabulate-values",
    "title": "Rs tapply() in Julia",
    "section": "tabulate values",
    "text": "tabulate values\nIn order to efficiently run a function like tapply(), I want a count of how many times each distinct value appears in a vector. R calls such a function table. Let’s first load up Julia and share with Julia some of the vectors we’ve been using in our examples.\nlibrary(JuliaCall)\njulia_assign(\"x\", x)\n\n## Julia version 1.5.0 at location C:\\Users\\rache\\AppData\\Roaming\\R\\data\\R\\JULIAC~1\\julia\\V15~1.0\\bin will be used.\n\n## Loading setup script for JuliaCall...\n\n## Finish loading setup script for JuliaCall.\n\njulia_assign(\"g\", g)\njulia_assign(\"y\", y)\njulia_assign(\"groups\", groups)\nI called my version of this function table in Julia, too. Here’s the source code, much of which I borrowed from the Julia package StatsBase.jl,\nfunction table(x::Vector)\n    d = Dict{eltype(x), Int}()\n    for v in x\n        idx = Base.ht_keyindex2!(d, v)\n        if idx &gt; 0\n            @inbounds d.vals[idx] += 1\n        else\n            @inbounds Base._setindex!(d, 1, v, -idx)\n        end\n    end\n    return d\nend\n\n## table (generic function with 1 method)\nSo now we can call our Julia function.\ntable(g)\n\n## Dict{String,Int64} with 5 entries:\n##   \"B\" =&gt; 2\n##   \"A\" =&gt; 2\n##   \"C\" =&gt; 3\n##   \"D\" =&gt; 1\n##   \"E\" =&gt; 2\nBecause Julia doesn’t inherently have a table type, I used a dictionary.\nNext, I wrote a function which I named group. This is equivalent to R’s split(). Since Julia already has a function named split, I chose a different name.\nfunction group(x::Vector, g::Vector)\n    gt = eltype(g)\n    gt &lt;: Number && gt != Int && (g = convert.(Int, g))\n    t = table(g)\n    d = Dict(k =&gt; Vector{eltype(x)}(undef, v) for (k, v) in t)\n    ug = collect(keys(t))\n    u = gt &lt;: Number ? ug : Dict(k =&gt; i for (i, k) in pairs(ug))\n    c = zeros(Int, length(d))\n    @inbounds for i in eachindex(g, x)\n        gi = g[i]\n        ui = u[gi]\n        c[ui] += 1\n        d[gi][c[ui]] = x[i]\n    end\n    return d\nend\n\n## group (generic function with 1 method)\nThe function group() groups the elements of x into groups based on the groups defined in g.\ngroup(x, g)\n\n## Dict{String,Array{Float64,1}} with 5 entries:\n##   \"B\" =&gt; [3.0, 4.0]\n##   \"A\" =&gt; [1.0, 2.0]\n##   \"C\" =&gt; [5.0, 6.0, 7.0]\n##   \"D\" =&gt; [8.0]\n##   \"E\" =&gt; [9.0, 10.0]\nLet’s compare this to what R’s function split() does. The order is not the same, so take a second to convince yourself the grouped elements of x appropriately match.\nsplit(x, g)\n\n## $A\n## [1] 1 2\n## \n## $B\n## [1] 3 4\n## \n## $C\n## [1] 5 6 7\n## \n## $D\n## [1] 8\n## \n## $E\n## [1]  9 10\nFinally, here is an equivalent to tapply(), which I named mapg() (think map groups). I also added an option to first sort the groups in g, just in case that proves helpful (which it did, in the details of the second example). Notice that I changed the order of the arguments to better match the order of the arguments to Julia’s function map(), namely the function to be applied to the groups comes first.\nfunction mapg(f, x, g; sortfirst = false)\n    v = collect(group(x, g))\n    z = sortfirst ? sort(v, by = x -&gt; first(x)) : v\n    return map(y -&gt; f(last(y)), z)\nend\n\n## mapg (generic function with 1 method)\nLet’s use mapg() to print out some integers in a “pretty” format.\nfunction f(x)\n  lx = length(x)\n  out = \"\"\n  if lx == 1\n    out *= \"$(x[1])\"\n  else\n    out *= lx == 2 ? \"$(x[1]), $(x[2])\" : \"$(x[1]) - $(x[end])\"\n  end\n  return out\nend\n\n## f (generic function with 1 method)\n\n\ns = mapg(f, y, groups, sortfirst = true)\n\n## 4-element Array{String,1}:\n##  \"1.0 - 3.0\"\n##  \"6.0, 7.0\"\n##  \"9.0 - 11.0\"\n##  \"13.0\"\n\njoin(s, \", \")\n\n## \"1.0 - 3.0, 6.0, 7.0, 9.0 - 11.0, 13.0\"\nIf you are following along, try calling mapg() without the sortfirst = true argument to better understand how sorting helps."
  },
  {
    "objectID": "posts/2025-04-25-Math500-Seminar-Chris-Barker/index.html",
    "href": "posts/2025-04-25-Math500-Seminar-Chris-Barker/index.html",
    "title": "Data Science Seminar – Dr. Chris Barker",
    "section": "",
    "text": "When the Unexpected Happens, Statistics Steps Up.\nJoin us for a special seminar hosted by the Data Science Initiative at CSU Chico.\nDr. Chris Barker will present on how randomization tests can help make valid inferences when clinical trials are disrupted by unexpected events such as pandemics, wars, or natural disasters.\n\n🗓️ Date: April 25, 2025\n🕐 Time: 1:00 PM – 2:00 PM\n📍 Location: Holt Hall 291\n🎤 Speaker: Dr. Chris Barker\n📄 View the related research paper\n\nFrom pandemic lockdowns to war zones, disruptions in clinical trials are increasingly common. This talk will explore how modern nonparametric statistical methods help ensure valid results, even when assumptions break down."
  },
  {
    "objectID": "posts/2019-03-29-dsi-seminar-arash-negahban.html",
    "href": "posts/2019-03-29-dsi-seminar-arash-negahban.html",
    "title": "DSI Seminar 3/29: An Introduction to SAP Predictive Analytics Workshop",
    "section": "",
    "text": "Presenter: Dr. Arash Negahban, Assistant Professor of Business Information Systems\nDate: Thursday March 29th, 2019\nTime: 1-3:00 pm\nLocation: Glenn 304 NOTE DIFFERENT ROOM\nRSVP: http://goo.gl/forms/BnjV0y5zoz09tUU83\n\n\n\nSAP Predictive Analytics is the visualization tool for SAP, the world’s largest business software company founded in 1972 and headquartered in Germany. SAP University Competence Center (UCC) under BIS department in College of Business is one of only six UCCs in the world that provides hosting services and technical support to universities that participate in SAP University Alliance, a global program that has more than 3,200 educational institutions in over 111 countries.\nThe goal of this mini-workshop is to provide an overview of SAP Predictive Analytics and guide the participants through the process of downloading, installing, and exploring the software. It is recommended to have a laptop. If you have any dataset you want to analyze, please have it handy."
  },
  {
    "objectID": "posts/2019-03-29-dsi-seminar-arash-negahban.html#description",
    "href": "posts/2019-03-29-dsi-seminar-arash-negahban.html#description",
    "title": "DSI Seminar 3/29: An Introduction to SAP Predictive Analytics Workshop",
    "section": "",
    "text": "SAP Predictive Analytics is the visualization tool for SAP, the world’s largest business software company founded in 1972 and headquartered in Germany. SAP University Competence Center (UCC) under BIS department in College of Business is one of only six UCCs in the world that provides hosting services and technical support to universities that participate in SAP University Alliance, a global program that has more than 3,200 educational institutions in over 111 countries.\nThe goal of this mini-workshop is to provide an overview of SAP Predictive Analytics and guide the participants through the process of downloading, installing, and exploring the software. It is recommended to have a laptop. If you have any dataset you want to analyze, please have it handy."
  },
  {
    "objectID": "posts/2019-02-02-dsi-seminar-spatial-is-special.html",
    "href": "posts/2019-02-02-dsi-seminar-spatial-is-special.html",
    "title": "DSI seminar 2/14: Spatial is Special!",
    "section": "",
    "text": "Presenter: Peter Hansen, Chico State GIS Specialist\nDate: Thursday February 14th, 2019\nTime: 2-2:50 pm\nLocation: Tehama 116\nRSVP: http://goo.gl/forms/BnjV0y5zoz09tUU83\n\n\n\nAre you curious about how to work with or create spatial data? Are you interested in beginning to explore how geographic data can be used in your research and other data inquiries? Data with a spatial component can be analyzed with software called GIS (Geographic Information Systems). In this workshop, we will talk briefly about geographic data and discuss methods on how it can be used to enrich your data science experience."
  },
  {
    "objectID": "posts/2019-02-02-dsi-seminar-spatial-is-special.html#description",
    "href": "posts/2019-02-02-dsi-seminar-spatial-is-special.html#description",
    "title": "DSI seminar 2/14: Spatial is Special!",
    "section": "",
    "text": "Are you curious about how to work with or create spatial data? Are you interested in beginning to explore how geographic data can be used in your research and other data inquiries? Data with a spatial component can be analyzed with software called GIS (Geographic Information Systems). In this workshop, we will talk briefly about geographic data and discuss methods on how it can be used to enrich your data science experience."
  },
  {
    "objectID": "posts/2018-04-23-intro-sap.html",
    "href": "posts/2018-04-23-intro-sap.html",
    "title": "Workshop: An Introduction to SAP Predictive Analytics",
    "section": "",
    "text": "Date: Thursday April 26, 2018\nTime: 2-2:50 pm\nLocation: MLIB 442\nPresenter: Dr. Arash Negahban, CSUC College of Business\n\n\n\nJoin us for a peek into the predictive analytics arena from a Business perspective – using the SAP software.This is also a great opportunity to learn about the SAP resources we have available on campus.\nSAP Predictive Analytics is the visualization tool for SAP, the world’s largest business software company founded in 1972 and headquartered in Germany. SAP University Competence Center (UCC) under BIS department in College of Business is one of only six UCCs in the world that provides hosting services and technical support to universities that participate in SAP University Alliance, a global program that has more than 3,200 educational institutions in over 111 countries.\nThe goal of this mini-workshop is to provide an overview of SAP Predictive Analytics and guide the participants through the process of downloading, installing, and exploring the software. It is recommended to have a laptop. If you have any dataset you want to analyze, please have it handy.\nRSVP HERE: https://goo.gl/forms/SXPm8n2xoeR3Rn2q2"
  },
  {
    "objectID": "posts/2018-04-23-intro-sap.html#description",
    "href": "posts/2018-04-23-intro-sap.html#description",
    "title": "Workshop: An Introduction to SAP Predictive Analytics",
    "section": "",
    "text": "Join us for a peek into the predictive analytics arena from a Business perspective – using the SAP software.This is also a great opportunity to learn about the SAP resources we have available on campus.\nSAP Predictive Analytics is the visualization tool for SAP, the world’s largest business software company founded in 1972 and headquartered in Germany. SAP University Competence Center (UCC) under BIS department in College of Business is one of only six UCCs in the world that provides hosting services and technical support to universities that participate in SAP University Alliance, a global program that has more than 3,200 educational institutions in over 111 countries.\nThe goal of this mini-workshop is to provide an overview of SAP Predictive Analytics and guide the participants through the process of downloading, installing, and exploring the software. It is recommended to have a laptop. If you have any dataset you want to analyze, please have it handy.\nRSVP HERE: https://goo.gl/forms/SXPm8n2xoeR3Rn2q2"
  },
  {
    "objectID": "posts/2017-08-01-new_site.html",
    "href": "posts/2017-08-01-new_site.html",
    "title": "New Site",
    "section": "",
    "text": "We have a new site!\nOne of Robin Donatello’s summer projects was to revamp the DSI website to have more flexibility in the content. Thanks to blogdown package by Yihui Xie, creating a custom professional website can be done relatively easily from the comfort of R Studio. He has a great tutorial/book on how to create websites with R Markdown.\nOver the course of the next few weeks [edit: Months] all content from the previous site will be migrated over.\nStay tuned for more information on our Fall events"
  },
  {
    "objectID": "posts/2019-11-05-were-hiring.html",
    "href": "posts/2019-11-05-were-hiring.html",
    "title": "We’re Hiring!",
    "section": "",
    "text": "The Department of Mathematics and Statistics at Chico State is hiring TWO Tenure-track Assisstant Professor positions in Statistics. We are looking for individuls from diverse backgrounds to join our team as we build the most amazing Statistics and Data Science programs in the North State.\n\n\n\nThis browser does not support PDFs. Please download the PDF to view it: Download PDF."
  },
  {
    "objectID": "posts/2017-04-07-Tidy_announce.html",
    "href": "posts/2017-04-07-Tidy_announce.html",
    "title": "DSI Workshop - Preparing Data for Analysis using R",
    "section": "",
    "text": "MLIB 442\n3PM - 4:30M(+)\nFriday\nApril 7, 2017\nDr. Rick Hubbard"
  },
  {
    "objectID": "posts/2017-04-07-Tidy_announce.html#data-science-initiative---hands-on-workshop-series",
    "href": "posts/2017-04-07-Tidy_announce.html#data-science-initiative---hands-on-workshop-series",
    "title": "DSI Workshop - Preparing Data for Analysis using R",
    "section": "Data Science Initiative - Hands-on Workshop Series",
    "text": "Data Science Initiative - Hands-on Workshop Series\nAs part of its Hands-on Workshop Series, the Chico Data Science Initiative is pleased to provide this practical and applied session. Preparing Data for Analysis is designed to assist everyone that analyzes data succeed and avoid (and/or resolve) frustrating problems unfortunately inherent in many datasets.\nThe Preparing Data for Analysis Workshop offers something for everyone…from the earliest of beginners to the most sophisticated Data Scientists."
  },
  {
    "objectID": "posts/2017-04-07-Tidy_announce.html#data-science-initiative-learning-doing-andcookies",
    "href": "posts/2017-04-07-Tidy_announce.html#data-science-initiative-learning-doing-andcookies",
    "title": "DSI Workshop - Preparing Data for Analysis using R",
    "section": "Data Science Initiative: Learning, Doing and…Cookies!",
    "text": "Data Science Initiative: Learning, Doing and…Cookies!\nIn addition to a place in space and time where interesting people address and resolve challenging questions, the Data Science Initiative also has a reputation for three fabulous things:\n\nLearning (about data, modeling, analysis, interpretation, visualization, etc.);\nDoing (all the above plus mentoring and problem-resolution); and\nCookies (considered self-evident).\n\nWorkshop Details & Materials"
  },
  {
    "objectID": "posts/2025-10-14-Data Science Seminar-Internships/index.html",
    "href": "posts/2025-10-14-Data Science Seminar-Internships/index.html",
    "title": "Data Science Seminar - Internship Series",
    "section": "",
    "text": "📅 Date: Selected Fridays 3-3:45pm\n📍 Location: Holt Hall 175"
  },
  {
    "objectID": "posts/2025-10-14-Data Science Seminar-Internships/index.html#seminar-overview",
    "href": "posts/2025-10-14-Data Science Seminar-Internships/index.html#seminar-overview",
    "title": "Data Science Seminar - Internship Series",
    "section": "Seminar Overview",
    "text": "Seminar Overview\n\nAre you interested in the field of Data Science?\nAre you already in the field (or adjacent) but not sure what you want to do with your skills?\nAre you looking for an internship?\n\nCome join us to learn about the exciting summer internships our current Masters in Data Science and Analytics students participated in last summer. We will also be inviting our internship partners to come share about their opportunities as well."
  },
  {
    "objectID": "posts/2025-10-14-Data Science Seminar-Internships/index.html#schedule-in-progress",
    "href": "posts/2025-10-14-Data Science Seminar-Internships/index.html#schedule-in-progress",
    "title": "Data Science Seminar - Internship Series",
    "section": "Schedule (in progress)",
    "text": "Schedule (in progress)\n\n\n\nDate\nSpeakers\nOrganization\nTopic\n\n\n\n\n10/17\nKhushi Choudary and Jayana Sarma\nWestern Weather\nThe internship focused on engineering the software platform for “Joules,” a conversational Al assistant we co-developed. Our goal was to architect and build a production-ready, full-stack Al chatbot from the ground up. The primary deliverable was a high-performance application that successfully integrates advanced NLP models to make complex weather data accessible through simple, natural language.\n\n\n10/24\nTBD\n\n\n\n\n10/31\nShivam Pawar\n\n\n\n\n11/7\nAmol Bhalerao\n\n\n\n\n11/7\nZakir Elaskar\n\n\n\n\n11/14\nAbinesh S.\n\n\n\n\n11/21\nTBD\n\n\n\n\n12/5\nTBD"
  },
  {
    "objectID": "posts/2022-09-01-student-post-intro-sql/index.en.html",
    "href": "posts/2022-09-01-student-post-intro-sql/index.en.html",
    "title": "September Student post: Introduction to SQL",
    "section": "",
    "text": "This is a quick-and-dirty introduction that will explain what SQL is, how it is used, and what some SQL queries look like in R using the dplyr package. SQL (sometimes pronounced “sequel”) stands for Structured Query Language. It is a programming language used to manipulate data in Relational Database Management Systems and it “is one of the most common languages for interacting with data” (source sqltutorial.org). SQL consists of three main languages under the same umbrella:\nThough SQL has a specific set of standards written by the American Standards Institute (ANSI), the user base constantly requires new features and capabilities. To accommodate this, there are a few different SQL “dialects” created by companies such as Oracle and Microsoft each with different syntaxes. In this tutorial, all SQL syntax used will be valid across all database systems.\nBefore going into SQL code, there are some important terms to know before creating a database. A primary key is a column or set of columns in a table whose value is unique for every record in the table. This can often be as simple as an integer ID or the combination of an ID and a date. A foreign key is a column in the table that refers to the primary key of another table. An example of this could be a situation where there is a table for purchases with a column for item number. The item number column is a foreign key that refers to the primary key item number of an items table with product information. For a more in-depth tutorial, I suggest reading through the Programiz tutorial."
  },
  {
    "objectID": "posts/2022-09-01-student-post-intro-sql/index.en.html#building-a-database-in-sql",
    "href": "posts/2022-09-01-student-post-intro-sql/index.en.html#building-a-database-in-sql",
    "title": "September Student post: Introduction to SQL",
    "section": "Building a database in SQL",
    "text": "Building a database in SQL\nBuilding a database requires a schema. This shows the organization of the data as a blueprint of how the database is constructed. Below is an example of a simple relational database schema with seven tables: \n(image source)\nThe above schema is actually incomplete as only primary keys are identified (with an *) and we are left to assume that foreign keys have the same column name as the primary key it refers to. For example, job_id in the employees table is a foreign key for the job_id primary key in the jobs table. The “crows feet” notation connecting each table defines how many of each record there is for each relationship. They aren’t as important when using SQL, but they are necessary knowledge when one has to interact with a real database. I’ll explain the relationship between employees and jobs as an example. The connector on the jobs table signifies that every employee has one and only one job_id reference to a job in the jobs table. The connector on the employees table means every job_id may be associated with zero or more records (people) in the employees table."
  },
  {
    "objectID": "posts/2022-09-01-student-post-intro-sql/index.en.html#data-definition-language",
    "href": "posts/2022-09-01-student-post-intro-sql/index.en.html#data-definition-language",
    "title": "September Student post: Introduction to SQL",
    "section": "Data Definition Language",
    "text": "Data Definition Language\nIn the industry, these commands are often restricted to be used by only the Database Management group. This is so that no random person in the company can edit the database and potentially destroy sensitive information. To show examples of database creation using SQL, I will create the jobs table. The following code chunk contains comments with more details:\n-- The notation at the start of this line denotes a comment, everything after \"--\" will be ignored\n-- All SQL commands must end in a semicolon \";\"\n-- Most SQL command words are in all caps, but this can depend on the system\n-- First we have to create the database, this one will be called \"HR\"\nCREATE DATABASE HR;\n\n-- The CREATE TABLE command creates a table and takes the columns with data types as the argument\n-- The basic syntax looks like this:\nCREATE TABLE table_name (\n  column1 datatype,\n  column2 datatype,\n  ...\n);\n\n-- Here is the full code to create the jobs table:\nCREATE TABLE jobs (\n    job_id INT (11) AUTO_INCREMENT PRIMARY KEY,\n    job_title VARCHAR (35) NOT NULL,\n    min_salary DECIMAL (8, 2) DEFAULT NULL,\n    max_salary DECIMAL (8, 2) DEFAULT NULL\n);\nIn the above code chunk, there were some new commands that may not look familiar. I’ll explain each column line-by-line.\n\nThe job_id column will be integer data. The number in parentheses tells the database the maximum number of digits that a job_id can have, in this case it is 11. The AUTO_INCREMENT command is an automatic function that runs whenever a new job is added to the table. Finally, PRIMARY KEY tells us this is the primary key.\nThe job_title column has a datatype called VARCHAR. This is a keyword meaning character data that is varying, essentially it is string data. The maximum length of a job_title is 35 characters, and the row cannot be empty. The NOT NULL command forces all records to have a job_title.\nThe last two columns, min_salary and max_salary, are very similar. They both have decimal data type, with 8 digits before the decimal and 2 digits after. Also, they both have DEFAULT NULL commands meaning that they are not required values when adding a new job. Adding a new job without specifying salaries will make those attributes empty.\n\nTo denote a foreign key, the structure looks like this:\nCREATE TABLE table_name (\n  column1 datatype,\n  column2 datatype,\n  ...\n  -- column3 is a primary key in another table\n  FOREIGN KEY (column2) REFERENCES another_table_name (column3)\n);\nAdditional commands are necessary to add to CREATE TABLE for when a table or record is deleted, but those are beyond the scope of this introduction. Other commands in the Data Definition language are shown below:\n-- See how these commands are not enclosed in parentheses?\n-- Little syntax differences like these can depend on the specific software being used\n-- However, all SQL commands end with a semicolon ;\n\nALTER TABLE table_name\nADD new_column datatype\nDROP old_column\nRENAME TO NEW_TABLE_NAME;\n\nDROP TABLE table_name;\n\n-- The ALTER TABLE command can also change column names and data definitions with RENAME and MODIFY"
  },
  {
    "objectID": "posts/2022-09-01-student-post-intro-sql/index.en.html#data-control-language",
    "href": "posts/2022-09-01-student-post-intro-sql/index.en.html#data-control-language",
    "title": "September Student post: Introduction to SQL",
    "section": "Data Control Language",
    "text": "Data Control Language\nThere are only two main commands in this language. They are GRANT and REVOKE. Only Database Administrator’s or owner’s of the database object can provide/remove privileges on a database object. The details of these commands are beyond the scope of this introduction, but their skeleton will be shown.\nThe syntax for the GRANT command is:\nGRANT privilege_name \nON database_name \nTO {user_name |PUBLIC |role_name} -- username or all users or users with role_name\n[WITH GRANT OPTION]; -- optional\nThe syntax for the REVOKE command is:\nREVOKE privilege_name \nON database_name \nFROM {user_name |PUBLIC |role_name}; -- username or all users or users with role_name"
  },
  {
    "objectID": "posts/2022-09-01-student-post-intro-sql/index.en.html#data-manipulation-language",
    "href": "posts/2022-09-01-student-post-intro-sql/index.en.html#data-manipulation-language",
    "title": "September Student post: Introduction to SQL",
    "section": "Data Manipulation Language",
    "text": "Data Manipulation Language\nTo demonstrate examples, I will create a couple of toy datasets: one for employees and one for jobs. In these examples, I did not include a primary key for employees so we can assume the first and last name together are the primary key. The primary key of the jobs table is job_id and the employees table has a foreign key with the same name.\nemployees &lt;- tibble(\n  first_name = c(\"Curly\", \"Larry\", \"Moe\", \"Joe\"),\n  last_name = c(\"Morris\", \"Cambridge\", \"Wallace\", \"Frasier\"),\n  salary = c(10000.00, 10000.00, 12500.00, 13333.33),\n  job_id = c(1, 2, 3, 4)\n)\nhead(employees)\n## # A tibble: 4 × 4\n##   first_name last_name salary job_id\n##   &lt;chr&gt;      &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;\n## 1 Curly      Morris    10000       1\n## 2 Larry      Cambridge 10000       2\n## 3 Moe        Wallace   12500       3\n## 4 Joe        Frasier   13333.      4\njobs &lt;- tibble(\n  job_title = c(\"Janitor\", \"Maintenenace\", \"Electrical\", \"Manager\"),\n  job_id = c(1, 2, 3, 4)\n)\nhead(jobs)\n## # A tibble: 4 × 2\n##   job_title    job_id\n##   &lt;chr&gt;         &lt;dbl&gt;\n## 1 Janitor           1\n## 2 Maintenenace      2\n## 3 Electrical        3\n## 4 Manager           4\nFor this introduction, I’ll focus on the SELECT command to make queries to the database. However, there are other commands in the language such as INSERT, UPDATE, and DELETE. The basic format of a SQL query looks like this:\nSELECT select_list\nFROM table_name;\nUsing R, this command would look like:\nselect(data = table_name, column1, column2, ...)\nThe select list can be any number of comma-separated column names or an asterisk * to denote all columns in the table. When evaluating the SELECT statement, the database system evaluates the FROM clause first and then the SELECT clause. You can also do arithmetic in the SELECT clause, a couple of examples are below with their R translation and output:\nSELECT first_name, last_name, salary, salary * 1.25\nFROM employees;\nemployees %&gt;% select(first_name, last_name, salary) %&gt;%\n  mutate(raise = salary * 1.25)\n## # A tibble: 4 × 4\n##   first_name last_name salary  raise\n##   &lt;chr&gt;      &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;\n## 1 Curly      Morris    10000  12500 \n## 2 Larry      Cambridge 10000  12500 \n## 3 Moe        Wallace   12500  15625 \n## 4 Joe        Frasier   13333. 16667.\nSELECT AVG(salary), COUNT(DISTINCT(salary)), ROUND(salary, 0) -- round to 0 decimal places\nFROM employees;\nemployees %&gt;% transmute(avg_salary = mean(salary),\n          count_distinct = n_distinct(salary), trunc_salary = floor(salary))\n## # A tibble: 4 × 3\n##   avg_salary count_distinct trunc_salary\n##        &lt;dbl&gt;          &lt;int&gt;        &lt;dbl&gt;\n## 1     11458.              3        10000\n## 2     11458.              3        10000\n## 3     11458.              3        12500\n## 4     11458.              3        13333\nSELECT MAX(salary), MIN(salary)\nFROM employees;\nemployees %&gt;% transmute(max_sal = max(salary), min_sal = min(salary))\n## # A tibble: 4 × 2\n##   max_sal min_sal\n##     &lt;dbl&gt;   &lt;dbl&gt;\n## 1  13333.   10000\n## 2  13333.   10000\n## 3  13333.   10000\n## 4  13333.   10000\nTo get data from other tables and join it to this one, we use a JOIN clause. Using INNER JOIN, we can select the rows that have a record in both tables. SQL also supports LEFT JOIN and RIGHT JOIN. The format looks like this:\nSELECT first_name, last_name, job_title\nFROM employees\nINNER JOIN jobs ON job_id = job_id;\n-- the name before the equals sign is the primary key in the employees table\nIn R, it might look like this:\nemployees %&gt;% select(first_name, last_name, job_id) %&gt;%\n  inner_join(jobs, by=c(\"job_id\"=\"job_id\"))\n## # A tibble: 4 × 4\n##   first_name last_name job_id job_title   \n##   &lt;chr&gt;      &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;       \n## 1 Curly      Morris         1 Janitor     \n## 2 Larry      Cambridge      2 Maintenenace\n## 3 Moe        Wallace        3 Electrical  \n## 4 Joe        Frasier        4 Manager\nSQL queries can be powerful, and they can also get huge if you have to join multiple tables. This introduction does not go in depth, so to learn more you should do some research. If you know R, you will see some parallels between the dplyr package and SQL queries. In fact, R actually supports SQL to get data straight from central relational databases. In this introductory tutorial, databases were introduced, basic examples were given for each of the three SQL languages, and some queries were shown in the R programming language.\n\nJoseph Shifman is a Computer Science major with a minor in Math. He is also in the Data Science Certificate program at CSU Chico. To see more projects he has worked on, check out his Github or his LinkedIn."
  },
  {
    "objectID": "posts/2025-03-14-Math500-Seminar-Lori-Christian/index.html",
    "href": "posts/2025-03-14-Math500-Seminar-Lori-Christian/index.html",
    "title": "Data Science Seminar – Your [Data] Powers Can Change the World!",
    "section": "",
    "text": "💬 What’s This All About?\nWe all know data can power business decisions, but what if it could change the world?\nJoin us for a back-to-back seminar featuring two incredible speakers who used their data science skills to make real social impact — from fighting human trafficking to helping a community navigate a global pandemic.\n\n\n\n🧠 Featured Speakers\n\n🗨️ Lori McNeil\nUsing Your [Data] Powers for Good\n📅 March 14, 2025 | 🕐 1:00 PM – 1:30 PM\nDiscover how a civic hackathon inspired Lori to launch the Civic Hacker Summit — and how data scientists can lead grassroots change in their own communities.\n🔗 About Lori\n🔗 Connect on LinkedIn\n\n\n\n💻 Christian Hammond\nCoding for a Cause: Helping Butte County Navigate a Pandemic\n📅 March 14, 2025 | 🕑 2:00 PM – 2:30 PM\n🔗 Butte County COVID-19 Dashboard\nA behind-the-scenes look at how Christian developed the unofficial COVID-19 dashboard for Butte County — translating complex data into clarity for the people who needed it most.\n\n📍 Location: Holt Hall 291\n🌱 Open to all majors. Come get inspired.\n🧑‍💻 Whether you’re into code, community, or both — this is for you."
  },
  {
    "objectID": "posts/2023-11-15-state-of-ds-f23/index.en.html",
    "href": "posts/2023-11-15-state-of-ds-f23/index.en.html",
    "title": "State of Data Science at Chico State - Fall 23",
    "section": "",
    "text": "It’s been a busy year (or two)!\nApologies for the radio silence since Spring, it’s been pretty busy over here. We have lots of updates to share with you, so what better time to do an end of the year “State of Data Science” wrap up."
  },
  {
    "objectID": "posts/2023-11-15-state-of-ds-f23/index.en.html#undergraduate-certificate-in-data-science",
    "href": "posts/2023-11-15-state-of-ds-f23/index.en.html#undergraduate-certificate-in-data-science",
    "title": "State of Data Science at Chico State - Fall 23",
    "section": "Undergraduate Certificate in Data Science",
    "text": "Undergraduate Certificate in Data Science\n\n\nWe saw 4 more students graduate with this certificate in Spring 2023, bringing our total to 19 since the start of the program in 2019.\n\nSee their capstone project repositories here.\n\nCurrent enrollment is at 7 students: 2 from Business Information Systems, 1 from Statistics, 3 from Computer Science and 1 from Organizational Communication. Side note: We had 2 from Statistics, but a conflict with the upper division Linear Algebra (MATH 435) class that is critical for graduate study conflicts with CSCI 211 this spring, so choices had to be made."
  },
  {
    "objectID": "posts/2023-11-15-state-of-ds-f23/index.en.html#community-coding-is-back-in-person",
    "href": "posts/2023-11-15-state-of-ds-f23/index.en.html#community-coding-is-back-in-person",
    "title": "State of Data Science at Chico State - Fall 23",
    "section": "Community Coding is back in person!",
    "text": "Community Coding is back in person!\nGot data and working on analysis? Got questions on using R, Python or other programming languages? Great way to dedicate time to working on that project you’ve been meaning to get around to. Come and hang out with other coders in a welcoming and supportive environment.\n\n\nWhile most of the posted hours are still individual faculty’s office hours, we are striving to rebuild the drop-in open working environment. Wednesdays this Fall are either in Sylvesters, or in the BSS Student Success Center. Both collaborative working spaces."
  },
  {
    "objectID": "posts/2023-11-15-state-of-ds-f23/index.en.html#new-courses",
    "href": "posts/2023-11-15-state-of-ds-f23/index.en.html#new-courses",
    "title": "State of Data Science at Chico State - Fall 23",
    "section": "New Courses",
    "text": "New Courses\n\nMath 131: Introduction to Python We are excited to offer, for the first time, Introduction to Python as MATH 131 in spring 2024. Like the sister course MATH 130 (Intro to R), this will be a 1 unit, credit / no credit course that only lasts the first 5 weeks of the semester. Tu/Th 2-3:15pm.\nMath 185: Data Science for Social Good. Students practice collecting and wrangling data into a usable form, visualizing large data sets to discover patterns, representing data in a meaningful way, exploring varying interpretations of the data and results, and discussing potentials for misuse and abuse. This course promotes critical reflection on the ethical, social, cultural, and political dimensions of data as well as providing direct hands on experience with both spreadsheets, and the programming language R. This Freshmen level class carries GE B4 credit.\nMath 500: Data Science Seminar. This 1 unit seminar explores current and relevant applications and implementations of data science and analytical methods and tools in the field. Seminars will include external and student-led presentations and hands-on tutorials. Emphasis is placed on students sharing and getting feedback on an approved capstone or master’s project\nCSCI 644: DevOps Engineering This course introduces students to distributed system administration skills, setting up distributed computation environments, cloud virtualization technologies, and setting up mobile, web, machine learning, artificial intelligence, and data science pipelines.\n\nThe College of Business has been expanding their data analytical course offerings. Primarily using SQL, Tableau and Python.\n\nMINS 235: Database Design. SQL is essential for everyone!\nBSIS 308: Decision Analysis for Business. Code-less decision making with data at the core\nBSIS 421: Business Analytics with Python\nBSIS 460: Data Analytics. SQL + Analytical algorithms = essential skills for Data Scientists\nStarting Fall 2024 the MBA - Enterprise Information Systems option will be reconfigured to be an option in Business Analytics."
  },
  {
    "objectID": "posts/2023-11-15-state-of-ds-f23/index.en.html#new-masters-in-data-science-and-analytics",
    "href": "posts/2023-11-15-state-of-ds-f23/index.en.html#new-masters-in-data-science-and-analytics",
    "title": "State of Data Science at Chico State - Fall 23",
    "section": "New Masters in Data Science and Analytics",
    "text": "New Masters in Data Science and Analytics\nWe have launched a new Masters in Data Science and Analytics 🎉and are accepting applications for Fall 2024\nSimilar to the Undergraduate Certificate, this program blends the strengths of both the Mathematics and Computer Science departments to create a program that provides both breadth and depth.\nThe Applied Analytics track can be thought of as an applied track, where the focus is for students to collaborate closely with researchers or companies in a domain specific field. Students in this track could be employed in positions where they are the “data person” on a team. This track may appeal more to students from a broad range of majors and domain interests such as nutrition, agriculture, medicine, bioinformatics, journalism, political science and even the digital humanities.\nThe Machine Learning track provides deeper and more technical training on the mathematical and computational underpinnings of the statistical, machine learning and artificial intelligence models being used. This track may appeal to students with backgrounds in areas such as mathematics, statistics, or computer science. Leveraging their more technical backgrounds students in this track will learn how to develop, implement, and integrate algorithmic solutions using massive amounts of data based on artificial intelligence, machine learning, or statistical analysis methods.\nStudents in the Undergraduate Certificate are strong candidates for acceptance and can even transfer some classes such as MATH/CSCI 485 and MATH 456 over to the Masters program, potentially reducing their time to complete the degree.\n\n\n\n\n\n\nAdmissions Requirements\n\n\n\n\nCalculus II\nUpper Division Applied Statistics (E.g. Math 314 or 315)\nIntroductory level in both R (Math 130 or equivalent) and Python (MATH 131 or equivalent)\n\nStudents wishing to pursue the Machine Learning track must also meet the following requirements before formally declaring the ML track.\n\nCalculus III-Multivariable Calculus (MATH 220 or equivalent)\nLinear Algebra (MATH 235 or equivalent)\nProgramming & Algorithms I (CSCI 111 or equivalent)\nProgramming & Algorithms II- Advanced Object-Oriented Programming (CSCI 211 or equivalent)"
  },
  {
    "objectID": "posts/2023-11-15-state-of-ds-f23/index.en.html#data-science-club",
    "href": "posts/2023-11-15-state-of-ds-f23/index.en.html#data-science-club",
    "title": "State of Data Science at Chico State - Fall 23",
    "section": "Data Science Club",
    "text": "Data Science Club\nWith it’s inaugural meeting this Fall, a Data Science Club has finally been created at Chico State! The Data Science Club strives to help students learn, discuss, and participate in data science. Ever want to join a club at the ground level and get to be foundational in how it grows? Now is your time. You can find more information on their website, or in their channel on the Math & Stats Discord Server."
  },
  {
    "objectID": "posts/2023-11-15-state-of-ds-f23/index.en.html#math-stats-discord-server",
    "href": "posts/2023-11-15-state-of-ds-f23/index.en.html#math-stats-discord-server",
    "title": "State of Data Science at Chico State - Fall 23",
    "section": "Math & Stats Discord Server",
    "text": "Math & Stats Discord Server\nDid I mention a Math & Stats Discord server? Sometime in 2020, or 2021 I joined the very popular student-run Discord server for the Computer Science Department. Student moderated and managed, I found their structure of having channels for each class that were permanent, students and faculty join join and leave as needed very helpful.\nComing from a place of using Slack as the back channel communication platform for my classes, and feeling like I had to juggle multiple workspaces per class I joined up with a few other faculty and with the help of a student created a space for multiple Math classes that could be added or dropped as needed.\nIt is not as chatty or robust as the CS server (not surprisingly), but we hope as more students join and use this space to work on their math and stats classes we can recruit more faculty to join, or at least announce it as a space for their students to collaborate.\n\n\n\n\n\n\nLFM - Student mod\n\n\n\nWe’re currently looking for new student moderators to help disseminate announcements, cross post cool info from the CS discord, create new channels such as Alumni & Profs and find ways to engage our community!"
  },
  {
    "objectID": "posts/2023-11-15-state-of-ds-f23/index.en.html#norcal-datafest-2024---save-the-date",
    "href": "posts/2023-11-15-state-of-ds-f23/index.en.html#norcal-datafest-2024---save-the-date",
    "title": "State of Data Science at Chico State - Fall 23",
    "section": "NorCal DataFest 2024 - Save the date",
    "text": "NorCal DataFest 2024 - Save the date\n\nSave the Date - April 12-14th at Chico State is the site of the next NorCal DataFest\nThe American Statistical Association’s DataFest, founded at UCLA in 2011, is a 48-hour data analysis competition in which undergraduate students from various majors get to work in teams on large, complex, and real-world data. The data is kept secret until opening of the event on Friday evening and teams present their findings to a panel of judges on Sunday afternoon. Students explore, analyze, and visualize the data to discover insights. No prior knowledge of programming or data visualization is necessary! Sometimes having a dedicated “storyteller” on the team is the key to victory.\nPrevious years’ data sets have included crime data from the LAPD, dating data from eHarmony, and energy use data from GridPoint. This year’s data set will be revealed at the opening of the event on Friday evening.\nAt the conclusion of the competition, each team will have 5 minutes and 2 slides to make a presentation to a panel of judges. Judges will select teams to win prizes for areas such as “Best Insight”, “Best Visualization”, and “Best use of External Data”.\nThis event is now rotating across the North State. Last year it was held at Sacramento State, with participants from both Chico and Sac State participating. This year we hope to draw teams from Sonoma and Cal Poly Humboldt as well.\nKeep an eye on our website for more information and registration information."
  },
  {
    "objectID": "posts/2023-11-15-state-of-ds-f23/index.en.html#internships",
    "href": "posts/2023-11-15-state-of-ds-f23/index.en.html#internships",
    "title": "State of Data Science at Chico State - Fall 23",
    "section": "Internships",
    "text": "Internships\nOur partnership with the Center for Healthy Communities’ Research & Evaluation team has been growing! Every semester we have placed 1-2 students from Statistics or other data related majors with them in paid internships, many of which have resulted in longer term paid positions. Some students even stayed on after graduation until finding a full time position or starting graduate school.\nOur partnership with Project DA-FANH allowed for the expansion of this internship to other organizations on campus including the Center for Regenerative Agriculture and Resilient Systems, Institutional Research and Strategic Analytics, and the Louis Stokes Alilance for Minority Participation. You can read about these partners on the project webpage.\nWith one more fall cohort of internships, this USDA grant funded project aiming to build pathway for students of color in the intersection of Data Science/Data Analytics within food, agriculture, natural resources and human sciences (FANH) careers. Carrying 3 units, this experience could count towards the DS Certificate, or perhaps your major while providing an authentic career experience using data to make decisions."
  },
  {
    "objectID": "posts/2019-04-11-learnings.html",
    "href": "posts/2019-04-11-learnings.html",
    "title": "At DataFest 2019, I Learned…",
    "section": "",
    "text": "During CSU, Chico’s DataFest 2019, two questions from different teams provided me (Edward, not Dr. Donatello) an excellent learning experience. This blog post attempts to describe the problems these teams faced and then offer up some solutions. This post is about my own learnings during DataFest and does not even pretend to claim that these are the only, nor the best, solutions to these problems."
  },
  {
    "objectID": "posts/2019-04-11-learnings.html#team-data-strikes-back",
    "href": "posts/2019-04-11-learnings.html#team-data-strikes-back",
    "title": "At DataFest 2019, I Learned…",
    "section": "Team Data Strikes Back",
    "text": "Team Data Strikes Back\nTeam Data Strikes Back wanted to number the levels of a categorical variable. Here’s some made up data to represent the idea. Our goal is to index the levels of \\(f\\).\nsuppressMessages(library(dplyr))\ndf &lt;- tibble(f = sample(letters, 20, replace=TRUE))\nThe solution I came up with relies on sorting the data, so let’s do that first.\no &lt;- order(df$f)\ndf &lt;- df[o,,drop=FALSE]\ndf$nf &lt;- match(df$f, unique(df$f))\n\n# check\nhead(df)\n## # A tibble: 6 x 2\n##   f        nf\n##   &lt;chr&gt; &lt;int&gt;\n## 1 a         1\n## 2 d         2\n## 3 g         3\n## 4 g         3\n## 5 g         3\n## 6 i         4\nSurely there’s other ways to do this; R probably has a function for it. But I don’t didn’t know which function. Moreover, this solution is general enough to be used within a broader grouping variable \\(g\\) and does not require any variable to be a factor.\nnumber_levels &lt;- function(x) {\n  x &lt;- sort(x)\n  match(x, unique(x))\n}\ndf$g &lt;- as.character(gl(4, 5, labels=sample(LETTERS, 4)))\n\ndf &lt;- df %&gt;%\n  group_by(g) %&gt;%\n  mutate(gf = number_levels(f))\nIt requires some extra work if you want the numbered levels to be increasing across the levels of some grouping variable \\(g\\), but we can manage with some help from a rarely used assignment operator.\nindex_grouped_levels &lt;- function() {\n  idx &lt;- 0\n  nl &lt;- function(x) {\n    levels &lt;- number_levels(x) + idx\n    idx &lt;&lt;- max(levels)\n    levels\n  }\n  nl\n}\n\nigrp_levels &lt;- index_grouped_levels()\ndf &lt;- df %&gt;%\n  arrange(g, f) %&gt;%\n  group_by(g) %&gt;%\n  mutate(ngf = igrp_levels(f))\n\nA Simpler Solution\nOn the Tuesday after DataFest, I show off my work to Dr. Donatello, and she looks at me like I’m crazy. She says, “What about \\(\\texttt{as.numeric(f)}\\) called on a factor?” I respond, “Ffa, sha, wha?” Then she shows me, and we worked out this gem.\ndf &lt;- tibble(f = sample(letters, 20, replace=TRUE))\ndf$g &lt;- as.character(gl(4, 5, labels=sample(LETTERS, 4)))\n\n# as.numeric() on a concatenated factor\ndf &lt;- df %&gt;%\n  arrange(desc(g), f) %&gt;%\n  mutate(gf = paste0(g, f)) %&gt;%\n  mutate(mgf = as.numeric(as.factor(gf)))\n\n# my strategy\nigrp_levels &lt;- index_grouped_levels()\ndf &lt;- df %&gt;%\n  group_by(g) %&gt;%\n  mutate(ngf = igrp_levels(f))\n\nall(df$mgf == df$ngf)\n## [1] TRUE"
  },
  {
    "objectID": "posts/2025-03-28-Math500-Seminar-Jing-Guo/index.html",
    "href": "posts/2025-03-28-Math500-Seminar-Jing-Guo/index.html",
    "title": "Data Science Seminar – Dr. Jing Guo",
    "section": "",
    "text": "🧠 Graph Learning from Smooth Signals and Regressors (GLReg)\nHow do we learn the underlying structure of a graph when signals are both smooth and influenced by covariates?\nJoin Dr. Jing Guo as she presents a novel graph learning framework that combines: - Smoothness of signals on nodes - Linear regression using node-level predictors\nThis model (GLReg) enables the inference of graph topology using real-world, noisy data and can be applied to domains like: - 🌍 Geographical data\n- 🧬 Biomedical networks\n- 🧑‍🤝‍🧑 Social networks\n\n\n\n📊 What You’ll Learn\n\nHow to infer a graph Laplacian from both response and predictor signals\nThe interaction between smooth signals and regressors\nApplications using both simulated and real-world data\n\n\n📅 Date: March 28, 2025\n🕐 Time: 1:30 pm - 2:00 pm 📍 Venue: Holt Hall 291\n\n\n\n📚 Pre-Seminar Materials\nParticipants are encouraged to review the materials in advance:\n- 📄 Graph Learning From Signals With Smoothness Superimposed by Regressors (2023)\nBring questions — we’re here to learn together!"
  },
  {
    "objectID": "posts/2018-04-06-intro_python_announce.html",
    "href": "posts/2018-04-06-intro_python_announce.html",
    "title": "Workshop: Using Python for Exploratory Data Analysis",
    "section": "",
    "text": "April is Data Fest Prep month! Hone your skills in preparation for this exciting data hackathon event!"
  },
  {
    "objectID": "posts/2018-04-06-intro_python_announce.html#description",
    "href": "posts/2018-04-06-intro_python_announce.html#description",
    "title": "Workshop: Using Python for Exploratory Data Analysis",
    "section": "Description",
    "text": "Description\nIn this workshop, we’ll explore Python and Jupyter notebooks as data analysis tools. The basics of statistical analysis will be focused on Python’s library Pandas. With Pandas we’ll learn how to import, filter, group, and summarize data. Matplotlib is the preferred plotting tool of Python, and we’ll combine Pandas with Matplotlib to make some simple but informative plots. No Python experience is necessary, but a working Python environment is required – one should be able to launch a Jupyter notebook on their own machine and install libraries using Pip."
  },
  {
    "objectID": "posts/2018-04-06-intro_python_announce.html#rsvp-here-for-this-and-other-upcoming-dsi-workshops.",
    "href": "posts/2018-04-06-intro_python_announce.html#rsvp-here-for-this-and-other-upcoming-dsi-workshops.",
    "title": "Workshop: Using Python for Exploratory Data Analysis",
    "section": "RSVP here for this and other upcoming DSI workshops.",
    "text": "RSVP here for this and other upcoming DSI workshops."
  },
  {
    "objectID": "posts/2018-07-11-student-data-analyst-job-at-chico-state.html",
    "href": "posts/2018-07-11-student-data-analyst-job-at-chico-state.html",
    "title": "Current job and research project openings at Chico State",
    "section": "",
    "text": "Strategic Planning Student Assistant\n\nDepartment: Office of the President, CSU, Chico\nProject Details: As one of the first steps in the strategic planning process, we are conducting both internal and external scans. The internal scan will review internal data (President’s Listening Tour, Campus Climate Survey, Alumni Attitude Survey, Spring Graduate Survey, etc.) to identify institutional strengths, weaknesses, opportunities, and threats. The external (environmental) scan will examine patterns of change in the surrounding environment that will impact Chico State as an institution in the future. This includes a wide range of metrics at the global, national, state, and regional level, including economic factors, demographic factors, higher education trends, etc. This is not a super hardcore data science position but will require a lot sifting through and visualizing data. In addition to helping with the scans, the student (if they chose to remain with the project) would assist with the planning and execution of strategic planning campus engagement events, analysis of campus engagement data, and other tasks associated with the strategic planning process.\nTime commitment: This is a paid position open until filled. Summer hours up to 40hr/wk, and up to 20 hours (at least 15) during the semester if interested.\nRequirements: Applicants should have a basic grasp of statistical methods, a solid grasp of MS Excel and functions, data cleansing and formatting, graphing, etc. Experience with tools like Tableau or PowerBI would be a bonus. Applicants should have excellent written communication and organizational skills. Additional data cleaning skills with a programming language such as R or Python acceptible as long as the process is clearly documented and can be reproduced by other staff.\nContact: Students can apply on the Handshake job application website.\n\n\n\n\nCarpentry Workshop Helper\n\nProject Details: The DSI will be hosting a Software Carpentry workshop on Reproducible Scientific Analysis using R. This two-day hands-on workshop will serve approximately 20-30 learners by 2-3 instructors so technical assistance (TA/helpers) are incredibly needed! TA’s will generally wander around the room, responding to red stickies (flags that help is needed) and providing assistance as needed. We would like to have at least 2 helpers at all times.\nTime commitment: Any portion of 8:30am - 5pm Monday August 13th & Tuesday August 14th. Full day volunteers get a free lunch!\nSkills Requirements: Knowlege of R (base, ggplot, dplyr), spreadsheets, shell/bash is helpful but not required.\nContact: Email Robin Donatello directly if you are interested.\n\n\n\n\nApplied Statistics Research Assistant\n\nDepartment: Joint research between Statistics & Chemistry\nProject Details: The Department of Chemistry and Biochemistry is conducting a complete overhaul of how their General Chemistry (Chem 111) labs are run. This new setup is called Studio Labs and fully integrate lecture with lab, instead of having them as separate meeting times and activities. Research has shown that this type of active and engaged learning has a positive impact on student success and can lead to higher pass rates for this class. Using the new PHYS building as a catalyst, the department is making this change over the next three years. Pre and post surveys will be administered to assess the impact of this new lab implementation on faculty, staff and students. Surveys will be administered annually starting Fall 2018.\nTime commitment: 5-10 hours/wk for 3 units of research credit. The initial workflow setup starts Spring 2019.\nSkills Requirements: R, RStudio, One of (or equivalent) MATH 314, MATH 315, MATH/CSCI 385\nContact: Email Robin Donatello directly if you are interested.\n\n\n\n\nStatistics Research Assistant\n\nDepartment: Statistics\nProject Details: Simulation based Statistical research on methods to handle missing and inconsistent data.\nTime commitment: 3-10 hours/wk for 1-3 units of research credit.\nSkills Requirements: Requires moderate to strong skills with R, knowledge of LaTeX (can be taught on demand). Ability to create and use user-driven functions, conduct simulations and visualize results. Serious work involved, requesting approx 5 hrs/week. Publication involved.\n\nContact: Email Robin Donatello directly if you are interested.\n\n\n\nHave a campus job, research position, or project you want to advertise here? Email the DSI with your request."
  },
  {
    "objectID": "posts/2017-10-12-data-opportunities-for-stat-data-science-students.html",
    "href": "posts/2017-10-12-data-opportunities-for-stat-data-science-students.html",
    "title": "Fun Opportunities for Statistics Students",
    "section": "",
    "text": "The following list of opportunities for students of Statisics was sent to us by Mark Harbison at Sacramento City College.\n\nPolice Data Challenge:\nThe American Statistical Association (ASA)’s public education campaign, This Is Statistics, in collaboration with the Police Data Initiative, has launched the Police Data Challenge - a national contest for high school and undergraduate students to put their statistical and data visualization skills to work creating safer communities. Data sets from metropolitan police departments in Baltimore, Cincinnati, and Seattle are available for participants to peruse in formulating analyses and recommending innovative solutions to enhance public safety. Teams of 2 to 5 high school or college undergraduate students in the U.S. and Canada can submit an entry. Submissions are comprised of a short essay describing the team’s process and a presentation of the team’s analysis and recommendations via PowerPoint. Awards will be given in the categories of Best Overall Analysis, Best Visualization, and Best Use of External Data. Students need to register by October 20. Their submissions are due by November 3. Here is a link to more information about how your students can participate in this contest: http://thisisstatistics.org/policedatachallenge/ And here is a link to the This Is Statistics webpage that you can share with your students: http://thisisstatistics.org/students/\nTeam Chico! Contact Robin Donatello if you want to participate. You do not have to be a Statistics major to participate!\n\n\n“Data to Insight” MOOC\n“Data to Insight: An Introduction to Data Analysis” is a free online course by leading statistics educator Chris Wild. It provides a hands-on introduction to modern statistical data analysis, visualization and inference emphasizing key ideas and practical empowerment. It starts from the statistical basics and steps just enough beyond them for you to provide your students with glimpses of exciting potentials that lie almost within their grasp. The course started October 2, 2017, though people can join up to 10 weeks late. Here is a link to more information about it: https://www.futurelearn.com/courses/data-to-insight\n\n\n“What’s Going on in this Graph?” (WGOITG)\nThe American Statistical Association (ASA) has partnered with the New York Times Learning Network to help students better understand and think more critically about graphs. A variation of their popular “What’s Going on in this Picture?”, WGOITG will be a monthly feature starting September 19 and continuing the second Tuesday of the following months (October 10, November 14, etc.) through the end of the school year in May. Led by Sharon Hessney, the ASA team includes Corey Andreasen, Anna Bargagliotti, Chris Franklin, Stephen Miller, and Roxy Peck. A graph from a NYT news article will be presented on those dates with live moderation from 9 am - 2 pm around the following questions: (1) What do you notice?, (2) What do you wonder?, and (3) What’s going on in this graph?. On the Friday following the activity, the NYT LN will publish a follow up with details about the graph and statistical observations/lessons from Sharon and the team. Here is a link to more information: https://www.nytimes.com/2017/09/06/learning/announcing-a-new-monthly-feature-whats-going-on-in-this-graph.html\n\n\nUSPROC\nThe Consortium for the Advancement of Undergraduate Statistics Education (CAUSE) and the American Statistical Association (ASA) are sponsoring the Undergraduate Statistics Project Competition (USPROC). The purpose of USPROC is to encourage the development of data analysis skills, to enhance presentation skills, and to recognize outstanding work by undergraduate statistics students. Competition tracks are available for projects at different levels (including the introductory/intermediate statistics levels). Here is a link to more information about how your students can submit their projects: https://www.causeweb.org/usproc/home\n\n\neUSR\nThe 2017 Electronic Undergraduate Statistics Research Conference (eUSR) will take place on Friday, November 3, 2017. This free e-conference includes a keynote address from a Data Scientist at Stack Overflow, a career panel including the Head of Data Science at Lyft, other panels on graduate school and diversity in Statistics and Data Science, and presentations by USPROC student award winners. I’m attaching to this e-mail a flyer that you can give your students. Here is a link to more information about how your students can sign up to participate: https://www.causeweb.org/usproc/eusrc/2017"
  },
  {
    "objectID": "posts/2017-12-05-new-intro-to-r.html",
    "href": "posts/2017-12-05-new-intro-to-r.html",
    "title": "Intro to R (MATH 130)- New section added for spring",
    "section": "",
    "text": "A second section of MATH 130 - Introduction to R has been added to the Spring 18 schedule.\n\nMW 3-4:45\nHolt 155\nWeek 1-5 only\nInstructor: Robin Donatello or Edward Roualdes (TBD)\n\nUntil open enrollment starts back up in January, contact Robin Donatello to enroll."
  },
  {
    "objectID": "posts/2019-02-23-wids.html",
    "href": "posts/2019-02-23-wids.html",
    "title": "Women in Data Science technical conference! Mon Mar 4th, Sylvesters 100",
    "section": "",
    "text": "The Global Women in Data Science (WiDS) Conference aims to inspire and educate data scientists worldwide, regardless of gender, and support women in the field. This annual one-day technical conference provides an opportunity to hear about the latest data science related research and applications in a broad set of domains, All genders are invited to participate in the conference, which features outstanding women doing outstanding work.\nChico State is holding a regional event on March 4th featuring live streaming of the event at Stanford, a lunchtime career panel featuring local women in Data Science."
  },
  {
    "objectID": "posts/2019-02-23-wids.html#one-day-technical-conference",
    "href": "posts/2019-02-23-wids.html#one-day-technical-conference",
    "title": "Women in Data Science technical conference! Mon Mar 4th, Sylvesters 100",
    "section": "",
    "text": "The Global Women in Data Science (WiDS) Conference aims to inspire and educate data scientists worldwide, regardless of gender, and support women in the field. This annual one-day technical conference provides an opportunity to hear about the latest data science related research and applications in a broad set of domains, All genders are invited to participate in the conference, which features outstanding women doing outstanding work.\nChico State is holding a regional event on March 4th featuring live streaming of the event at Stanford, a lunchtime career panel featuring local women in Data Science."
  },
  {
    "objectID": "posts/2019-02-23-wids.html#presentation-opportunities",
    "href": "posts/2019-02-23-wids.html#presentation-opportunities",
    "title": "Women in Data Science technical conference! Mon Mar 4th, Sylvesters 100",
    "section": "Presentation opportunities",
    "text": "Presentation opportunities\nWe want to hear from you. What are you working on? What challenges have you faced? What lessons have you learned or advice would you like to give? Anyone identifying as a woman is invited to share their journey, path, research, current job highlights, and recruitment opportunities."
  },
  {
    "objectID": "posts/2019-02-23-wids.html#httpswids-chico.netlify.comevent",
    "href": "posts/2019-02-23-wids.html#httpswids-chico.netlify.comevent",
    "title": "Women in Data Science technical conference! Mon Mar 4th, Sylvesters 100",
    "section": "https://wids-chico.netlify.com/event/",
    "text": "https://wids-chico.netlify.com/event/\nRegistration link: https://goo.gl/forms/oR3u2z9OMdRKj7uo2"
  },
  {
    "objectID": "posts/2019-01-22-january-updates.html",
    "href": "posts/2019-01-22-january-updates.html",
    "title": "January Updates",
    "section": "",
    "text": "DSI Workshop Spring Seminar and Workshop series starts 2/5/19\nIn addition to doing some good DataFest prep training workshops our topics for this spring include dealing with dates & times, joining tables using SQL, simple strategies to manage large data sets, Intro to version control with git, more fun with Bayesian statistics, and building a professional website in R using Markdown.\nStay tuned for an official calendar of events and announcements.\n\n\n\nCA Mayors Cup Cybersecurity Challenge 2/23/19\nThis is the very first time NorCal is participating in the annual CA Mayors Cup! Butte College is hosting and Mendocino College is participating remotely. K-12 teams are being formed now, so far, Chico High, Anderson, Chico Country Day, Ukiah high, Core Butte, Westwood High, and Laytonville!\nThey need your participatation in this event to show our community leaders, parents and educators the importance of tech education! They are looking for sponsorship $ for food, prizes and T-shirts as well. Email wendy@chicostart.com.\nLearn more at https://ca-cyberhub.org/resources/mayors-cyber-cup/\n\n\n\nSave the date: DataFest 2019! Fri 4/5- Sun 4/7\nThis year is going to be bigger and better!\nWe are collaborating with the Northern California Undergraduate Mathematics conference to open DataFest to undergraduate students from colleges all over the North State.\nSee more about the event, read what people had to say about last year’s event, and how you can help contribute to make this year awesome at the event website: https://chicodatafest.netlify.com/\nRegistration opens February 1st, 2019. Preference will be given to teams.\n\n\n\nNorcon Hacker Conference 4/13/19\nNorthern CA’s one and only hacker con. By hackers, for hackers. The Norcon Security Conference is a one-day event created by and intended for the community. This is the place where security professionals, hobbyists, and anyone interested in security come to hang out. Norcon features lectures and interactive training aimed at varying skill levels. Everyone at Norcon is encouraged to participate and learn. We embrace those from diverse backgrounds, ages, and skill levels.\nLearn more at https://growtech.io/\n\n\n\nInternet of Things and Medical Technology Advancements Create New Software Testing Needs\nLocal business out of Redding making some news by expaning their testing services to include IoT. Could be looking to expand their workforce soon! https://www.prweb.com/releases/internet_of_things_and_medical_technology_advancements_create_new_software_testing_needs/prweb16034508.htm"
  },
  {
    "objectID": "posts/2017-03-24-DSI-kickoff.html",
    "href": "posts/2017-03-24-DSI-kickoff.html",
    "title": "DSI Kick Off Meeting (& quick intro to R)",
    "section": "",
    "text": "Logistics\n\nDate: Friday March 24, 2017\nTime: 3-4:30 pm\nLocation: MLIB 045\n\nIn this kick off session we’ll discuss what Data Science is, how the Data Science Initiative at Chico State is rising to meet the challenge of preparing and training a much needed computational science workforce, and how you can be a part of it. Then we’ll explore who our Data Science community is using R.\nWorkshop Details & Materials"
  },
  {
    "objectID": "posts/2018-02-21-new-undergraduate-certificate-in-data-science-fall-18.html",
    "href": "posts/2018-02-21-new-undergraduate-certificate-in-data-science-fall-18.html",
    "title": "New Undergraduate Certificate in Data Science - Fall 18",
    "section": "",
    "text": "We are very proud to share with you that starting Fall 2018 Chico State will offer an Undergraduate Certificate in Data Science!\nThis certificate program jointly sponsored by the Department of Mathematics and Statistics and the Department of Computer Science introduces students to data science by requiring a set of interdisciplinary classes: applied statistics classes, quantitative classes and computer science (programming and database) classes.\nThe certificate is designed so that students will gain experience with skills such as inspecting, cleaning, transforming, and modeling data, unstructured data and; computational statistics; pattern recognition; data mining /predictive analytics; machine learning; data visualization; and programming. This certificate will complement a student’s academic major and prepare them for a career in which data analysis is required.\nThis step indicates that Chico State recognizes that the academic and industry need for students trained in Data Science is an immediate one. This certificate is an intermediate outcome in a longer-term plan for building our campus’ Data Science capacity.\nMore information about the curriculum and program can be found under the curriculum page on this site.\nFall enrollment starts soon, so keep an eye on this site for upcoming informational sessions and other fun workshops and research talks!\nQuestions about the program? Contact us!"
  },
  {
    "objectID": "posts/2018-08-19-post-workshop-report.html",
    "href": "posts/2018-08-19-post-workshop-report.html",
    "title": "Software Carpentry- Post workshop report",
    "section": "",
    "text": "Last week Chico State hosted it’s first Software Carpentry workshop and it was a great success. We were thrilled to have Reid Otsuji from UC San Diego and a Library Carpentry instructor come up to help teach the material.\nWe had three undergraduate students help out as technical assistant roaming helpers throughout the workshop: Grant Esparza (Computer Science), Jerry Tucay (Applied Mathematics & Statistics), and Eisley Adoremos (Statistics). Their assistance with answer questions and helping add to the collaborate class notes was invaluable! We couldn’t have done it without them.\n\nLearners\nOur learners were a mixture of undergraduate and graduate students from non technical majors, many faculty and staff from Chico State, external faculty from Sacramento State and researchers from UC Davis, and community business members. Such a blending of backgrounds and experiences was fantastic.\nWhat was most impressive was the turnout from the Center for Healthy Communities. I will be working with this Center on a new CalFresh outreach grant and am looking forward to helping to streamline and automate many of their reporting processes.\n\n\nLesson Details\nThe details of the workshop can be seen on the workshop webpage, which also includes links to the lesson materials. I will still summarize it here.\nDay 1 we started off with Reid discussing best practices on organizing and recording data in spreadsheets. He covered common pitfalls, problems with dates, data entry and the like. Learners got a chance to take a “messy” spreadsheet and try to reformat into something that is readable by a computer program. After a gentle introduction to the R language and the R studio interface, it was time for a well deserved lunch.\nThen in the afternoon I got to demonstrate how awesome markdown is, and how combined with the powers of R they too could make awesome websites (such as this one and my personal website), as well as other HTML pages and PDF reports. We dug more into the guts of the R programming language in how R handles data sets (using data frames), how to explore these data frames, how to make new variables, logical statements and such.\nDay 2 Reid introduced the learners to the Bash Shell. We discussed file hierarchy, benefits to using a command line interface as opposed to a GUI, how to navigate your file system (great setup for learning relative vs. absolute paths), and how to edit files in Nano.\n\nThe second afternoon returned us to R, this time specifically I gave a very short introduction to Data visualization using ggplot. Only having an hour I really didn’t have time to get into many of the statistical graphic examples I would have liked to. The other main topic that afternoon was using dplyr for data manipulation and aggregation.\n\nDay 3 I have been toying around with writing a lesson for contribution to the Carpentries on how to build a website using RMarkdown. I wrote it originally to test out at a Carpentry workshop at UC Davis in January 17, but got food poisoning the night before so I didn’t get to test it out. Reid was interested so we invited everyone to attend an optional 3rd morning on using git and GitHub for version control, and building simple websites.\nI was thrilled when 6 participants (most from CHC) along with the 3 student helpers showed up to have fun with git. I really wish we had a full day to devote to this. We only had time to teach the bare minimum git (what it does,add, commit, push and pull) enough to use git along with R projects to make the website. Everyone walked out of that half day with a functioning webpage, and we had a great discussion about what it could be used for (class notes, project website, informational dashboard, file submission etc)\n\n\nCollaboration\nThroughout the workshop, participants took notes using the online markdown document sharing platform called HackMD. HackMD is like Google docs but written in Markdown. It was a great hands on way for learners to see how to write Markdown code without “formal” instruction. The notes have been locked at this point and are available for view and downloading without any login necessary.\n\n\nFeedback\nWhile I know Reid and I had fun, what was more important is that the learners had fun and felt their time was worthwhile. As part of being an officially recognized Carpentry workshop, The Carpentries hosted a pre and post survey. This is critical for the instructors to have to help assess if we were successful in our attempts to share these skills and tools. I want to share some kind words we received via email,\n\nThe workshop was a real help in getting started with R. I’m really glad that I attended.\n\nand survey responses about things that were considered major strengths of the workshop\n\npurposefully having us make mistakes and learning how to correct them -strategies for trouble shooting\n\n\nHackMD was critical to staying on track Very open to on-going questions and discusssions on how applied to different disciplines\n\n\nShowed us ways to apply these techniques to our own research.\n\n\nI got exposure to coding and it was amazing how relevant it was to the type of work I’ve done before in excel and how easier it is to work on in R vs. excel.\n\nI look forward to reviewing the rest of the survey information, especially the section on what we can do to improve. It’s important for all instructors to understand we can always get better, and we are very thankful for the information that the learners provided.\n\n\nFuture learning\nThe DSI will continue hosting weekly community coding sessions, short workshops and seminars throughout the Fall 2018 semester. We are always looking for people interested in speaking and sharing their knowledge. If your group would like to do a personalized set of trainings please contact us for details.\n\n\n\nLinks\n\nhttps://software-carpentry.org/\nhttps://www2.archivists.org/prof-education/faculty/reid-otsuji\nhttps://librarycarpentry.org/\nhttps://www.rstudio.com/\nhttps://github.com/\nhttps://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects\nhttps://hackmd.io/sfN_8XIlQxWQn2UFRZ0kXA?view\nhttps://carpentries.org/"
  },
  {
    "objectID": "posts/2021-09-23-fall-data-challenge/index.en.html",
    "href": "posts/2021-09-23-fall-data-challenge/index.en.html",
    "title": "Using Data to Fight Food Insecurity",
    "section": "",
    "text": "The Fall Data Challenge (https://thisisstatistics.org/falldatachallenge/) starts next Monday on October 11th. This is a GREAT opportunity for students to\n\napply statistical and data wrangling skills to important real-world issues and make recommendations to combat this critical issue\ncompete for prizes, T-shirts & bragging rights\nPractice for DataFest in the Spring!\n\nThis is a team event open to all majors. We welcome pre-formed teams as well as individuals! There will be a kickoff event Monday 10/11 night where teams can be formed. Late joins are also welcome!\nPlease see attached flier for more information. If you are interested, please contact Robin Donatello at rdonatello@csuchico.edu."
  },
  {
    "objectID": "posts/2021-05-11-fall-internship-opportunity.html",
    "href": "posts/2021-05-11-fall-internship-opportunity.html",
    "title": "Fall 21 internship opportunity",
    "section": "",
    "text": "Due to the great success we had this Spring, we are offering another Data Science internship experience with the Center for Healthy Communities. This flexible, 3 unit internship is focused on the management, analysis and reporting of data through a variety of projects relating to basic needs and our communities health.\nThis is a great opportunity for students who need to complete the Capstone for the Data Science Certificate or students who need additional units to round out their schedules.\nDeadline to submit the on-line application is June 4th.\nFor additional details, please view the Virtual Data Science Internship Job Description.\nPlease email datascience@csuchico.edu with any questions.\nImage credit Women of Color in Tech"
  },
  {
    "objectID": "posts/2019-01-21-community-coding-now-for-credit.html",
    "href": "posts/2019-01-21-community-coding-now-for-credit.html",
    "title": "Community Coding - Now for credit!",
    "section": "",
    "text": "Spring 19 semester is upon us and we’re exicted to start up Community Coding again."
  },
  {
    "objectID": "posts/2019-01-21-community-coding-now-for-credit.html#what-is-community-coding",
    "href": "posts/2019-01-21-community-coding-now-for-credit.html#what-is-community-coding",
    "title": "Community Coding - Now for credit!",
    "section": "What is community coding?",
    "text": "What is community coding?\nStudents, staff, faculty, and the public are invited to join our Community Coding sessions. Bring your computer, coding projects, and your questions to this open working environment."
  },
  {
    "objectID": "posts/2019-01-21-community-coding-now-for-credit.html#what-is-this-for-credit-option",
    "href": "posts/2019-01-21-community-coding-now-for-credit.html#what-is-this-for-credit-option",
    "title": "Community Coding - Now for credit!",
    "section": "What is this for credit option?",
    "text": "What is this for credit option?\nCommit to studying 1 hr. per week for your (not necessarily CS) programming course and earn credit. Enroll in MATH 290-02 (5854), a 1 unit credit/no-credit course. Credit is earned by attending at least 10 times.\nThe DSI Spring seminar series of talks and workshops will overlap with these hours. Approximately once per week we will have a guest speaker talk about some interesting Data Science topic or provide a hands-on workshop experience to learn a new tip or trick in R, Python, Tableau or some other program."
  },
  {
    "objectID": "posts/2024-12-01-were_hiring/index.en.html",
    "href": "posts/2024-12-01-were_hiring/index.en.html",
    "title": "We’re Hiring!",
    "section": "",
    "text": "The Wildcat Data Hub(WDH) supports data-driven research for students, faculty, and the community while offering paid, hands-on opportunities for student interns. By combining academic expertise with real-world projects, WDH is a great way to build skills, gain experience, and make an impact through assisting others with their research.\n\nJob Title: Data Science Research and Consulting Assistant\nTime Commitment: 9 hr/wk during Spring term\nWage: Eligible for $17/hr after successful probationary period\nUnit Requirement: 1-3 Units of Math 589\nRequirements: At least one upper division or graduate class in Statistics or Data Science using R or Python.\nMajors: Any\n\nThis is a two part internship. After completing a probationary period of 45 hours of unpaid work, a successful demonstration of professional competencies, and a positive faculty recommendation, you will be considered to move into the second, paid portion of the internship for an additional 90 hours.\nThe Consulting Assistant works under a faculty mentor to assist campus researchers with unique data collection, analysis, and scripting related projects. In addition to working directly with clients, interns will assist the Hub director on development and expansion of the WDH by conducting outreach and recruitment activities and maintaining public communication channels such as the website and social media. Specific tasks will vary depending on the needs of the researchers and the skills of the student assistant.\nExample Responsibilities Include:\n\nProvide drop in assistance on coding problems through Community Coding (similar to math tutoring, but for data science programming languages)\nProviding general technical support: Answering questions about computational, data analysis and visualization tools and techniques.\nAssisting researchers with all parts of the Data Science life cycle including\n\nData cleaning and preparation (e.g. removing duplicates, handling missing values, and reformatting data)\nData analysis (e.g using statistical software to perform descriptive and inferential analysis)\nData visualization (e.g. creating appropriate charts, and graphs)\nAutomation (e.g. writing functions and scripts to perform repetitive or complex tasks)\n\n\nNote: Like subject matter tutoring services, the Wildcat Data Hub does not accept requests to help with homework assignments.\nExample Skills Developed During the Internship:\n\nUse agile project management tools (ClickUp) to maintain a project timeline with deadlines and deliverables\nImproved solution-seeking skills (e.g. finding answers on places like Google, Stack Overflow)\nProfessionally collaborate and communicate within a remote team setting using various communication systems such as email and Microsoft Teams.\nUnderstand and practice how Statistics and Data Science tools and techniques contribute to the success of student and faculty researchers.\nImproved ability to communicate complex technical concepts to clients from diverse backgrounds, active listening to their needs, and providing timely updates to build strong relationships.\n\nPRIORITY APPLICATION DEADLINE: By 5pm on Dec 13th Click here for the online application link. If you have questions, please contact the Director of the Wildcat Data Hub, Robin Donatello at rdonatello@csuchico.edu"
  },
  {
    "objectID": "communityCoding.html",
    "href": "communityCoding.html",
    "title": "Community Coding",
    "section": "",
    "text": "Got data and working on analysis? Got questions on using R, Python or other programming languages? Come and hang out with other coders in a welcoming and supportive environment.\nStudents, staff, faculty, and the public are invited to join our Community Coding sessions. Bring your computer, coding projects, and questions to this open working environment.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n❮\n\n\n❯\nSign In  Please sign in to help us track usage and keep this great space!"
  },
  {
    "objectID": "communityCoding.html#schedule-locations-for-fall-2025",
    "href": "communityCoding.html#schedule-locations-for-fall-2025",
    "title": "Community Coding",
    "section": "Schedule & Locations for Fall 2025",
    "text": "Schedule & Locations for Fall 2025\nCommunity Coding is regularly held at the Innovation Lab on the second floor of the Meriam Library next to the print center. Additional drop in help sessions are available by individual faculty in their office or over Zoom."
  },
  {
    "objectID": "posts/2018-03-15-bayesian-seminar-roualdes.html",
    "href": "posts/2018-03-15-bayesian-seminar-roualdes.html",
    "title": "Seminar: Introduction to Bayesian Modeling",
    "section": "",
    "text": "Join us on Thursday March 15 at 3pm in MLIB 442 to hear Dr. Edward Roualdes from Statistics present the benefits of Bayesian Modeling. [RSVP here]\n\nAbstract:\n\nMuch of the statistics taught today is more accurately known as frequentist statistics – a distinction that gets little attention. However, an alternative exists and the alternative bridges what some see as a gap between statisticians and computer scientists who apply mathematical models to data. Bayesian statistics is the alternative. This talk will motivate Bayesian statistics in multiple ways. First, we’ll introduce Bayesian statistics with some old baseball data. Then we’ll dissect the baseball example, describing just how random variables play a role. The entire discussion will be high level, with little to no statistical background required. Pretty plots will complement all mathematical details._\n\nSee the rest of the DSI Spring 18 [Seminar and Workshop schedule] here."
  },
  {
    "objectID": "posts/2017-03-24-install_R_homebrew.html",
    "href": "posts/2017-03-24-install_R_homebrew.html",
    "title": "Installing R with Homebrew on Mac OS X",
    "section": "",
    "text": "This document explains how to install R and RStudio with Homebrew on Mac OS.\n\nMain Instructions\nThe steps below will install Homebrew, R, and RStudio. Open a terminal and run the following commands.\n\nInstall Homebrew.\n\nusr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"\nThis command will download, install, and set up Homebrew. The first time a brew command runs it will ask for a password.\n\nInstall R with the following commands:\n\nbrew tap homebrew/science # adds another source for applications.\nbrew install r            # runs installer of r\nThe first command is necessary if you want to add science/math type applications. The second command handles all the installation of R itself. As of 3.25.2017 this installs version . This can take a while because Homebrew downloads then builds the tools though it tends to be faster an easier than manual installation.\n\nInstall RStudio with the following command:\n\nbrew cask install rstudio\nTry navigating to RStudio to verify installation.\n\nOptional Set up RStudio to work from the command line.\n\necho \"alias rstudio='open -a RStudio'\" &gt;&gt; ~/.bash_profile\nsource ~/.bash_profile\nThis sets up your bash profile to run RStudio when rstudio is entered into the command line (i.e. rstudio example.rmd). It adds and alias to your ~/.bash_profile so you can remove it if you want.\nThis concludes the installation of RStudio. The rest of this documentation is more on Homebrew.\n\n\nBackground and Info on Homebrew.\n\nWhat is Homebrew.\nHomebrew is a package manager for macOS (MacOS X) that claims to be The missing package manager to macOS. You can use this to find open source and UNIX tools that most Linux distros have but don’t natively show up on Mac (i.e. wget and imagemagick). It works from the command line and it makes installing, updating, and removing packages easier.\n\n\nSome useful commands:\nBe careful with these because they do alter/remove applications.\n\nUpdate and Upgrade your packages.\n$ brew update   # update the formula\n$ brew upgrade  # Upgrade outdated, unpinned brews.\nList your installed packages.\n$ brew list     # lists all installed brews\nRemove an Application bash     $ brew uninstall &lt;formula&gt;\n\nFor more information on Homebrew navigate to brew.sh."
  },
  {
    "objectID": "posts/2019-02-13-intro-sql.html",
    "href": "posts/2019-02-13-intro-sql.html",
    "title": "DSI seminar 2/19: Managing data from multiple tables using SQL",
    "section": "",
    "text": "Presenter: Robin Donatello, Assistant Professor of Statistics\nDate: Tuesday February 19th, 2019\nTime: 3-3:50 pm\nLocation: Tehama 116\nRSVP: http://goo.gl/forms/BnjV0y5zoz09tUU83\n\n\n\nYou’ve got person level data (like country of origin) in one data set, annual data (like income) for each person across multiple years in another data set, but each person is on a team and team characteristics are on yet a THIRD data set. How do you link all this information together to gain any kind of insights? SQL is a powerful database language that can be used in it’s own program, but also inside many other programs like R, SAS and Python. Come learn the fundamentals of how to link information together across multiple tables, and how to create summary information using this powerful SQL language.\n\n\n\nI will be demonstrating SQL commands using R, but this talk is aimed at everyone.\n\nR Code demonstrating SQL [R code file]\n[Slides]\n\n\n\n\n\nIntro to SQL course on Data Camp https://www.datacamp.com/courses/intro-to-sql-for-data-science\nSoftware Carpentry lesson on Databases and SQL: http://swcarpentry.github.io/sql-novice-survey/\nData Management with SQL for Ecologists: https://datacarpentry.org/sql-ecology-lesson/\nUsing SQL in R\nUsing SQL in Python\n\nhttps://towardsdatascience.com/sql-and-etl-an-introduction-to-sqlalchemy-in-python-fc66e8be1cd4\nhttps://datatofish.com/how-to-connect-python-to-sql-server-using-pyodbc/\n\nDB Browser for SQLite (standalone program) https://sqlitebrowser.org/"
  },
  {
    "objectID": "posts/2019-02-13-intro-sql.html#description",
    "href": "posts/2019-02-13-intro-sql.html#description",
    "title": "DSI seminar 2/19: Managing data from multiple tables using SQL",
    "section": "",
    "text": "You’ve got person level data (like country of origin) in one data set, annual data (like income) for each person across multiple years in another data set, but each person is on a team and team characteristics are on yet a THIRD data set. How do you link all this information together to gain any kind of insights? SQL is a powerful database language that can be used in it’s own program, but also inside many other programs like R, SAS and Python. Come learn the fundamentals of how to link information together across multiple tables, and how to create summary information using this powerful SQL language."
  },
  {
    "objectID": "posts/2019-02-13-intro-sql.html#workshop-files",
    "href": "posts/2019-02-13-intro-sql.html#workshop-files",
    "title": "DSI seminar 2/19: Managing data from multiple tables using SQL",
    "section": "",
    "text": "I will be demonstrating SQL commands using R, but this talk is aimed at everyone.\n\nR Code demonstrating SQL [R code file]\n[Slides]"
  },
  {
    "objectID": "posts/2019-02-13-intro-sql.html#additional-potential-helpful-resources",
    "href": "posts/2019-02-13-intro-sql.html#additional-potential-helpful-resources",
    "title": "DSI seminar 2/19: Managing data from multiple tables using SQL",
    "section": "",
    "text": "Intro to SQL course on Data Camp https://www.datacamp.com/courses/intro-to-sql-for-data-science\nSoftware Carpentry lesson on Databases and SQL: http://swcarpentry.github.io/sql-novice-survey/\nData Management with SQL for Ecologists: https://datacarpentry.org/sql-ecology-lesson/\nUsing SQL in R\nUsing SQL in Python\n\nhttps://towardsdatascience.com/sql-and-etl-an-introduction-to-sqlalchemy-in-python-fc66e8be1cd4\nhttps://datatofish.com/how-to-connect-python-to-sql-server-using-pyodbc/\n\nDB Browser for SQLite (standalone program) https://sqlitebrowser.org/"
  },
  {
    "objectID": "posts/2018-02-18-stan-and-c-readings.html",
    "href": "posts/2018-02-18-stan-and-c-readings.html",
    "title": "Stan and C++ readings",
    "section": "",
    "text": "Contributed Post by Edward Roualdes\nLately, I’ve been reading everything I can get my hands on surrounding Stan, the probabilistic programming language. A particularly awesome paper, written by Bob Carpenter et. al., discusses their efforts at automatic differentiation. The paper mentions quite a few tricks of the trade surrounding the wide world of C++. In the last week, I dove head first into these various C++ ideas. I found them interesting, and I hope someone else will too.\n\nTemplate\nPImpl\nRAII\nlvalues and rvalues"
  },
  {
    "objectID": "posts/2022-10-27-fooling-facial-recognition/index.en.html",
    "href": "posts/2022-10-27-fooling-facial-recognition/index.en.html",
    "title": "Fooling Facial Recognition",
    "section": "",
    "text": "Most people have seen deep fakes and AI generated images online but people often don’t know the underlying technology behind it. For my senior Capstone, I am conducting a research project which uses Adversarial Networks and found this to be a very cool realm of machine learning.\n\nThe basic design of a Adversarial system include two different networks, the generator and the discriminator. The Generator will simply take in a random seed as an input and use that number to calculate pixel values. The Discriminator will be paired with a training set which is a mix of real images and generated images. It will then train over this set and classify them as either real or fake. Both networks will then be trained on the accuracy of the discriminator but in opposite directions. While the discriminator will try to maximize it’s accuracy, the generator will try to minimize it by generating images that the discriminator will think its real. This process has been used and has produce some facinating results in the machine learning sphere."
  },
  {
    "objectID": "posts/2022-10-27-fooling-facial-recognition/index.en.html#a-brief-introduction-to-adversarial-networks",
    "href": "posts/2022-10-27-fooling-facial-recognition/index.en.html#a-brief-introduction-to-adversarial-networks",
    "title": "Fooling Facial Recognition",
    "section": "",
    "text": "Most people have seen deep fakes and AI generated images online but people often don’t know the underlying technology behind it. For my senior Capstone, I am conducting a research project which uses Adversarial Networks and found this to be a very cool realm of machine learning.\n\nThe basic design of a Adversarial system include two different networks, the generator and the discriminator. The Generator will simply take in a random seed as an input and use that number to calculate pixel values. The Discriminator will be paired with a training set which is a mix of real images and generated images. It will then train over this set and classify them as either real or fake. Both networks will then be trained on the accuracy of the discriminator but in opposite directions. While the discriminator will try to maximize it’s accuracy, the generator will try to minimize it by generating images that the discriminator will think its real. This process has been used and has produce some facinating results in the machine learning sphere."
  },
  {
    "objectID": "posts/2022-10-27-fooling-facial-recognition/index.en.html#tidy-models-tutorial",
    "href": "posts/2022-10-27-fooling-facial-recognition/index.en.html#tidy-models-tutorial",
    "title": "Fooling Facial Recognition",
    "section": "Tidy Models Tutorial",
    "text": "Tidy Models Tutorial\nIn this tutorial I will walk you through how to fit a linear model to a data set using the tidy models package. In this tutorial I will be using a CalCOFI data set of oceanic measurements of temperature in Celsius and depth in Meters. Here we will see what the relationship between temperature and depth shallower than 500 meters.\n\nLibraries\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(readr)\n\n\nStep 1 - Import and Setup Dataset\nOur first step will be to import CalCOFI data and filter for our desired depth, done by the R code below.\n#Base Dataset\nCalCOFI &lt;- read.csv(\"CalCOFI.csv\")\n\n# Depth lower than 500 filtered out\nCalCOFI &lt;- CalCOFI %&gt;%\nfilter(Depthm &lt; 500)\n\n\nStep 2 - Initial Visualization\nBefore we begin modeling, we will want to see if linear modeling is applicable in this case. We can do this by some data visualization with a linear trend line, done by the R code below.\nCalCOFI %&gt;%\nggplot(aes(Depthm, T_degC)) + geom_point() + geom_smooth(method = \"lm\", se = FALSE)\n\nBased on the graph above, the fit can be roughly described as linear and makes linear regression applicable.\n\n\nStep 3 - Build and Fit Model\nNow we can Build and fit out model to our data, done by the R code below.\n# Build\nmodel &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\")\n\n# Fit\nfit &lt;- model %&gt;%\n  fit(T_degC~Depthm, data = CalCOFI)\n\n\nStep 4 - Interpretation\nOur last step is to interpret the model we have fit. So to view our coefficients, see R code below.\ntidy(fit)\n## # A tibble: 2 × 5\n##   term        estimate std.error statistic p.value\n##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n## 1 (Intercept)  15.0    0.00415       3609.       0\n## 2 Depthm       -0.0239 0.0000225    -1065.       0\nFrom this we can see an association of depth to temperature of -0.0239. This means that on average, for every single meter increase of depth would result a decrease in temperature of 0.0239 Celsius."
  },
  {
    "objectID": "posts/2022-10-27-fooling-facial-recognition/index.en.html#fooling-facial-recognition-software-using-convoltional-generative-adversarial-networks",
    "href": "posts/2022-10-27-fooling-facial-recognition/index.en.html#fooling-facial-recognition-software-using-convoltional-generative-adversarial-networks",
    "title": "Fooling Facial Recognition",
    "section": "Fooling Facial Recognition Software Using Convoltional Generative Adversarial Networks",
    "text": "Fooling Facial Recognition Software Using Convoltional Generative Adversarial Networks\n\nBackground\nFacial Recognition software is becoming more and more prevalent in our daily lives from our phones to law enforcement. To help prevent the misuse of this kind of software we should further our understanding of these algorithms so they don’t remain as mysterious black boxes. This project’s goal was to test the accuracy of open-source pre-trained Facial Recognition models using Deep Convolutional Generative Adversarial Networks or DCGANs. The DCGAN was used to generate images from random noise which would then be scored based on what confidence score it can elicit from pre-existing facial recognition models for a specific person’s Identity (such as The Rock). This project focuses on generating images that are identified as one of four recognized Identities by the recognition model. The generated test images that had a high confidence score of being a recognized image were subsequently looked at by humans to see if they looked like their classified identities. This will give us insight on how an end user can create fake generated images and still elicit high confidence scores from facial recognition software.\n\n\nExperiment Overview\n\n\nNoise:\n\nnormally distributed random numbers\n\n\n\nGenerator: Deep Convolutional Generator\nInput Layer:\n\n100 values Hidden Layers:\nFully Connected\nTransposed Convolution A.K.A Deconvolution\nActivation Function: LeakyReLU\n\nOutput Layer:\n\n224 x 224 pixels\nActivation Function: Sigmoid\n\n\n\nFacial Recognition Model\nVGGFace2 Models implemented in Keras\n\nInput preprocessing\nConvolutional Architectures\nResNet50 and SENet50\n\nOutput:\n\nConfidences on 8631 Identities\n\n\n\nTraining the Generator\nSetup in Jupyter using Python\n\nEach Generator focuses on 1 Identity\nBatch size of 5\nLoss based on how high a confidence the Recognition Model outputs\nLoss Calculated using Cross Entropy\nExponentially Decaying Learning Rate\n\n\n\nGPU:\n\nNVIDIA GeForce GTX 1660 Ti with Max-Q Design\n\n\n\n\nResults\n\nReal Face Controls\n\n\n\nGenerated Images\n\n\n\n\nConclusion\nThe results of this project show that it is possible to train a Generator for each Identity in the VGGFace2 and achieve a high confidence score. This method is still contingent on having access to the full model. This indicates that open source models such as these can be fooled by potentially malicious actors while other closed-source models may remain safe, but more research would be advised. Future research would best be targeted at replication using smaller generators, testing other learning rates and loss functions, testing this method for Facial Detectors since they are often paired with Facial Recognition, and using this method to improve model accuracy through training with generated false images."
  },
  {
    "objectID": "posts/2023-11-13-intro-python-spring-2024/index.en.html",
    "href": "posts/2023-11-13-intro-python-spring-2024/index.en.html",
    "title": "Announcing Introduction to Python MATH 131 in Spring 2024",
    "section": "",
    "text": "We are excited to offer, for the first time, Introduction to Python as MATH 131 in spring 2024. Like the sister course MATH 130 (Intro to R), this will be a 1 unit, credit / no credit course that only lasts the first 5 weeks of the semester.\nMATH 131 in spring 2024 will be Tuesday/Thursday from 2 - 3.15pm in Holt 277 from 01/22 to 02/23.\nNo experience is necessary and the course is open to all majors who are interested in learning about computer programming.\nimport random\ndef will_you_join_us():\n    return random.choice([“yes”, “no”, “idk, let me check...\"])\nThe format of the course will be very similar to MATH 130, just ported into a new language. We’ll cover the same overall topics and end the course with a project to summarize the topics learned.\nIf you have any questions, shoot me, Edward, an email: eroualdes@csuchico.edu."
  },
  {
    "objectID": "posts/2017-08-01-speakers-needed.html",
    "href": "posts/2017-08-01-speakers-needed.html",
    "title": "Call for speakers and makers",
    "section": "",
    "text": "Looking for speakers for F17 DSI workshops & lightning talks\n\nIs your company or department doing something fun and interesting with Data Science?\nDo you know a coding tip/trick that you would like to share with the community?\nDo you have some interesting insights that you would like to share?\n\nCome share your ideas/thoughts/project/insights with the Data Science community\nContact us for more info & to schedule your session."
  },
  {
    "objectID": "posts/2024-03-15-datafest-2024/index.en.html#what-is-the-asa-datafest",
    "href": "posts/2024-03-15-datafest-2024/index.en.html#what-is-the-asa-datafest",
    "title": "DataFest 2024 @Chico April 12-14",
    "section": "What is the ASA DataFest?",
    "text": "What is the ASA DataFest?\nASA DataFest is a data hackathon for undergraduate students, sponsored by the American Statistical Association and founded at UCLA, in 2011. A data analysis problem is presented in the form of a dataset and an associated challenge. Teams of students get a dataset on Friday afternoon and work on the problem until Sunday afternoon where they present their findings. After two days of intense data wrangling, analysis, and presentation design, each team is allowed a few minutes and no more than two slides to impress a panel of judges. Prizes are given for Best in Show, Best Visualization, and Best Use of External Data.\nUndergraduates from all majors are welcome. Some of the most diverse teams have been the most successful.\nThis event is open to ALL undergraduates in the North State!\nLearn more about this national event at the event website: https://norcaldatafest.netlify.app/\n\nRegistration closes March 29th"
  },
  {
    "objectID": "posts/2019-04-08-norcon.html",
    "href": "posts/2019-04-08-norcon.html",
    "title": "Norcon - Hacker Conference April 13th",
    "section": "",
    "text": "Chico’s one and only hacker con. By hackers, for hackers. The Norcon Security Conference is a one-day event created by and intended for the community. This is the place where security professionals, hobbyists, and anyone interested in security can come to hang out. Norcon features lectures and interactive training aimed at varying skill levels. Everyone at Norcon is encouraged to participate and learn. We embrace those from diverse backgrounds, ages, and skill levels.\n\nScan the code below to start the Crypto Scavenger Hunt!"
  },
  {
    "objectID": "posts/2025-05-09-Math500-Seminar-Abel-Rodriguez/index.html",
    "href": "posts/2025-05-09-Math500-Seminar-Abel-Rodriguez/index.html",
    "title": "What Does Your Congressperson Really Think?",
    "section": "",
    "text": "While party affiliation often drives how elected representatives vote, it’s not the whole story.\nIn this seminar, Dr. Abel Rodriguez introduces a data-driven approach to uncovering ideological preferences using statistical models and voting data.\nYou’ll learn how social scientists and statisticians use tools like: - Latent Factor Models - Item Response Theory (IRT) - Ideological scaling\nto map out where legislators and judges fall on the political spectrum — including identifying centrists, extremists, and outliers across both parties."
  },
  {
    "objectID": "posts/2025-05-09-Math500-Seminar-Abel-Rodriguez/index.html#seminar-overview",
    "href": "posts/2025-05-09-Math500-Seminar-Abel-Rodriguez/index.html#seminar-overview",
    "title": "What Does Your Congressperson Really Think?",
    "section": "",
    "text": "While party affiliation often drives how elected representatives vote, it’s not the whole story.\nIn this seminar, Dr. Abel Rodriguez introduces a data-driven approach to uncovering ideological preferences using statistical models and voting data.\nYou’ll learn how social scientists and statisticians use tools like: - Latent Factor Models - Item Response Theory (IRT) - Ideological scaling\nto map out where legislators and judges fall on the political spectrum — including identifying centrists, extremists, and outliers across both parties."
  },
  {
    "objectID": "posts/2025-05-09-Math500-Seminar-Abel-Rodriguez/index.html#key-topics-covered",
    "href": "posts/2025-05-09-Math500-Seminar-Abel-Rodriguez/index.html#key-topics-covered",
    "title": "What Does Your Congressperson Really Think?",
    "section": "🔍 Key Topics Covered",
    "text": "🔍 Key Topics Covered\n\nHow to rank legislators/judges on an ideological scale\nHow latent variables reveal hidden policy stances\nInsights from U.S. Congressional and Supreme Court data\n\n\n📅 Date: May 9, 2025\n📍 Location: Holt Hall 291\n👤 Speaker: Dr. Abel Rodriguez – Learn more"
  },
  {
    "objectID": "posts/2020-01-22-spring20-cc.html",
    "href": "posts/2020-01-22-spring20-cc.html",
    "title": "Extended hours for Community coding! Spring 20",
    "section": "",
    "text": "Hours & Location\n\nMW 10-12, Tehama 116\nT 2-4, Butte 518\nW 5:30-7pm Butte 518\nR 4-6pm Butte 518\nF 1-2pm, 3-4pm, Butte 518\n\nFlyer with hours: bit.ly/cc_hours\n\n\nWhat is community coding?\nTaking a programming class this semester? Or a class doing statistical data analysis? Have a pet programming/data science project you’re working on? Students, staff, faculty, and the public are invited to join our Community Coding sessions. Bring your computer, coding projects, and your questions to this open working environment.\n\n\nWhat is this for credit option?\nHelp your study habit by committing to attending 1 hr. per week and earn credit. Enroll in MATH 290-02 (5069), a 1-unit credit/no-credit course. Credit is earned by attending at least 10 times."
  },
  {
    "objectID": "posts/2017-04-28-stat-models-announce.html",
    "href": "posts/2017-04-28-stat-models-announce.html",
    "title": "DSI Workshop - Fitting introductory statistical models in R",
    "section": "",
    "text": "Date: Friday April 28, 2017\nTime: 3-4:30 pm\nLocation: MLIB 442\nPresenter: Robin Donatello: rdonatello@csuchico.edu\n[Workshop Details & Materials]\n\n\n\nIn this workshop you will learn and practice the following:\n\nHow to conduct a handful of statistical analysis techniques using R\n\nNote: This workshop does not cover the Statistical Methodology or theory behind these statistical procedures. This workshop assumes that you have checked model assumptions and have chosen the most appropriate model for the research question being analyzed.\n\n\n\n\nA laptop with R (v3.3.0+), and RStudio (v1.1.136) installed and operational.\nThe cdc data downloaded and put into a workshop folder. (Right click and choose “save as”)\nggplot2 version 2.2.1 or higher installed.\ngridExtra version 2.2.1 or higher installed\n\nNeed a refresher on how to make plots? See the Data ViZ DSI tutorial from April 21, 2017."
  },
  {
    "objectID": "posts/2017-04-28-stat-models-announce.html#learning-objectives",
    "href": "posts/2017-04-28-stat-models-announce.html#learning-objectives",
    "title": "DSI Workshop - Fitting introductory statistical models in R",
    "section": "",
    "text": "In this workshop you will learn and practice the following:\n\nHow to conduct a handful of statistical analysis techniques using R\n\nNote: This workshop does not cover the Statistical Methodology or theory behind these statistical procedures. This workshop assumes that you have checked model assumptions and have chosen the most appropriate model for the research question being analyzed."
  },
  {
    "objectID": "posts/2017-04-28-stat-models-announce.html#pre-requirements-setup",
    "href": "posts/2017-04-28-stat-models-announce.html#pre-requirements-setup",
    "title": "DSI Workshop - Fitting introductory statistical models in R",
    "section": "",
    "text": "A laptop with R (v3.3.0+), and RStudio (v1.1.136) installed and operational.\nThe cdc data downloaded and put into a workshop folder. (Right click and choose “save as”)\nggplot2 version 2.2.1 or higher installed.\ngridExtra version 2.2.1 or higher installed\n\nNeed a refresher on how to make plots? See the Data ViZ DSI tutorial from April 21, 2017."
  },
  {
    "objectID": "posts/2022-11-27-tech-justice/index.en.html",
    "href": "posts/2022-11-27-tech-justice/index.en.html",
    "title": "Exploring Tech Justice: The Just Data Lab",
    "section": "",
    "text": "As part of the Advanced Data Science, we explored how technology can perpetuate existing structures of discrimination through its design and application. As a part of this exploration, we read Race After Technology by Ruha Benjamin. As a person who may use data and algorithms to make decisions in the future it is important for me to understand how others experience these algorithims, and what should be done in light of the role technology. In this blog post I will introduce what the Just Data Lab and how they are leveraging data and technology for justice"
  },
  {
    "objectID": "posts/2022-11-27-tech-justice/index.en.html#what-is-the-just-data-lab",
    "href": "posts/2022-11-27-tech-justice/index.en.html#what-is-the-just-data-lab",
    "title": "Exploring Tech Justice: The Just Data Lab",
    "section": "What is the Just Data Lab?",
    "text": "What is the Just Data Lab?\nAuthor of Race After Technology, Ruha Benjamin, founded the Ida B. Wells Just Data Lab at Princeton. The lab was named after late 19th and early 20th centuries prominent journalist, activist, and researcher Ida B. Wells. Click here for a brief biography of Ida B. Wells. The goal of the lab is to “rethink and retool data for justice”. The lab addresses a variety of issues from revealing companies engaged in immigrant surveillance to developing strategies to aid formerly incarcerated small business owners. Additionally, the lab has a variety of tech and social justice initiatives. The lab has lots of cool projects! The Barred Business Project provides business grants to support the work of formerly incarcerated Black, Transgender, Queer, Native, and Disabled business owners. In order to further enhance the mission to help these groups, the team leveraged data to tell stories by creating an interactive map. Here you can see the map. They also provide a list of resources for community engagement. One I found particularly interesting was the Equitable Internet Initiative. This initiative seeks to increase internet access in underserved Detroit neighborhoods. One of the reasons I found this initiative particularly interesting was the emphasis on community engagement. The majority of the workers come from the neighborhoods they work in. This is just one of the initiatives the lab is a part of."
  },
  {
    "objectID": "posts/2022-11-27-tech-justice/index.en.html#how-can-people-get-involved-in-this-organization",
    "href": "posts/2022-11-27-tech-justice/index.en.html#how-can-people-get-involved-in-this-organization",
    "title": "Exploring Tech Justice: The Just Data Lab",
    "section": "How can people get involved in this organization?",
    "text": "How can people get involved in this organization?\nCheckout the Just Data Lab’s website. Here, the teams have worked hard, using the data and explaining the situation of many groups who are under-represented and may have different experiences than you. Go to their website and read up on some of the work they have done. This link will also show you more about other organizations that may be in the area or have options to get involved for those out of the area. (Note: You may have to scroll down for the page to load.) Educating yourself is another way to get involved. If you are interested in learning more about data ethic read Race After Technology and/or follow the author of Race After Technology and founder of the Just Data Lab, Ruha Benjamin on Twitter.\nIf you want to take it a step further and are a part of a community-based organization focused on social justice you can apply to partner with the lab! This is an incredible opportunity to access the resources of the lab to enhance your organization. Checkout the logistics of applying here!"
  },
  {
    "objectID": "posts/2022-11-27-tech-justice/index.en.html#what-is-a-tech-justice-issue-in-your-own-community-that-you-and-your-neighbors-could-address",
    "href": "posts/2022-11-27-tech-justice/index.en.html#what-is-a-tech-justice-issue-in-your-own-community-that-you-and-your-neighbors-could-address",
    "title": "Exploring Tech Justice: The Just Data Lab",
    "section": "What is a tech justice issue in your own community that you and your neighbors could address?",
    "text": "What is a tech justice issue in your own community that you and your neighbors could address?\nOne potential tech justice issue that could be addressed in the community, Chico State’s Campus, is mapping surveillance. The lab accentuates mapping due to the ease of understanding. There are likely surveillance technologies used in the community many are unaware of. To address this we could research the surveillance technologies used in our community. Then this information could be used to create a map for public use. It is important that the community is aware of the surveillance and the usage of the surveillance.\n\nAuthor Bio\nMy name is Faith, and I’m a Chico State graduate. I majored in mathematics and economics. I am interested in harnessing the power of mathematics to study real world problems. Checkout my linkedin profile!"
  },
  {
    "objectID": "posts/2018-08-19-seminar-labkey.html",
    "href": "posts/2018-08-19-seminar-labkey.html",
    "title": "Seminar: LabKey Server",
    "section": "",
    "text": "The DSI is excited for our first speaker for Fall 2018. Jim Piper has been a regular at our DSI talks and events and is going to share with us his work on LabKey Server, a team collaboration software program specialized for the sciences. A hands demo of this program will be included.\nLight refreshments will be provided by the DSI."
  },
  {
    "objectID": "posts/2018-08-19-seminar-labkey.html#what-is-labkey-server",
    "href": "posts/2018-08-19-seminar-labkey.html#what-is-labkey-server",
    "title": "Seminar: LabKey Server",
    "section": "What Is LabKey Server",
    "text": "What Is LabKey Server\n\nSecure Collaboration\n\nPassword protected web site for your team to share and coordinate work on multiple projects hosted on your own hardware or in the cloud\nCreate group discussion forums with messages that include markdown\nUpload/Download files\nImport data from csv and xls files into a relational database\nCreate interactive visualizations\nCreate views of data that span multiple datasets using powerful sql based queries and filters\nMake only selected reports view-able to the public on the web\nRich APIs for getting data from LabKey to interact with Python and R scripts\nExtensive documentation and active community forums What Is LabKey\n\n\n\nRobust in Features and Solid in Engineering\n\nLabKey Server got its start in 2003 at the Fred Hutchinson Cancer Research Center in Seattle Washington. In 2005 the LabKey company was founded partly owned by the Hutch. In 2013 they moved into their own offices in Seattle. LabKey is currently used by over 500 researcher organizations for all types of research with small and large teams around the world including the Zika Open Research Poral.\nLabKey Server is actively being developed by a team of skilled software engineers, testers, ux designers, documentation writers, project managers, and customer support people. LabKey Server functionality has grown over the years always embracing new technologies. The current ui is snappy and responsive utilizing java script, bootstrap and font-awesome among other tools. LabKey is built primarily with java technologies and supports users interacting with a wide selection of protocols including ldap, WebDav, Markdown, Java Script, and HTML.\n\n\n\nMostly Free\n\nFeatures mentioned above and more are included in the free community edition under the Apache Software License Version 2.0. There are additional features and support that do require a subscription but the free community edition is very powerful in itself.\n\n\n\nMostly Open Source\n\nSource code is made available for most all base features of LabKey server. LabKey Server can be compiled from source if needed to run on most any environment. A modulalrized architecture makes new features and source code customizations straight forward."
  },
  {
    "objectID": "posts/2018-08-19-seminar-labkey.html#demo",
    "href": "posts/2018-08-19-seminar-labkey.html#demo",
    "title": "Seminar: LabKey Server",
    "section": "Demo",
    "text": "Demo\n\nDemonstrate uploading an example csv dataset and using it to creating interactive visualizations as done here"
  },
  {
    "objectID": "posts/2018-08-19-seminar-labkey.html#how-to-get-started-with-labkey-server",
    "href": "posts/2018-08-19-seminar-labkey.html#how-to-get-started-with-labkey-server",
    "title": "Seminar: LabKey Server",
    "section": "How To Get Started With LabKey Server",
    "text": "How To Get Started With LabKey Server\n\nGet a free Hosted 30 day trial and have your own free LabKey website in 5 mintues with just a few clicks\nMake your own permanent free website on your own hardware or in the cloud. You will need a dedicated computer, Java, Postgres or MSSQL Server, network connectivity and probably a few hours of setup time. Setup requires a strong familiarity with networking, Tomcat based web applications, Java, and Relational Databases. Follow the directions here for a permanent free LabKey website.\n\n\nAbout Jim Piper\n\nJim Piper is the owner operator of Lab Data Interation LLC a software consultancy specializing in helping researchers manage data and adopt machine learning techniques. Jim has been working with Java and web applications since finishing his Masters degree at San Jose State in 1999. Jim worked as a software developer for LabKey from 2016 through 2018. Jim’s full work history can be found on linkedin."
  },
  {
    "objectID": "posts/2021-04-09-niaid.en.html",
    "href": "posts/2021-04-09-niaid.en.html",
    "title": "Virtual Workshop Series for Harnessing the Power of Data to Advance Immune-mediated and Infectious Disease Research",
    "section": "",
    "text": "The National Institute of Allergy and Infectious Diseases (NIAID) is excited to advance discovery and innovation in infectious diseases and immune-mediated disorders research by leveraging data and data science approaches. Towards this end, NIAID will conduct a series of ideas and innovation webinars that bring together experts and stakeholders in data science, infectious diseases, immunology, and immune-mediated disorders.\nThrough the webinar series, participants will have the opportunity to provide insights into the current landscape of data science research and development, as well as offer ideas that promise to shape the future of data-driven immune-mediated and infectious disease research. The webinar series will serve as a platform for collaboration, idea generation, and networking among participants and generate foundational materials that is expected to inform the prospective role of data science in advancing NIAID’s mission.\nSECOND EVENT: Ethical, Legal, and Social Implications of Harnessing Data to Advance Immune-Mediated and Infectious Disease Research\nWHEN: April 16th, 2021 2-3:30 pm ET\nWHERE: Virtually hosted on Zoom - register to receive meeting link\nREGISTRATION: https://zoom.us/webinar/register/WN_RRefGTnQQWaevB__VdjL4w\nAGENDA: https://apply.hub.ki/datascience4niaid/\nWHAT: Our expert panel will engage in a moderated discussion following short talks where they offer perspectives in the evolving landscape of ethical, legal, and social implications of harnessing data to advance immune-mediated and infectious disease research.\nWHO: Invited Speakers include Ms. Megan Doerr (Sage Bionetworks), Dr. Bradley Malin (Vanderbilt University), Dr. Alexandra L. Phelan (Georgetown University). Moderated by Dr. Stephany Duda (Vanderbilt University) and Dr. Purvesh Khatri (Stanford University).\nCONTACTS: Event Organizing Committee (NIAIDODSET@niaid.nih.gov)"
  },
  {
    "objectID": "posts/2021-04-09-niaid.en.html#description",
    "href": "posts/2021-04-09-niaid.en.html#description",
    "title": "Virtual Workshop Series for Harnessing the Power of Data to Advance Immune-mediated and Infectious Disease Research",
    "section": "",
    "text": "The National Institute of Allergy and Infectious Diseases (NIAID) is excited to advance discovery and innovation in infectious diseases and immune-mediated disorders research by leveraging data and data science approaches. Towards this end, NIAID will conduct a series of ideas and innovation webinars that bring together experts and stakeholders in data science, infectious diseases, immunology, and immune-mediated disorders.\nThrough the webinar series, participants will have the opportunity to provide insights into the current landscape of data science research and development, as well as offer ideas that promise to shape the future of data-driven immune-mediated and infectious disease research. The webinar series will serve as a platform for collaboration, idea generation, and networking among participants and generate foundational materials that is expected to inform the prospective role of data science in advancing NIAID’s mission.\nSECOND EVENT: Ethical, Legal, and Social Implications of Harnessing Data to Advance Immune-Mediated and Infectious Disease Research\nWHEN: April 16th, 2021 2-3:30 pm ET\nWHERE: Virtually hosted on Zoom - register to receive meeting link\nREGISTRATION: https://zoom.us/webinar/register/WN_RRefGTnQQWaevB__VdjL4w\nAGENDA: https://apply.hub.ki/datascience4niaid/\nWHAT: Our expert panel will engage in a moderated discussion following short talks where they offer perspectives in the evolving landscape of ethical, legal, and social implications of harnessing data to advance immune-mediated and infectious disease research.\nWHO: Invited Speakers include Ms. Megan Doerr (Sage Bionetworks), Dr. Bradley Malin (Vanderbilt University), Dr. Alexandra L. Phelan (Georgetown University). Moderated by Dr. Stephany Duda (Vanderbilt University) and Dr. Purvesh Khatri (Stanford University).\nCONTACTS: Event Organizing Committee (NIAIDODSET@niaid.nih.gov)"
  },
  {
    "objectID": "posts/2018-03-06-bioinformatics-class-s18.html",
    "href": "posts/2018-03-06-bioinformatics-class-s18.html",
    "title": "Seminar: Teaching Bioinformatics",
    "section": "",
    "text": "Interested in analyzing genomic expression data? Interested in the tools that Biologists use to analyze DNA data?\nJoin us on Tuesday March 13 at 2pm in MLIB 442 to hear Dr. Gordon Wolfe and Dr. Dave Keller from Biology presenting an overview and update on BIOL 482: Bioinformatics. [RSVP here]\n\nAbstract:\n\nWe will present an overview of our BIOL 482 bioinformatics class: how it was developed, and how we see it fulfilling the needs of our curriculum. We will show some data of student background and experience, and describe the kinds of activities we are incorporating into the class. Time pending we will present the student projects being conducted during the first half of the semester.\n\nSee the rest of the DSI Spring 18 [Seminar and Workshop schedule] here."
  },
  {
    "objectID": "posts/2017-04-14-import_data_announce.html",
    "href": "posts/2017-04-14-import_data_announce.html",
    "title": "DSI Workshop - Exploring your data",
    "section": "",
    "text": "Date: Friday April 14, 2017\nTime: 3-4:30 pm\nLocation: MLIB 442\nPresenter: Robin Donatello: rdonatello@csuchico.edu\n\n\n\nIn this workshop you will learn and practice the following:\n\nHow to get data into R from a variety of places including the web, from excel, from a CSV file and from a simple text file.\nHow to start looking at your data using tables and simple plots\nIdentifying problems in the data such as missing data or numbers stored as characters\n\nWorkshop Details & Materials"
  },
  {
    "objectID": "posts/2017-04-14-import_data_announce.html#learning-objectives",
    "href": "posts/2017-04-14-import_data_announce.html#learning-objectives",
    "title": "DSI Workshop - Exploring your data",
    "section": "",
    "text": "In this workshop you will learn and practice the following:\n\nHow to get data into R from a variety of places including the web, from excel, from a CSV file and from a simple text file.\nHow to start looking at your data using tables and simple plots\nIdentifying problems in the data such as missing data or numbers stored as characters\n\nWorkshop Details & Materials"
  },
  {
    "objectID": "posts/2017-04-21-ggplot2_announce.html",
    "href": "posts/2017-04-21-ggplot2_announce.html",
    "title": "DSI Workshop - Data Visualization with ggplot2",
    "section": "",
    "text": "Date: Friday April 21, 2017\nTime: 3-4:30 pm\nLocation: MLIB 442\nPresenter: Robin Donatello: rdonatello@csuchico.edu\n[Workshop Details & Materials]\n\n\n\nIn this workshop you will explore data through visual tools using ggplot. You will learn how to plot different graphs."
  },
  {
    "objectID": "posts/2017-04-21-ggplot2_announce.html#learning-objectives",
    "href": "posts/2017-04-21-ggplot2_announce.html#learning-objectives",
    "title": "DSI Workshop - Data Visualization with ggplot2",
    "section": "",
    "text": "In this workshop you will explore data through visual tools using ggplot. You will learn how to plot different graphs."
  },
  {
    "objectID": "posts/2018-04-23-data-fest-prep.html",
    "href": "posts/2018-04-23-data-fest-prep.html",
    "title": "Data Fest Prep",
    "section": "",
    "text": "Date: Tuesday April 24, 2018\nTime: 2-3:50 pm\nLocation: MLIB 442\n\n\n\nPlanning on participating in Data Fest 2018? Want to practice your data wrangling skills?\nOn Tuesday we will be doing a “dry run” of DataFest by using 2017 data. Basically here’s the data and the overall analysis goal. # GO!"
  },
  {
    "objectID": "posts/2018-04-23-data-fest-prep.html#description",
    "href": "posts/2018-04-23-data-fest-prep.html#description",
    "title": "Data Fest Prep",
    "section": "",
    "text": "Planning on participating in Data Fest 2018? Want to practice your data wrangling skills?\nOn Tuesday we will be doing a “dry run” of DataFest by using 2017 data. Basically here’s the data and the overall analysis goal. # GO!"
  },
  {
    "objectID": "posts/2018-10-25-seminar-csci-hayes.html",
    "href": "posts/2018-10-25-seminar-csci-hayes.html",
    "title": "Cloud Computing at Chevron",
    "section": "",
    "text": "Who: Travis Hayes, Solution Architect forChevron Information Technology Company\nWhen: Friday, Oct 26, 2018; 2pm\nWhere: O’Connell 254\nAbstract\nLean about Chevron’s cloud journey through infrastructure automation, CI/CD, and application modernization at scale."
  },
  {
    "objectID": "posts/2018-03-23-ds-info-session.html",
    "href": "posts/2018-03-23-ds-info-session.html",
    "title": "Data Science Certificate Info Session",
    "section": "",
    "text": "Come learn about the new Undergraduate Certificate in Data Science. Motivation for the program, details about the enrollment process, course requirements and benefits for students. Enrollment in the Certificate program opens Fall 2018.\n\nThursday 3-29, 2pm, MLIB 442\nCommunity Coding session will follow at 3pm."
  },
  {
    "objectID": "posts/2022-08-01-guest-post-underlying-geometry-of-data/index.en.html",
    "href": "posts/2022-08-01-guest-post-underlying-geometry-of-data/index.en.html",
    "title": "August Student post: Underlying geometry of data",
    "section": "",
    "text": "We start our student contributed guest post series with a look at data from a topological lens. Skip Moses graduated from Chico State Department of Mathematics and Statistics in 2022. He triple majored in Pure Math, Applied Math, Statistics, and completed the Certificate in Data Science.\n\nData often has an underlying structure or geometry that can be modeled as a signal on the vertices of a weighted, undirected graph. Dong et. al. provide an algorithm for learning the underlying structure of a graph given a smooth signal representation on the graph here. Dong et. al. originally implemented the algorithm in MATLAB, however, it can be solved effiecently in Python. In the post here a brief description of the algorithm, and example of a learned graph are provided."
  },
  {
    "objectID": "posts/2017-10-24-meet-and-analyze-data.html",
    "href": "posts/2017-10-24-meet-and-analyze-data.html",
    "title": "Meet and analyze data",
    "section": "",
    "text": "The Data Science Initative and the Statistics Faculty are hosting “meet and analyze data”. This is simply a reserved space held in central locations for people working on code, data analysis, or some other form of Data Science to come, hang out, and code in proximity with other coders. Got a question? We’re right there. We may not be able to help directly, but we’ll try. At least we’ll help you get a good Google search going. Even if you don’t need immediate help, or you just want a place outside the office to get some work done, the door is open to everyone.\n\nTue, 2-3:50 MLIB 442, Edward Roualdes\nThu, 2-2:30 SSC 426, Robin Donatello\n\nDays/times subject to campus building closures during holidays and winter break. Similar times will be held next semester, times and locations TBD."
  },
  {
    "objectID": "posts/2023-03-09-health-equity-datathon/index.en.html",
    "href": "posts/2023-03-09-health-equity-datathon/index.en.html",
    "title": "Health Equity Datathon",
    "section": "",
    "text": "To learn more and secure your spot &gt;&gt; CIVIC-HACKERS.ORG/HED23"
  },
  {
    "objectID": "posts/2023-03-03-datafest-2023-registration-now-open/index.en.html#what-is-the-asa-datafest",
    "href": "posts/2023-03-03-datafest-2023-registration-now-open/index.en.html#what-is-the-asa-datafest",
    "title": "DataFest 2023 April 14-16- Registration now open!",
    "section": "What is the ASA DataFest?",
    "text": "What is the ASA DataFest?\nASA DataFest is a data hackathon for undergraduate students, sponsored by the American Statistical Association and founded at UCLA, in 2011. A data analysis problem is presented in the form of a dataset and an associated challenge. Teams of students get a dataset on Friday afternoon and work on the problem until Sunday afternoon where they present their findings. After two days of intense data wrangling, analysis, and presentation design, each team is allowed a few minutes and no more than two slides to impress a panel of judges. Prizes are given for Best in Show, Best Visualization, and Best Use of External Data.\nUndergraduates from all majors are welcome. Some of the most diverse teams have been the most successful.\nThis event is open to ALL undergraduates in the North State!"
  },
  {
    "objectID": "posts/2023-03-03-datafest-2023-registration-now-open/index.en.html#at-sacramento-state",
    "href": "posts/2023-03-03-datafest-2023-registration-now-open/index.en.html#at-sacramento-state",
    "title": "DataFest 2023 April 14-16- Registration now open!",
    "section": "At Sacramento State",
    "text": "At Sacramento State\nThis time we’re heading down south and joining our colleagues at Sacramento State\nLearn more about this national event at the event website: https://norcaldatafest.netlify.app/"
  },
  {
    "objectID": "posts/2019-03-03-dsi-seminar-strategies-to-manage-big-data.html",
    "href": "posts/2019-03-03-dsi-seminar-strategies-to-manage-big-data.html",
    "title": "DSI Seminar 3/5: Strategies to manage Big Data",
    "section": "",
    "text": "Presenter: Edward Roualdes, Associate Professor of Statistics\nDate: Tuesday March 5th, 2019\nTime: 2-2:50 pm\nLocation: Tehama 116\nRSVP: http://goo.gl/forms/BnjV0y5zoz09tUU83\n\n\n\nThis talk is about managing big data in a short amount of time, since there are certainly better solutions to managing big data with more time and/or money available. We’ll briefly cover the constraints of the problem, limited memory and computing power. These constraints will be explored from within R, but the same ideas carry over to any programming language. The remainder of the talk will be a hands on tutorial for managing a large data set."
  },
  {
    "objectID": "posts/2019-03-03-dsi-seminar-strategies-to-manage-big-data.html#description",
    "href": "posts/2019-03-03-dsi-seminar-strategies-to-manage-big-data.html#description",
    "title": "DSI Seminar 3/5: Strategies to manage Big Data",
    "section": "",
    "text": "This talk is about managing big data in a short amount of time, since there are certainly better solutions to managing big data with more time and/or money available. We’ll briefly cover the constraints of the problem, limited memory and computing power. These constraints will be explored from within R, but the same ideas carry over to any programming language. The remainder of the talk will be a hands on tutorial for managing a large data set."
  },
  {
    "objectID": "posts/2018-04-01-setup_python_announce.html",
    "href": "posts/2018-04-01-setup_python_announce.html",
    "title": "Workshop: Getting Started with Python & Jupyter Notebooks",
    "section": "",
    "text": "April is Data Fest Prep month! Hone your skills in preparation for this exciting data hackathon event!\n\nLogistics / Setup\n\nDate: Thursday April 5, 2018\nTime: 3-3:50 pm\nLocation: MLIB 442\nPresenter: Grant Esparza\n[Workshop Details & Materials]\n\nThe DSI is hosting for our first workshop on Python!\nGrant Esparza from Computer Science will help us install Python 3 and the Jupyter Notebook, and get us started using Python. This 2-part workshop will follow-up in a week by Edward Roualdes showing us how to use and visualize data using Python.\nPython is one of the leading high-level Data Science programming languages. The power of Python combined with the literate programming tool Jupyter has been featured in a Nature article touting the benefits to scientific research."
  },
  {
    "objectID": "posts/2022-03-01-project-da-fanh/index.html",
    "href": "posts/2022-03-01-project-da-fanh/index.html",
    "title": "New grant program supports Hispanic students in Data Science enabled USDA career paths.",
    "section": "",
    "text": "CHICO, Calif.- California State University, Chico and California State University, San Bernardino campuses partnered to better the education of Hispanic undergraduate students in food, agriculture, natural resources and human sciences domains (FANH).\nThe primary goal of this project is to retain and graduate highly qualified students in the intersection of data science (DS) and analytics (DA) and the food, agriculture, natural resources and human sciences domains. Project DA-FANH assists underserved students on both campuses and allows for increased representation in fields that are traditionally lacking in diversity. The program assists in training students how to use data to enhance the nation’s professional and scientific workforce.\nRobin Donatello, project director, explained the value of the program.\n\n“It showcases how data analytics is accessible to everyone, and it empowers students to learn how to be the boss of their own data and use it to make an impact in the societal areas they care about,” Donatello said.\n\nBy incorporating culturally relevant education while modeling data science and analytics techniques in the FANH curriculum, this project dismantles barriers and existing stereotypes about who belongs, and it builds a career pathway for students of color in the intersection of data science and analytics and FANH careers.\nProject activities include career panels and job assistance to provide students access to career opportunities. The project also offers internship experiences that emphasize problem solving, data-driven decision-making and remote team-collaboration skills.\nDA-FANH is directed by Robin Donatello (Chico State) and Essia Hamouda (Cal State San Bernardino) and is supported by many other influential and successful women, including specialty leads Stephanie Bianco and Christine Hererra. This partnership ignited a project that launched in August 2021 and was officially released February 21, 2022.\nFaculty-led project directors encourage and ensure that DS/DA skills are a part of a curriculum that supports FANH programs. All news, activities and latest updates will be accessible through the project website, along with social media links and scholarship opportunities.\nFor more information please visit the Project DA-FANH website or contact one of the project directors below:\nRobin Donatello DA-FANH Project Director Associate Professor in Statistics, California State University, Chico rdonatello@csuchico.edu\nEssia Hamouda DA-FANH Project Director Assistant Professor of Information and Decision Sciences California State University, San Bernardino ehamouda@csusb.edu"
  },
  {
    "objectID": "posts/2022-03-01-project-da-fanh/index.html#two-institutions-partner-to-enhance-the-quality-of-undergraduate-education-for-hispanic-students",
    "href": "posts/2022-03-01-project-da-fanh/index.html#two-institutions-partner-to-enhance-the-quality-of-undergraduate-education-for-hispanic-students",
    "title": "New grant program supports Hispanic students in Data Science enabled USDA career paths.",
    "section": "",
    "text": "CHICO, Calif.- California State University, Chico and California State University, San Bernardino campuses partnered to better the education of Hispanic undergraduate students in food, agriculture, natural resources and human sciences domains (FANH).\nThe primary goal of this project is to retain and graduate highly qualified students in the intersection of data science (DS) and analytics (DA) and the food, agriculture, natural resources and human sciences domains. Project DA-FANH assists underserved students on both campuses and allows for increased representation in fields that are traditionally lacking in diversity. The program assists in training students how to use data to enhance the nation’s professional and scientific workforce.\nRobin Donatello, project director, explained the value of the program.\n\n“It showcases how data analytics is accessible to everyone, and it empowers students to learn how to be the boss of their own data and use it to make an impact in the societal areas they care about,” Donatello said.\n\nBy incorporating culturally relevant education while modeling data science and analytics techniques in the FANH curriculum, this project dismantles barriers and existing stereotypes about who belongs, and it builds a career pathway for students of color in the intersection of data science and analytics and FANH careers.\nProject activities include career panels and job assistance to provide students access to career opportunities. The project also offers internship experiences that emphasize problem solving, data-driven decision-making and remote team-collaboration skills.\nDA-FANH is directed by Robin Donatello (Chico State) and Essia Hamouda (Cal State San Bernardino) and is supported by many other influential and successful women, including specialty leads Stephanie Bianco and Christine Hererra. This partnership ignited a project that launched in August 2021 and was officially released February 21, 2022.\nFaculty-led project directors encourage and ensure that DS/DA skills are a part of a curriculum that supports FANH programs. All news, activities and latest updates will be accessible through the project website, along with social media links and scholarship opportunities.\nFor more information please visit the Project DA-FANH website or contact one of the project directors below:\nRobin Donatello DA-FANH Project Director Associate Professor in Statistics, California State University, Chico rdonatello@csuchico.edu\nEssia Hamouda DA-FANH Project Director Assistant Professor of Information and Decision Sciences California State University, San Bernardino ehamouda@csusb.edu"
  },
  {
    "objectID": "posts/2018-07-14-swc-announce.html",
    "href": "posts/2018-07-14-swc-announce.html",
    "title": "August Workshop - Reproducible Scientific Research with R",
    "section": "",
    "text": "On August 13 - 15th, the DSI is hosting a Software Carpentry workshop for graduate students, faculty, and any other researcher that wants to learn how to conduct reproducible research. You don’t need to have any previous knowledge of the tools that will be presented at the workshop.\nThe Carpentries are a fiscally sponsored project of Community Initiatives. They teach skills that are immediately useful for researchers, using lessons and datasets that allow researchers to quickly apply what they’ve learned to their own work. We’re really excited about using the Software Carpentry curriculum here to help our researchers become more efficient in their research.\nThis workshop is focused on Reproducible Scientific research using R. The curriculum will include:\n\nDay 1: Monday August 13, 9am - 4:30 pm\n\nOrganizing data in spreadsheets\nGetting started with R and Markdown\n\nDay 2: Tuesday August 14, 9am - 4:30 pm\n\nCommand line power: using the shell\nData visualization and manipulation\n\nDay 3: (optional) Wednesday August 13, 9am - 12 noon\n\nVersion control in R Studio using Projects\nBuilding websites in R with Markdown\n\n\nThe target audience is learners who have little to no prior computational experience, and the instructors put a priority on creating a friendly environment to empower researchers and enable data-driven discovery. Even those with some experience will benefit, as the goal is to teach not only how to do analyses, but how to manage the process to make it as automated and reproducible as possible. For instance, after attending this workshop you will be able to:\n\nUse the unix shell to manage files without a graphical user interface.\nImport, process and visualize data sets in R Studio\nCreate reproducible scientific documents that are human readable.\n(Optional) Build a website where you can share research, post course materials, or start an e-portfolio to demonstrate your work.\n\nSpace is limited and it will likely fill quickly. There is a small fee for this event to provide refreshments for participants throughout the two days. If you cannot afford this fee contact us to disucss options.\nSee the workshop website for specific details on the topics, schedule and RSVP instructions.\nQuestions? Send an email to Robin Donatello: rdonatello@csuchico.edu"
  },
  {
    "objectID": "posts/2018-10-29-ds-info-session-f18.html",
    "href": "posts/2018-10-29-ds-info-session-f18.html",
    "title": "Data Science info session",
    "section": "",
    "text": "Missed this event? Watch the Video Recording here: [https://media.csuchico.edu/media/0_kkfl6yt8]"
  },
  {
    "objectID": "posts/2018-10-29-ds-info-session-f18.html#when-friday-nov-2nd-noon",
    "href": "posts/2018-10-29-ds-info-session-f18.html#when-friday-nov-2nd-noon",
    "title": "Data Science info session",
    "section": "When: Friday, Nov 2nd, noon",
    "text": "When: Friday, Nov 2nd, noon"
  },
  {
    "objectID": "posts/2018-10-29-ds-info-session-f18.html#where-butte-101",
    "href": "posts/2018-10-29-ds-info-session-f18.html#where-butte-101",
    "title": "Data Science info session",
    "section": "Where: Butte 101",
    "text": "Where: Butte 101\nDo you want to increase your ability to read, understand, create and communicate data as information? To tell a better data story?\nDo you want to be a better consumer and curator of news, improving your ability to identify bull-oney stories that are only aimed to spread false information?\nAre you concerned about ethics and fairness in algorithms that are used for decisions such as whether or not you get that home mortgage, or that your resume is not tossed out without being seen due to a bias in the screening algorithm.\nOr perhaps you want to add on some data-handling skills such as being able to obtain and process non-standard data such as text, images, and relational databases to improve your ability to analyze data in your current field of study.\nEmployers are snapping up anyone who has technical skills related to data handling or analysis. Data Scientists have been and still are in very high demand in many fields such as Business Analytics, Genomic Analysis, Social Science, Healthcare and a multitude of Science fields that generate a lot of sensor data.\n\nData Science is an interdisciplinary field that uses scientific methods, algorithms, visualizations, and creativity to extract knowledge and insights from data in various forms from many locations.\n\nChico State offers an Undergraduate Certificate in Data Science, a multitude of Data Science related courses, short courses, training workshops, seminar sessions and fun data challenge events such as DataFest (a 48 hour hackathon in April). All events are aimed to increase the data literacy of our entire campus community regardless of affiliation or major.\nCome hear about the new Data Science curriculum and programs and learn how you can get involved.\nLight refreshments will be provided"
  },
  {
    "objectID": "posts/2022-07-17-fall-22-guest-post-series/index.en.html",
    "href": "posts/2022-07-17-fall-22-guest-post-series/index.en.html",
    "title": "Fall 22 Guest post series",
    "section": "",
    "text": "Last Spring 2022 our most recent cohort of Data Science certificate students took the Advanced Data Science course, MATH/CSCI 485. In addition to consulting with campus based partners to use data science tools to solve a business or programmatic need, students practiced writing for a public audience.\nThis fall we will be showcasing these students contributed blog posts, one a month starting in August.\nTopic were chosen by the students based on their interest and range from theoretical examinations of graph data structure, to reflections on justice in tech, and tutorials on SQL.\nWe hope you enjoy these contributed posts!\nCheck out our homepage for up to date news on what’s happening in the world of Data Science at Chico State"
  },
  {
    "objectID": "posts/2019-02-17-asa-datafest-2019.html",
    "href": "posts/2019-02-17-asa-datafest-2019.html",
    "title": "ASA DataFest 2019 @ Chico State - April 5-7",
    "section": "",
    "text": "logo\n\n\nWe’re doing it again! Last year the ASA DataFest at Chico State featured 12 undergraduate students in 3 teams of 4 people, a ton of food and a lot of fun. This year we’re expanding this event, registration is open to ALL undergraduates in the North State! As of 2-17-19 we we already have 22 students (about 5 teams) already registered!\nMore students means more funding is needed to keep everyone fed, caffinated and to provide excellent prizes to the winners. Sponsorship opportunities are still available. Contact us for more information on how you can contribute.\nWhat is the ASA DataFest?\nASA DataFest is a data hackathon for undergraduate students, sponsored by the American Statistical Association and founded at UCLA, in 2011. A data analysis problem is presented in the form of a dataset and an associated challenge. Teams of students get a dataset on Friday afternoon and work on the problem until Sunday afternoon where they present their findings. After two days of intense data wrangling, analysis, and presentation design, each team is allowed a few minutes and no more than two slides to impress a panel of judges. Prizes are given for Best in Show, Best Visualization, and Best Use of External Data.\nUndergraduates from all majors are welcome. Some of the most diverse teams have been the most successful.\nA key feature of ASA DataFest is that it brings together the data science community. Undergraduate students do the work, but they are assisted by roving consultants who are graduate students, faculty, and industry professionals.\nLearn more about this national event at the event website: http://chicodatafest.netlify.com/"
  },
  {
    "objectID": "posts/2021-05-13-swc-website-june.en.html",
    "href": "posts/2021-05-13-swc-website-june.en.html",
    "title": "Sofware Carpentry Workshop for Website Building",
    "section": "",
    "text": "This event has been postponed due to unforseen and unavoidable circumstances. We will be rescheduling this event for Summer. We are considering expanding the workshop an additional 2 days to include more lessons on R programming. Registered participants want a refund please email datascience@csuchico.edu. We apologize for the inconvenience.\n\nEver wish you had a way to showcase your work inside and out of the classroom? A place to share materials with students, or to blog about current research and developments in your field?\nOn March 6th & 13th, 2021 the CSU Math Council is sponsoring a virtual professional development workshop for Mathematics & Statistics faculty across the CSU to learn how to build a professional website using Data Science tools such as GitHub and R Markdown.\nWe will be using curated lesson materials from The Carpentries, a fiscally sponsored project of Community Initiatives. They teach skills that are immediately useful for researchers, using lessons and datasets that allow researchers to quickly apply what they’ve learned to their own work. However, this will not be a standard Software Carpentry workshop, we have purposefully chosen selected parts of Carpentry lessons to provide the necessary building blocks for a successful website. The curriculum will include:\n\nUsing the Unix Shell\nVersion control with git\nVery basic introduction to R (no real working with data)\nCreating reproducible documents using Markdown.\nUsing all those tools to create a website\n\nThe target audience is learners who have little to no prior computational experience, and the instructors put a priority on creating a friendly environment to empower faculty to learn new tools to showcase their accomplishments.\nSpace is limited and it will likely fill quickly. Here is a link to the workshop webpage https://csucdsi.github.io/2021-03-06-csumath/ for more information and to sign up.\nQuestions? Send an email to datascience@csuchico.edu\nWe hope to see you in March!"
  },
  {
    "objectID": "posts/2022-11-27-bls-open-pos/index.en.html",
    "href": "posts/2022-11-27-bls-open-pos/index.en.html",
    "title": "Research Statistician vacancies at the Bureau of Labor Statistics",
    "section": "",
    "text": "This is a cross-post from a recent Project-DAFANH “Ask me anything” career speaker.\n\nDo you enjoy conducting statistical or survey methodological research? Would you like to join a group of researchers and be on the forefront of developing novel statistical methodologies that directly impact federal economic indicators? Does a federal job that emphasizes work-life balance and is committed to your professional development sound right for you?\nhttps://www.usajobs.gov/job/688034000\nThen consider applying to the Bureau of Labor Statistics (BLS) Office of Survey Methods Research! We’re hiring GS-12 or GS-13 Research Mathematical Statisticians to join the Mathematical Statistics Research Center, where we strive to improve the accuracy of BLS survey data and the estimates BLS publishes, where we aim to improve the efficiency of BLS data collection and estimation methods, and where we get to consult with economists, statisticians, and data scientists on emerging mathematical statistical issues to support all of BLS!\nTo apply for this position, please go to USAJobs: https://www.usajobs.gov/job/688034000. For more information about this posting, contact Jeff Gonzalez (Gonzalez.Jeffrey@bls.gov).\nTips for a successful application process:\n\nProvide transcripts that document the degree requirements listed in the Qualifications section of the announcement. If you think the transcripts are not self-explanatory, you can add a section for “relevant coursework” to the education section of your resume or CV highlighting the courses and credits that should count toward the requirement. Provide all relevant transcripts, not just your most recent one.\nTailor your resume or CV to this vacancy announcement. Document your relevant work experience through bullet points in your resume or CV. Reflect the language used in the announcement where applicable (see Duties and Specialized Experience under Qualifications). For example, identify your methodological research, convey that it contributed to new or improved methods, and include how you disseminated your research findings. Resumes are first reviewed by non-technical human resources staff that determine whether you are minimally qualified by ensuring your resume corresponds to the requirements listed in the announcement.\nYour work experience bullet points should be tied to positions for which you list start and stop dates, using “MM/YYYY” format, for employment as well as hour-per-week. This is how human resources staff determine whether your cumulative experience meets the work threshold (see Specialized Experience under Qualifications).\nYou do not have to limit your resume or CV to one or two pages. You can take as much room as you need (within reason) to convey your qualifications but be sure to proofread it before you submit your application.\nFor more information on writing an effective Federal resume, read: Tips for Writing a Federal Resume | U.S. Department of Labor (dol.gov)"
  },
  {
    "objectID": "posts/2022-11-27-bls-open-pos/index.en.html#multiple-gs-1213-research-math-stat-vacancies-at-the-bureau-of-labor-statistics",
    "href": "posts/2022-11-27-bls-open-pos/index.en.html#multiple-gs-1213-research-math-stat-vacancies-at-the-bureau-of-labor-statistics",
    "title": "Research Statistician vacancies at the Bureau of Labor Statistics",
    "section": "",
    "text": "This is a cross-post from a recent Project-DAFANH “Ask me anything” career speaker.\n\nDo you enjoy conducting statistical or survey methodological research? Would you like to join a group of researchers and be on the forefront of developing novel statistical methodologies that directly impact federal economic indicators? Does a federal job that emphasizes work-life balance and is committed to your professional development sound right for you?\nhttps://www.usajobs.gov/job/688034000\nThen consider applying to the Bureau of Labor Statistics (BLS) Office of Survey Methods Research! We’re hiring GS-12 or GS-13 Research Mathematical Statisticians to join the Mathematical Statistics Research Center, where we strive to improve the accuracy of BLS survey data and the estimates BLS publishes, where we aim to improve the efficiency of BLS data collection and estimation methods, and where we get to consult with economists, statisticians, and data scientists on emerging mathematical statistical issues to support all of BLS!\nTo apply for this position, please go to USAJobs: https://www.usajobs.gov/job/688034000. For more information about this posting, contact Jeff Gonzalez (Gonzalez.Jeffrey@bls.gov).\nTips for a successful application process:\n\nProvide transcripts that document the degree requirements listed in the Qualifications section of the announcement. If you think the transcripts are not self-explanatory, you can add a section for “relevant coursework” to the education section of your resume or CV highlighting the courses and credits that should count toward the requirement. Provide all relevant transcripts, not just your most recent one.\nTailor your resume or CV to this vacancy announcement. Document your relevant work experience through bullet points in your resume or CV. Reflect the language used in the announcement where applicable (see Duties and Specialized Experience under Qualifications). For example, identify your methodological research, convey that it contributed to new or improved methods, and include how you disseminated your research findings. Resumes are first reviewed by non-technical human resources staff that determine whether you are minimally qualified by ensuring your resume corresponds to the requirements listed in the announcement.\nYour work experience bullet points should be tied to positions for which you list start and stop dates, using “MM/YYYY” format, for employment as well as hour-per-week. This is how human resources staff determine whether your cumulative experience meets the work threshold (see Specialized Experience under Qualifications).\nYou do not have to limit your resume or CV to one or two pages. You can take as much room as you need (within reason) to convey your qualifications but be sure to proofread it before you submit your application.\nFor more information on writing an effective Federal resume, read: Tips for Writing a Federal Resume | U.S. Department of Labor (dol.gov)"
  },
  {
    "objectID": "posts/2019-04-09-case_study_lyft.html",
    "href": "posts/2019-04-09-case_study_lyft.html",
    "title": "DSI Seminar 4/23 & 4/25: Growing a Scientific Mindset to Develop Analytics Teams",
    "section": "",
    "text": "The Chico State Data Science Initiative is proud to welcome Chico State Alumni Martin Frigaard, App Developer with Intricity and Peter Spangler, Data Scientist at Lyft back for two das to give their invited talk for the Predictive World Analytics 2019 Conference."
  },
  {
    "objectID": "posts/2019-04-09-case_study_lyft.html#link-to-slides-handon-materials",
    "href": "posts/2019-04-09-case_study_lyft.html#link-to-slides-handon-materials",
    "title": "DSI Seminar 4/23 & 4/25: Growing a Scientific Mindset to Develop Analytics Teams",
    "section": "Link to Slides & Handon materials",
    "text": "Link to Slides & Handon materials\nhttp://bit.ly/csuc-data-talk"
  },
  {
    "objectID": "posts/2019-04-09-case_study_lyft.html#description",
    "href": "posts/2019-04-09-case_study_lyft.html#description",
    "title": "DSI Seminar 4/23 & 4/25: Growing a Scientific Mindset to Develop Analytics Teams",
    "section": "Description",
    "text": "Description\nSuccess in a data-driven world means empowering teams with science to improve decision making through confident, replicable and trainable programs that can engage an entire organization. Analytics teams that use a scientific approach to answer business questions will accelerate actionable insights and improve user experiences.\nPeter and Martin will discuss their experience driving value in organizations including Lyft, Citrix, Alibaba and Bell where data science methods for growth and insights are at the forefront of the business. Data science is a team sport, the people in the business closest to the data often are in a position to know it best. Fostering an analytic mindset throughout the organization and training teams in a scientific approach to attack the problems they encounter will produce a needed competitive advantage.\nGain speed and agility in modeling solutions to the questions in your organization for a deeper understanding of the business landscape."
  },
  {
    "objectID": "posts/2019-04-09-case_study_lyft.html#a-hands-on-live-coding-demonstration-will-follow-the-talk.",
    "href": "posts/2019-04-09-case_study_lyft.html#a-hands-on-live-coding-demonstration-will-follow-the-talk.",
    "title": "DSI Seminar 4/23 & 4/25: Growing a Scientific Mindset to Develop Analytics Teams",
    "section": "A hands on live coding demonstration will follow the talk.",
    "text": "A hands on live coding demonstration will follow the talk.\nBring your laptop. The coding environment will be provided for you at the start of the talk.\nDay 1 -"
  },
  {
    "objectID": "posts/2018-04-19-ggplot2_announce.html",
    "href": "posts/2018-04-19-ggplot2_announce.html",
    "title": "Workshop: Data Visualization with ggplot2",
    "section": "",
    "text": "April is Data Fest Prep month! Hone your skills in preparation for this exciting data hackathon event!"
  },
  {
    "objectID": "posts/2018-04-19-ggplot2_announce.html#rsvp-here-for-this-and-other-upcoming-dsi-workshops.",
    "href": "posts/2018-04-19-ggplot2_announce.html#rsvp-here-for-this-and-other-upcoming-dsi-workshops.",
    "title": "Workshop: Data Visualization with ggplot2",
    "section": "RSVP here for this and other upcoming DSI workshops.",
    "text": "RSVP here for this and other upcoming DSI workshops."
  },
  {
    "objectID": "posts/2017-08-14-introduction-to-r-short-course.html",
    "href": "posts/2017-08-14-introduction-to-r-short-course.html",
    "title": "Introduction to R Short Course",
    "section": "",
    "text": "Learn R Now!\n\nWill you be taking Math 315 (Statistics)?\nDo you want to have better control over your own data analysis?\nHave you always wanted to learn R but never got around to it?\nDo you want to learn how to visualize your data?\nAre you interested in Data Science, Data Analytics, Business Analytics, Forecasting, Bioinformatics, or Health Informatics?\nDo you want to learn how to make your research reproducible?\n\nIf you answered “Yes” or even “Maybe” to ANY of these items then you should enroll in this Workshop!\n\n2-3:50 pm, BUTTE 211\nCredit / No-Credit grading\nFaculty / Staff welcome to audit!\n4 weeks only: 8/22 – 9/14\nMATH 130-01 #591\n\nQuestions? Contact Robin Donatello for more details."
  },
  {
    "objectID": "posts/2019-11-07-asa-datafest-2020.html",
    "href": "posts/2019-11-07-asa-datafest-2020.html",
    "title": "ASA DataFest 2020 @ Chico State - April 17-19",
    "section": "",
    "text": "logo"
  },
  {
    "objectID": "posts/2019-11-07-asa-datafest-2020.html#save-the-date---april-17-19-2020",
    "href": "posts/2019-11-07-asa-datafest-2020.html#save-the-date---april-17-19-2020",
    "title": "ASA DataFest 2020 @ Chico State - April 17-19",
    "section": "Save the Date - April 17-19, 2020!",
    "text": "Save the Date - April 17-19, 2020!\nIn 2019 Chico State’s ASA DataFest tripled the participation from our first year. DataFest 2020 is set to break (our) records! DataFest 2019 hosted 36 undergraduate students in 6 teams, a ton of food and a lot of fun.\nThis event is open to ALL undergraduates in the North State!\n\nRegistration opens January 2020.\n\n\n\nDataFest Flyer\n\n\nWhat is the ASA DataFest?\nASA DataFest is a data hackathon for undergraduate students, sponsored by the American Statistical Association and founded at UCLA, in 2011. A data analysis problem is presented in the form of a dataset and an associated challenge. Teams of students get a dataset on Friday afternoon and work on the problem until Sunday afternoon where they present their findings. After two days of intense data wrangling, analysis, and presentation design, each team is allowed a few minutes and no more than two slides to impress a panel of judges. Prizes are given for Best in Show, Best Visualization, and Best Use of External Data.\nUndergraduates from all majors are welcome. Some of the most diverse teams have been the most successful.\nA key feature of ASA DataFest is that it brings together the data science community. Undergraduate students do the work, but they are assisted by roving consultants who are graduate students, faculty, and industry professionals.\nLearn more about this national event at the event website: http://chicodatafest.netlify.com/"
  },
  {
    "objectID": "posts/2018-10-25-seminar-biol-salehi.html",
    "href": "posts/2018-10-25-seminar-biol-salehi.html",
    "title": "Biomedical Optical Imaging and Machine Learning for Cancer and Disease Detection",
    "section": "",
    "text": "Who: Dr. Hassan S. Salehi, Assistant Professor, Department of Electrical & Computer Engineering, CSU, Chico\nWhen: Friday, Oct 26, 2018; 4pm\nWhere: Holt Hall 170\nAbstract\nOvarian cancer ranks fifth as the cause of cancer death in women. Due to nonspecific associated symptoms as well as lack of efficacious screening techniques at the disposal of patients, the survival rate for ovarian cancer has not significantly improved over the last two decades. Therefore, ovarian cancer has the highest mortality rate of all gynecologic cancers. As a result, there is an urgent need to improve the current diagnostic techniques to detect early malignancies in the ovary. Here, I will describe the development of a novel real-time co-registered photoacoustic/ultrasound (PAT/US) prototype imaging system along with machine learning techniques as a future screening modality for early-stage ovarian cancer detection and characterization. Further information on low-cost photoacoustic microscopy system with a novel laser scanner will be discussed.\nDental caries is a prominent health problem that affects more than 90 percent of all dentate adults and more than two-thirds of children in the United States. The conventional approach for diagnosing caries is clinical examination and supplemented by radiographs. However, studies based on the clinical and radiographic examination methods often show low sensitivity. To address this challenge, we have introduced a novel approach combining deep convolutional neural networks (CNN) and optical coherence tomography (OCT) imaging modality for classification of human oral tissues to detect early dental caries. The proposed technique was validated on ex vivo OCT images of human oral tissues, which attested to effectiveness of the proposed method. The sensitivity and specificity of distinguishing between different oral tissues were found to be ~98% and 100%, respectively. These preliminary results demonstrate the feasibility of using deep learning algorithms with OCT images to perform the automated diagnosis of early dental caries."
  },
  {
    "objectID": "posts/2024-12-03-msdsa_fall25/index.en.html#choose-chico",
    "href": "posts/2024-12-03-msdsa_fall25/index.en.html#choose-chico",
    "title": "Masters in Data Science and Analytics - Fall 25 enrollment open",
    "section": "Choose Chico",
    "text": "Choose Chico\nGet a head start on your Data Science career by majoring in a data related field like Statistics and learning from experienced faculty who use data to improve our society. Some classes will transfer to the MSDSA."
  },
  {
    "objectID": "posts/2024-12-03-msdsa_fall25/index.en.html#choose-your-adventure",
    "href": "posts/2024-12-03-msdsa_fall25/index.en.html#choose-your-adventure",
    "title": "Masters in Data Science and Analytics - Fall 25 enrollment open",
    "section": "Choose your Adventure",
    "text": "Choose your Adventure\nThe Applied Analytics track emphasizes collaborate with scientists or companies in an application domain. The Machine Learning track leverages deeper technical skills to engineer machine and statistical learning algorithms."
  },
  {
    "objectID": "posts/2024-12-03-msdsa_fall25/index.en.html#invest-in-yourself",
    "href": "posts/2024-12-03-msdsa_fall25/index.en.html#invest-in-yourself",
    "title": "Masters in Data Science and Analytics - Fall 25 enrollment open",
    "section": "Invest in Yourself",
    "text": "Invest in Yourself\nYou’ll learn how to handle real world (messy) data, make sense of it, and convey your findings effectively, ensuring you’re always a valuable asset for organizations seeking data-driven solutions."
  },
  {
    "objectID": "posts/2024-12-03-msdsa_fall25/index.en.html#make-a-difference",
    "href": "posts/2024-12-03-msdsa_fall25/index.en.html#make-a-difference",
    "title": "Masters in Data Science and Analytics - Fall 25 enrollment open",
    "section": "Make a Difference",
    "text": "Make a Difference\nData science can empower you to drive positive change in your community by uncovering insights from local data that can inform decisions, address critical issues, and make a tangible impact.\nLearn more about the program and apply here."
  },
  {
    "objectID": "posts/2021-04-07-csc2-chc-2021-ugr.en.html",
    "href": "posts/2021-04-07-csc2-chc-2021-ugr.en.html",
    "title": "Paid summer research opportunity- Basic needs and food insecurity among college students",
    "section": "",
    "text": "The Chico STEM connections collaborative (CSC2) offers a summer undergraduate research program (UGR Program) to eligible students who are at least in their second semester of their sophomore year. Students are eligible to participate in CSC² programs and services if they are:\n\nHispanic, or first generation college student, or low income, AND\nEnrolled as a student in one of these majors.\n\nThe Center for Healthy Communities is partnering with the Data Science Initiative to host 1-2 students to research basic needs and food insecurity among college students. The project description is below. See here for the full details including minimum qualifications.\n\nAs part of ongoing USDA funded grant work, the Center for Healthy Communities is conducting several outreach and research projects pertaining to Food Insecurity among College students state-wide. CHC is partnering and collecting process data from over 40 colleges across the state, including community colleges, UC’s and CSU’s. Additionally, CHC is collecting survey data on food insecurity, wellness and health from college students at 3 universities currently, and looking to expand to 10-20 more this Spring 2021. This survey, along with process data provides a wealth of potential research questions. The student will have the ability to work on a topic under the supervision of the faculty researcher, but will be encouraged to explore a research topic of their own choosing\n\nIf you have any questions about the project, please contact us at datascience@csuchico.edu.\nDirect questions about application and eligibility process to the CSC2 coordinator for your college listed in the announcement. &gt; Update: The closing date for student applications was March 12. Late appliations may be accepted but I doubt for much longer. We apologize for getting this announcement out late."
  },
  {
    "objectID": "home_main.html",
    "href": "home_main.html",
    "title": "Data Science at Chico State",
    "section": "",
    "text": "The Wildcat Data Hub (WDH) empowers the campus and local community with expert data science and statistical consulting, helping researchers and organizations achieve excellence in science and business. The WDH offers a range of services, including data collection, cleaning, visualization, and analysis, as well as personalized short and long term project assistance for students, faculty, and staff.\n\n\n\n\n\n\nA 48-hour data analysis competition where undergraduate students from various majors work in teams on large, real-world data. The data is revealed at the event’s start on Friday evening, and teams present their findings to a panel of judges on Sunday afternoon. No prior programming experience is required!\n\n\n\n\n\n\nCoding is a social activity! Whether you’re working on a data analysis project, exploring R or Python, or need a collaborative space to focus, this is the place for you. Bring your questions, challenges, and curiosity. Faculty and WDH staff are available to guide you through data science topics like data collection and analysis. Join a supportive environment where students, staff, and faculty can code, learn, and work together!\n\n\n\n\n\n\nCheck out the variety of innovative projects students have created as part of the Data Science Certificate Capstone, or the Masters in Data Science and Analytics. These projects highlight the power of creativity and technical expertise. Whether it’s app development, research, or sustainability initiatives, these projects drive progress and provide real-world impact."
  },
  {
    "objectID": "home_main.html#bridging-innovation-and-opportunity",
    "href": "home_main.html#bridging-innovation-and-opportunity",
    "title": "Data Science at Chico State",
    "section": "",
    "text": "The Wildcat Data Hub (WDH) empowers the campus and local community with expert data science and statistical consulting, helping researchers and organizations achieve excellence in science and business. The WDH offers a range of services, including data collection, cleaning, visualization, and analysis, as well as personalized short and long term project assistance for students, faculty, and staff.\n\n\n\n\n\n\nA 48-hour data analysis competition where undergraduate students from various majors work in teams on large, real-world data. The data is revealed at the event’s start on Friday evening, and teams present their findings to a panel of judges on Sunday afternoon. No prior programming experience is required!\n\n\n\n\n\n\nCoding is a social activity! Whether you’re working on a data analysis project, exploring R or Python, or need a collaborative space to focus, this is the place for you. Bring your questions, challenges, and curiosity. Faculty and WDH staff are available to guide you through data science topics like data collection and analysis. Join a supportive environment where students, staff, and faculty can code, learn, and work together!\n\n\n\n\n\n\nCheck out the variety of innovative projects students have created as part of the Data Science Certificate Capstone, or the Masters in Data Science and Analytics. These projects highlight the power of creativity and technical expertise. Whether it’s app development, research, or sustainability initiatives, these projects drive progress and provide real-world impact."
  },
  {
    "objectID": "projects/2025-09-25_MSDSA-summaries/index.html",
    "href": "projects/2025-09-25_MSDSA-summaries/index.html",
    "title": "MSDSA Project Descriptions (2024 Cohort)",
    "section": "",
    "text": "Masters project descriptions for the 2024 cohort of Masters in Data Science and Analytics students. Final project defense slides will be added upon completion.\n\nPushpak Rane\nIntegrating Indian Sign Language (ISL) into Healthcare for Deaf Patients in India.\nIn India, over 18 million deaf and hard-of-hearing patients face barriers to effective healthcare communication. Although Indian Sign Language (ISL) is officially recognized, it is rarely implemented in medical settings due to a shortage of trained professionals, leading to miscommunication and inadequate treatment. This project develops an AI-based system for real-time ISL interpretation using computer vision, trained on medical sign datasets, to bridge communication gaps and improve healthcare accessibility for the Deaf community.\n\n\n\nKhushi Choudhary\nOptimizing Volunteer Scheduling and Emergency Response Using Machine Learning\nThis project aims to build a predictive, real-time volunteer scheduling system that connects operational needs with available resources. Currently, incident command struggles with limited visibility—uncertain who will arrive, when, and with what skills—while volunteers lack clarity on where they are needed, particularly across mutual aid groups. With three separate scheduling systems in play (NVADG, County, and Mutual Aid), coordination is chaotic. The new app will apply machine learning to forecast shortages and skill gaps, provide volunteers with clear shift visibility, and enable coordinators to make faster, data-driven decisions in real time.\n\n\n\nGovardhan Baddala\nOffline-First Web App for Collecting and Syncing Geology Field Data\nThis project develops an offline-first web app for geology fieldwork, designed for use in remote areas without internet access. Currently, students rely on paper notes, which can be lost or introduce errors during later entry. The app stores data locally, then automatically syncs once a connection is available, ensuring faster, more accurate collection and reducing the risk of lost observations.\n\n\n\nShivam Pawar\nGraphLearnR: An R Package for Powerful and Accessible Graph Learning\nGraph learning is an emerging field that uncovers hidden network structures from observed data, with applications ranging from social networks and brain connectivity to protein interactions and transportation systems. Current methods often assume signal smoothness, overlook external factors, and require advanced coding skills. This project addresses these gaps by developing regression-aware graph learning tools in R, making advanced network structure discovery more accessible to researchers in neuroscience, social science, and biology.\n\n\n\nNate Dailey\nRaster-Based Wildfire Risk Model in Python\nThis project develops a scriptable wildfire model in Python to help identify hazardous areas for treatment and reduce wildfire risk. By calculating rate of spread, fireline intensity, and flame length for each pixel, the model provides a technical basis for prioritizing treatments such as mechanical thinning or prescribed burns. Inputs include fuel model and slope rasters, as well as wind speed, wind direction, and fuel moisture, enabling flexible, data-driven fire behavior analysis.\n\n\n\nZakir Elaskar\nB-Line Public Transit: A Data-Driven Analysis for Service Optimization This project applies data science techniques to analyze B-Line, the public transportation system serving Chico and surrounding communities. Public transit is essential for students, workers, and residents, yet inefficiencies can limit service quality and cost effectiveness. By examining trends, detecting inefficiencies, and proposing optimization strategies, this work provides data-driven insights to improve service delivery and promote more sustainable, cost-effective urban mobility.\n\n\n\nSnehitha Gorantla\nAir Pollution Prediction using Time Series Analysis\nThis project develops a hybrid time series model to forecast air pollutant levels in California using EPA CASTNET data (1987–2025). By incorporating meteorological variables such as temperature, wind, and humidity, the model aims to improve the accuracy of short-term air quality predictions. The research explores how weather factors influence pollutant concentrations over time and evaluates the extent to which these variables enhance predictive precision across both rural and suburban regions.\n\n\n\nAbinesh S\nAI Driven Medical Case Manager\nThis project develops an AI-driven medical case manager designed to address the nationwide shortage of trained case managers in healthcare. The system replicates key human functions—including care coordination, advocacy, resource navigation, and health monitoring—while focusing on older adults (65+) with complex needs. By integrating patient advocacy and continuous monitoring, the AI aims to reduce fragmented care, minimize delays in treatment, and improve outcomes. Research will assess its impact on hospital readmissions, patient satisfaction, and workflow integration, while also exploring feasibility within existing healthcare infrastructures.\n\n\n\nAmol Bhalerao\nLeveraging Machine Learning to Model CalFresh Participation CalFresh, California’s version of SNAP, provides essential food assistance to low-income individuals, including college students. Yet, despite 40% of California’s college students being eligible, 82% do not access these benefits. This gap is critical, as 1 in 3 students experience food insecurity, which can cause stress, poor nutrition, and difficulty focusing on academics. Using data from CHC-UCLA, this project will use machine learning to examine the barriers that prevent students from enrolling in CalFresh and identify strategies to increase participation, with the goal of improving student well-being and academic success.\n\n\n\nAnand Gangavarapu\nEvaluating the Ecological Effects of Mastication and Wildfire in Chaparral\nIn summer 2021, the Park Fire burned through parts of the Big Chico Creek Ecological Reserve (BCCER) in Butte County, California, impacting chaparral ecosystems and previously treated management units. While mastication is a widely used fuel treatment in chaparral, its ecological outcomes after wildfire remain uncertain. This project evaluates how masticated chaparral responds to fire, providing insight into treatment effectiveness, ecosystem recovery, and long-term resilience.\n\n\n\nJayana Sarma\nMorphometric Sex Determination and GPS Telemetry of Turkey Vultures in Western Montana\nTurkey Vultures (Cathartes aura) play a vital ecological role as scavengers, yet key aspects of their biology in Western Montana remain poorly understood. This study focuses on the subspecies C. a. meridionalis, which exhibits both migratory and resident behaviors. Research goals include developing accurate morphometric models to determine sex—addressing the challenge of visually similar males and females—while correcting field data inconsistencies. In addition, GPS telemetry is used to track movements and locate hidden nesting sites, with interactive visualizations created to clearly communicate findings. Together, these methods provide new insights into vulture ecology, migration, and breeding in Montana."
  },
  {
    "objectID": "projects/2024-12-31_Juan-Cortes-Aguiar/index.html#goal",
    "href": "projects/2024-12-31_Juan-Cortes-Aguiar/index.html#goal",
    "title": "The CFO Office Sign-in Dashboard App",
    "section": "Goal",
    "text": "Goal\nThe CFO Office Sign-in Sheet recorded information about walk-in student visits to Chico State’s Student Services Center (SSC) CalFresh Outreach (CFO) office.\nThe goal was to create a Dynamic Report using the Shiny app, data analyses, and final reports to keep track of visits to the office. These includes:\n\nDaily visits\nWeekly visits\nMonthly visits\nVisits by Term\nTypes of Assistance\nRepeated Assistance\nHow they heard about CalFresh"
  },
  {
    "objectID": "projects/2024-12-31_Juan-Cortes-Aguiar/index.html#interactive-dashboard",
    "href": "projects/2024-12-31_Juan-Cortes-Aguiar/index.html#interactive-dashboard",
    "title": "The CFO Office Sign-in Dashboard App",
    "section": "Interactive Dashboard",
    "text": "Interactive Dashboard"
  },
  {
    "objectID": "projects/2024-12-31_Juan-Cortes-Aguiar/index.html#impact",
    "href": "projects/2024-12-31_Juan-Cortes-Aguiar/index.html#impact",
    "title": "The CFO Office Sign-in Dashboard App",
    "section": "Impact",
    "text": "Impact\n\n\n\n\n\n\nQuestion\n\n\n\nHow does this project make a difference? (e.g., improve decision-making, provide insights)\n\n\n\n\n\n\n\n\nAnswer\n\n\n\nCFO Team: Saves time by reducing manual data entry. Improves record keeping and organization. Enhances workflow to better serve students.\nChico State Students: Provides access to information about campus resources. Supports basic needs, benefiting low-income, first-generation, and underrepresented students.\nStakeholders Delivers insights regarding their Federal support. Facilitates dissemination tracking for short-term CFO outcomes."
  },
  {
    "objectID": "projects/2024-12-31_Juan-Cortes-Aguiar/index.html#platforms-used",
    "href": "projects/2024-12-31_Juan-Cortes-Aguiar/index.html#platforms-used",
    "title": "The CFO Office Sign-in Dashboard App",
    "section": "Platforms used",
    "text": "Platforms used\n\nR Studio: Used for coding, data analysis, and visualization.\nShiny: R package for building interactive web applications, enabling dynamic data presentation and user interaction.\nGoogle Sheets: A cloud-based spreadsheet tool for real-time data collection, storage, and collaborative work.\nBox: A cloud storage platform used for file sharing and collaborative document management.\nGitHub: Version control and code collaboration platform for managing code and tracking changes."
  },
  {
    "objectID": "projects/2024-12-31_Juan-Cortes-Aguiar/index.html#variables",
    "href": "projects/2024-12-31_Juan-Cortes-Aguiar/index.html#variables",
    "title": "The CFO Office Sign-in Dashboard App",
    "section": "Variables",
    "text": "Variables\nTo create a Dynamic Report using the Shiny app, data analyses, and final reports to keep track of visits to the office. This includes:\n\nDaily, weekly, & monthly visits\nVisits by Term\nTypes of Assistance\nRepeated Assistance\nHow they heard about CalFresh"
  },
  {
    "objectID": "projects/2024-12-31_Juan-Cortes-Aguiar/index.html#data-collection-wrangling",
    "href": "projects/2024-12-31_Juan-Cortes-Aguiar/index.html#data-collection-wrangling",
    "title": "The CFO Office Sign-in Dashboard App",
    "section": "Data Collection & Wrangling",
    "text": "Data Collection & Wrangling\nData was collected through a Google Form, which gathers:\n\nHistory of visits\nSource of awareness about the SSC CFO office\nType of services sought\nName of the assistor\n\n\n\n\n\n\n\n\nAbout Me\n\n\n\n\n\n\n\n\n\n\nJuan is from the Central Coast of California. He graduated from CSU Chico with a BS in Mathematics (Statistics). He initially joined the DAFANH team as a Research and Evaluation intern and later transitioned to a staff role as a Program Assistant and Peer Mentor for the DAFANH 2024 Cohort. Juan enjoys the art of statistics, particularly in applying analytical skills to real-world problems. Outside of his academic and professional pursuits, he enjoys reading, playing the guitar, and weightlifting."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Student Projects",
    "section": "",
    "text": "This page highlights the innovative work of our talented students from the Data Science Certificate program or the Masters in Data Science and Analytics. Projects span a diverse range from academic research, community collaborations, and real-world applications, demonstrating the impact and creativity of our upcoming data professionals. Each project is linked directly to a Github repository with more details about the project, including if the project has good next steps that can be built on by another person.\n\n\n\n\n\n\n\n\n\n\n\n\nMSDSA Project Descriptions (2024 Cohort)\n\n\n\n\n\n\nNate Dailey and Robin Donatello\n\n\n\n\n\n\n\n\n\n\n\n\nBuilding an R package\n\n\n\n\n\n\nSaul Mooradian\n\n\n\n\n\n\n\n\n\n\n\n\nThe CFO Office Sign-in Dashboard App\n\n\n\n\n\n\nJuan Cortes\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "readme.html",
    "href": "readme.html",
    "title": "Blogpost Instructions",
    "section": "",
    "text": "To create a blogpost that will be featured under the Projects tab, follow these steps:\n\nCreate a Service Request\nSubmit a service request so we can help you with the process.\nReview Documentation\nCheck out the Quarto Documentation page—pay particular attention to the section on Markdown basics.\nDownload the Template\nDownload the blogTemplate folder from above and customize it to suit your content.\nCoordinate with the WDH Team\nCommunicate with your assigned WDH team member for guidance on how to get your post featured on the website.\n\n\n\n\n\nOur website has some constraints regarding inline code execution and interactive dashboards. To ensure your blogpost displays correctly:\n\nCode Formatting:\nUse markdown code fences to format any code snippets. This helps maintain readability and prevents execution issues.\nInteractive Content:\nInteractive elements (such as dashboards or widgets) may not render as expected. Consider:\n\nConverting interactive content into static images.\nHosting interactive elements externally and linking to them.\n\nDependencies:\nMinimize external dependencies that could affect load times or display issues on our site.\nLocal Testing:\nPreview your post locally using Quarto to confirm that everything renders as expected. Check for any discrepancies in formatting or functionality.\nAssistance:\nIf you run into issues with code or interactive elements, reach out to your assigned WDH team member for troubleshooting and support.\n\n\n\n\n\nOnce your blogpost is ready:\n\nSave Your Work:\nEnsure that all changes are saved and that your file follows any naming conventions provided by the WDH team.\nSubmit for Review:\nShare your customized .qmd file with your assigned WDH team member.\nRevise if Necessary:\nIncorporate any feedback provided to ensure your post meets the website’s requirements.\nPost Approval:\nAfter approval, your blogpost will be scheduled and featured under the Projects tab on our website.\n\n\n\n\n\n\nVersion Control:\nIf you’re familiar with version control systems (like Git), consider using them to track changes and collaborate with peers.\nFurther Resources:\nBesides the Quarto docs, you might find it helpful to review markdown guides and best practices available online.\nContact:\nFor any questions or additional support, do not hesitate to contact your WDH team member.\n\nHappy blogging!"
  },
  {
    "objectID": "readme.html#making-your-blogpost-work",
    "href": "readme.html#making-your-blogpost-work",
    "title": "Blogpost Instructions",
    "section": "",
    "text": "Our website has some constraints regarding inline code execution and interactive dashboards. To ensure your blogpost displays correctly:\n\nCode Formatting:\nUse markdown code fences to format any code snippets. This helps maintain readability and prevents execution issues.\nInteractive Content:\nInteractive elements (such as dashboards or widgets) may not render as expected. Consider:\n\nConverting interactive content into static images.\nHosting interactive elements externally and linking to them.\n\nDependencies:\nMinimize external dependencies that could affect load times or display issues on our site.\nLocal Testing:\nPreview your post locally using Quarto to confirm that everything renders as expected. Check for any discrepancies in formatting or functionality.\nAssistance:\nIf you run into issues with code or interactive elements, reach out to your assigned WDH team member for troubleshooting and support."
  },
  {
    "objectID": "readme.html#submitting-your-blogpost",
    "href": "readme.html#submitting-your-blogpost",
    "title": "Blogpost Instructions",
    "section": "",
    "text": "Once your blogpost is ready:\n\nSave Your Work:\nEnsure that all changes are saved and that your file follows any naming conventions provided by the WDH team.\nSubmit for Review:\nShare your customized .qmd file with your assigned WDH team member.\nRevise if Necessary:\nIncorporate any feedback provided to ensure your post meets the website’s requirements.\nPost Approval:\nAfter approval, your blogpost will be scheduled and featured under the Projects tab on our website."
  },
  {
    "objectID": "readme.html#additional-tips",
    "href": "readme.html#additional-tips",
    "title": "Blogpost Instructions",
    "section": "",
    "text": "Version Control:\nIf you’re familiar with version control systems (like Git), consider using them to track changes and collaborate with peers.\nFurther Resources:\nBesides the Quarto docs, you might find it helpful to review markdown guides and best practices available online.\nContact:\nFor any questions or additional support, do not hesitate to contact your WDH team member.\n\nHappy blogging!"
  },
  {
    "objectID": "ourteam.html",
    "href": "ourteam.html",
    "title": "Our Team",
    "section": "",
    "text": "The Wildcat Datahub partners with faculty and staff across campus to provide support for research projects. Our team includes faculty affiliates from the Statistics, Mathematics, Political Science departments, and more. Additionally, we have interns from various departments who provide support for research projects. check out our team below."
  },
  {
    "objectID": "ourteam.html#director",
    "href": "ourteam.html#director",
    "title": "Our Team",
    "section": "Director",
    "text": "Director\n\n\n Robin Donatello\nDepartment: Data Science\nrdonatello@csuchico.edu\nRead more: Robin’s Website"
  },
  {
    "objectID": "ourteam.html#faculty-affiliates",
    "href": "ourteam.html#faculty-affiliates",
    "title": "Our Team",
    "section": "Faculty Affiliates",
    "text": "Faculty Affiliates\n\n\n\n Nick Lytal\nDepartment: Statistics\nnlytal@csuchico.edu\n\n\n\n Ginger Alonso\nDepartment: Political Science\ngalonso2@csuchico.edu\n\n\n\n Kathy Gray\nDepartment: Statistics\nklgray@csuchico.edu\n\n\n\n Edward Roualdes\nDepartment: Statistics\neroualdes@csuchico.edu\n\n\n\n Kwadwo Boakye\nDepartment: Public Health & Health Services Administration\nkaboakye@csuchico.edu\n\n\n\n Become an Affiliate"
  },
  {
    "objectID": "ourteam.html#interns",
    "href": "ourteam.html#interns",
    "title": "Our Team",
    "section": "Interns",
    "text": "Interns\n\n\n\n Rowan Morkner\nMajor: Economics and Data Science\nrdmorknerbrown@csuchico.edu\nGithub\nPortfolio: rowanmorkner.com\n\n\n\n Khushi Choudhary\nMajor: Masters in Data Science\nk-choudhary@csuchico.edu\nGithub\nLinkedin\n\n\n\n Caleb Hearn\nMajor: Major: Economics & Applied Statistics\nchearn@csuchico.edu\nLinkedin\n\n\n\n Snehitha Gorantla\nMajor: Masters in Data Science\nsgorantla@csuchico.edu\nLinkedin"
  },
  {
    "objectID": "datahub.html",
    "href": "datahub.html",
    "title": "Wildcat Data Hub",
    "section": "",
    "text": "The Wildcat Data Hub (WDH) is a new consulting and support service at Chico State designed to support both campus and community researchers with all aspects of research relating to data. This includes undergraduate and graduate students, staff, faculty and our community members.\nThrough a mix of pro-bono and fee-based services, the WDH is dedicated to providing high-quality support for research projects while creating paid, hands-on learning opportunities for students.\n\n\n\n\n\n\n\n\n\n\nServices\n\nProgramming languages such as R, Python and SQL\nCleaning and transforming data\nData collection tools and techniques\nData Visualization and reports\nReproducible research techniques\nData analysis via statistical modeling / machine learning\nDeveloping measurable outcomes for research and grant proposals\n\nThe hub offers free drop in consultation and coding support. Short and long-term project assistance by qualified students under faculty mentorship available on a fee-based system.\n Request Support \n\n\n\n\nPrevious Work\n\nSupporting student authors in contributing blog posts\nWriting scripts import large quantities of data files into R for wrangling and analysis.\nAssisting graduate student thesis work with importing and cleaning time series data from sensors.\n\n\n\n\n\n\n\n\n\n\n\n\nOur Team\nThe Wildcat Datahub partners with faculty and staff across campus to provide support for research projects. Our team includes faculty affiliates from the Statistics, Mathematics, Political Science departments, and more. Including our director Robin Donatello, and faculty affiliates Nick Lytal, Ginger Alonso, Kathy Gray, Edward Roualdes, and Kwadwo Boakye. Additionally, we have interns from various departments who provide support for research projects.\n Meet the Team"
  }
]